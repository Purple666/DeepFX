{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Python] Keras-RLで簡単に強化学習(DQN)を試す](http://qiita.com/inoory/items/e63ade6f21766c7c2393)を参考に、エージェントを作成する。FXの自動取引を行い、利益を出すのが目標。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use('tkagg')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import talib\n",
    "from logging import getLogger, StreamHandler, DEBUG, INFO\n",
    "\n",
    "from hist_data import HistData\n",
    "from fx_trade import FXTrade\n",
    "from deep_fx import DeepFX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = getLogger(__name__)\n",
    "handler = StreamHandler()\n",
    "#handler.setLevel(INFO)\n",
    "#logger.setLevel(INFO)\n",
    "handler.setLevel(DEBUG)\n",
    "logger.setLevel(DEBUG)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header is included\n"
     ]
    }
   ],
   "source": [
    "#import imp\n",
    "#import sys\n",
    "#del(hist_data)\n",
    "#from hist_data import HistData\n",
    "#del(hist_data)\n",
    "#imp.reload(hist_data)\n",
    "#imp.reload(sys.modules[hist_data.__module__])\n",
    "hd = HistData(csv_path = 'historical_data/DAT_ASCII_USDJPY_M1_201710_m5.csv',\n",
    "                     begin_date='2017-10-02T00:00:00',\n",
    "                     end_date='2017-10-02T23:59:59')\n",
    "                     #end_date='2017-10-09T23:59:59')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:00:00</th>\n",
       "      <td>112.808</td>\n",
       "      <td>112.833</td>\n",
       "      <td>112.805</td>\n",
       "      <td>112.833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:05:00</th>\n",
       "      <td>112.833</td>\n",
       "      <td>112.834</td>\n",
       "      <td>112.784</td>\n",
       "      <td>112.793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:10:00</th>\n",
       "      <td>112.793</td>\n",
       "      <td>112.821</td>\n",
       "      <td>112.788</td>\n",
       "      <td>112.812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:15:00</th>\n",
       "      <td>112.812</td>\n",
       "      <td>112.812</td>\n",
       "      <td>112.790</td>\n",
       "      <td>112.794</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:20:00</th>\n",
       "      <td>112.801</td>\n",
       "      <td>112.805</td>\n",
       "      <td>112.787</td>\n",
       "      <td>112.795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:25:00</th>\n",
       "      <td>112.795</td>\n",
       "      <td>112.832</td>\n",
       "      <td>112.794</td>\n",
       "      <td>112.826</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:30:00</th>\n",
       "      <td>112.826</td>\n",
       "      <td>112.834</td>\n",
       "      <td>112.820</td>\n",
       "      <td>112.827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:35:00</th>\n",
       "      <td>112.825</td>\n",
       "      <td>112.851</td>\n",
       "      <td>112.819</td>\n",
       "      <td>112.832</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:40:00</th>\n",
       "      <td>112.836</td>\n",
       "      <td>112.851</td>\n",
       "      <td>112.827</td>\n",
       "      <td>112.841</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:45:00</th>\n",
       "      <td>112.840</td>\n",
       "      <td>112.851</td>\n",
       "      <td>112.826</td>\n",
       "      <td>112.826</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:50:00</th>\n",
       "      <td>112.825</td>\n",
       "      <td>112.836</td>\n",
       "      <td>112.810</td>\n",
       "      <td>112.815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:55:00</th>\n",
       "      <td>112.815</td>\n",
       "      <td>112.821</td>\n",
       "      <td>112.807</td>\n",
       "      <td>112.817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:00:00</th>\n",
       "      <td>112.821</td>\n",
       "      <td>112.841</td>\n",
       "      <td>112.819</td>\n",
       "      <td>112.837</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:05:00</th>\n",
       "      <td>112.838</td>\n",
       "      <td>112.842</td>\n",
       "      <td>112.815</td>\n",
       "      <td>112.840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:10:00</th>\n",
       "      <td>112.841</td>\n",
       "      <td>112.852</td>\n",
       "      <td>112.838</td>\n",
       "      <td>112.844</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:15:00</th>\n",
       "      <td>112.843</td>\n",
       "      <td>112.858</td>\n",
       "      <td>112.841</td>\n",
       "      <td>112.851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:20:00</th>\n",
       "      <td>112.851</td>\n",
       "      <td>112.901</td>\n",
       "      <td>112.850</td>\n",
       "      <td>112.900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:25:00</th>\n",
       "      <td>112.902</td>\n",
       "      <td>112.921</td>\n",
       "      <td>112.884</td>\n",
       "      <td>112.906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:30:00</th>\n",
       "      <td>112.907</td>\n",
       "      <td>112.914</td>\n",
       "      <td>112.897</td>\n",
       "      <td>112.909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:35:00</th>\n",
       "      <td>112.910</td>\n",
       "      <td>112.910</td>\n",
       "      <td>112.887</td>\n",
       "      <td>112.887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:40:00</th>\n",
       "      <td>112.886</td>\n",
       "      <td>112.906</td>\n",
       "      <td>112.886</td>\n",
       "      <td>112.888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:45:00</th>\n",
       "      <td>112.889</td>\n",
       "      <td>112.902</td>\n",
       "      <td>112.872</td>\n",
       "      <td>112.889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:50:00</th>\n",
       "      <td>112.889</td>\n",
       "      <td>112.889</td>\n",
       "      <td>112.862</td>\n",
       "      <td>112.869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:55:00</th>\n",
       "      <td>112.870</td>\n",
       "      <td>112.883</td>\n",
       "      <td>112.842</td>\n",
       "      <td>112.874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 02:00:00</th>\n",
       "      <td>112.878</td>\n",
       "      <td>112.924</td>\n",
       "      <td>112.828</td>\n",
       "      <td>112.904</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 02:05:00</th>\n",
       "      <td>112.905</td>\n",
       "      <td>112.907</td>\n",
       "      <td>112.864</td>\n",
       "      <td>112.883</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 02:10:00</th>\n",
       "      <td>112.881</td>\n",
       "      <td>112.888</td>\n",
       "      <td>112.835</td>\n",
       "      <td>112.851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 02:15:00</th>\n",
       "      <td>112.852</td>\n",
       "      <td>112.861</td>\n",
       "      <td>112.827</td>\n",
       "      <td>112.850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 02:20:00</th>\n",
       "      <td>112.854</td>\n",
       "      <td>112.906</td>\n",
       "      <td>112.851</td>\n",
       "      <td>112.878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 02:25:00</th>\n",
       "      <td>112.876</td>\n",
       "      <td>112.924</td>\n",
       "      <td>112.865</td>\n",
       "      <td>112.912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 21:30:00</th>\n",
       "      <td>112.976</td>\n",
       "      <td>112.988</td>\n",
       "      <td>112.928</td>\n",
       "      <td>112.933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 21:35:00</th>\n",
       "      <td>112.934</td>\n",
       "      <td>113.005</td>\n",
       "      <td>112.934</td>\n",
       "      <td>112.970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 21:40:00</th>\n",
       "      <td>112.969</td>\n",
       "      <td>112.978</td>\n",
       "      <td>112.950</td>\n",
       "      <td>112.961</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 21:45:00</th>\n",
       "      <td>112.962</td>\n",
       "      <td>113.076</td>\n",
       "      <td>112.951</td>\n",
       "      <td>113.059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 21:50:00</th>\n",
       "      <td>113.057</td>\n",
       "      <td>113.062</td>\n",
       "      <td>113.021</td>\n",
       "      <td>113.056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 21:55:00</th>\n",
       "      <td>113.055</td>\n",
       "      <td>113.170</td>\n",
       "      <td>113.055</td>\n",
       "      <td>113.148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:00:00</th>\n",
       "      <td>113.147</td>\n",
       "      <td>113.147</td>\n",
       "      <td>113.118</td>\n",
       "      <td>113.142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:05:00</th>\n",
       "      <td>113.143</td>\n",
       "      <td>113.161</td>\n",
       "      <td>113.115</td>\n",
       "      <td>113.117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:10:00</th>\n",
       "      <td>113.119</td>\n",
       "      <td>113.151</td>\n",
       "      <td>113.056</td>\n",
       "      <td>113.068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:15:00</th>\n",
       "      <td>113.070</td>\n",
       "      <td>113.100</td>\n",
       "      <td>113.067</td>\n",
       "      <td>113.080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:20:00</th>\n",
       "      <td>113.082</td>\n",
       "      <td>113.095</td>\n",
       "      <td>113.075</td>\n",
       "      <td>113.086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:25:00</th>\n",
       "      <td>113.086</td>\n",
       "      <td>113.122</td>\n",
       "      <td>113.068</td>\n",
       "      <td>113.099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:30:00</th>\n",
       "      <td>113.099</td>\n",
       "      <td>113.120</td>\n",
       "      <td>113.084</td>\n",
       "      <td>113.092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:35:00</th>\n",
       "      <td>113.091</td>\n",
       "      <td>113.091</td>\n",
       "      <td>113.050</td>\n",
       "      <td>113.060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:40:00</th>\n",
       "      <td>113.061</td>\n",
       "      <td>113.066</td>\n",
       "      <td>113.050</td>\n",
       "      <td>113.058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:45:00</th>\n",
       "      <td>113.059</td>\n",
       "      <td>113.064</td>\n",
       "      <td>113.050</td>\n",
       "      <td>113.059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:50:00</th>\n",
       "      <td>113.060</td>\n",
       "      <td>113.068</td>\n",
       "      <td>113.054</td>\n",
       "      <td>113.066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:55:00</th>\n",
       "      <td>113.069</td>\n",
       "      <td>113.077</td>\n",
       "      <td>113.065</td>\n",
       "      <td>113.072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:00:00</th>\n",
       "      <td>113.073</td>\n",
       "      <td>113.082</td>\n",
       "      <td>113.056</td>\n",
       "      <td>113.072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:05:00</th>\n",
       "      <td>113.073</td>\n",
       "      <td>113.073</td>\n",
       "      <td>113.064</td>\n",
       "      <td>113.064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:10:00</th>\n",
       "      <td>113.063</td>\n",
       "      <td>113.063</td>\n",
       "      <td>113.026</td>\n",
       "      <td>113.043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:15:00</th>\n",
       "      <td>113.045</td>\n",
       "      <td>113.068</td>\n",
       "      <td>113.031</td>\n",
       "      <td>113.064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:20:00</th>\n",
       "      <td>113.065</td>\n",
       "      <td>113.084</td>\n",
       "      <td>113.064</td>\n",
       "      <td>113.071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:25:00</th>\n",
       "      <td>113.080</td>\n",
       "      <td>113.105</td>\n",
       "      <td>113.080</td>\n",
       "      <td>113.089</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:30:00</th>\n",
       "      <td>113.088</td>\n",
       "      <td>113.127</td>\n",
       "      <td>113.078</td>\n",
       "      <td>113.124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:35:00</th>\n",
       "      <td>113.124</td>\n",
       "      <td>113.155</td>\n",
       "      <td>113.124</td>\n",
       "      <td>113.148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:40:00</th>\n",
       "      <td>113.147</td>\n",
       "      <td>113.147</td>\n",
       "      <td>113.111</td>\n",
       "      <td>113.135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:45:00</th>\n",
       "      <td>113.135</td>\n",
       "      <td>113.175</td>\n",
       "      <td>113.129</td>\n",
       "      <td>113.169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:50:00</th>\n",
       "      <td>113.167</td>\n",
       "      <td>113.178</td>\n",
       "      <td>113.125</td>\n",
       "      <td>113.137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:55:00</th>\n",
       "      <td>113.139</td>\n",
       "      <td>113.155</td>\n",
       "      <td>113.128</td>\n",
       "      <td>113.142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Open     High      Low    Close  Volume\n",
       "Date                                                           \n",
       "2017-10-02 00:00:00  112.808  112.833  112.805  112.833       0\n",
       "2017-10-02 00:05:00  112.833  112.834  112.784  112.793       0\n",
       "2017-10-02 00:10:00  112.793  112.821  112.788  112.812       0\n",
       "2017-10-02 00:15:00  112.812  112.812  112.790  112.794       0\n",
       "2017-10-02 00:20:00  112.801  112.805  112.787  112.795       0\n",
       "2017-10-02 00:25:00  112.795  112.832  112.794  112.826       0\n",
       "2017-10-02 00:30:00  112.826  112.834  112.820  112.827       0\n",
       "2017-10-02 00:35:00  112.825  112.851  112.819  112.832       0\n",
       "2017-10-02 00:40:00  112.836  112.851  112.827  112.841       0\n",
       "2017-10-02 00:45:00  112.840  112.851  112.826  112.826       0\n",
       "2017-10-02 00:50:00  112.825  112.836  112.810  112.815       0\n",
       "2017-10-02 00:55:00  112.815  112.821  112.807  112.817       0\n",
       "2017-10-02 01:00:00  112.821  112.841  112.819  112.837       0\n",
       "2017-10-02 01:05:00  112.838  112.842  112.815  112.840       0\n",
       "2017-10-02 01:10:00  112.841  112.852  112.838  112.844       0\n",
       "2017-10-02 01:15:00  112.843  112.858  112.841  112.851       0\n",
       "2017-10-02 01:20:00  112.851  112.901  112.850  112.900       0\n",
       "2017-10-02 01:25:00  112.902  112.921  112.884  112.906       0\n",
       "2017-10-02 01:30:00  112.907  112.914  112.897  112.909       0\n",
       "2017-10-02 01:35:00  112.910  112.910  112.887  112.887       0\n",
       "2017-10-02 01:40:00  112.886  112.906  112.886  112.888       0\n",
       "2017-10-02 01:45:00  112.889  112.902  112.872  112.889       0\n",
       "2017-10-02 01:50:00  112.889  112.889  112.862  112.869       0\n",
       "2017-10-02 01:55:00  112.870  112.883  112.842  112.874       0\n",
       "2017-10-02 02:00:00  112.878  112.924  112.828  112.904       0\n",
       "2017-10-02 02:05:00  112.905  112.907  112.864  112.883       0\n",
       "2017-10-02 02:10:00  112.881  112.888  112.835  112.851       0\n",
       "2017-10-02 02:15:00  112.852  112.861  112.827  112.850       0\n",
       "2017-10-02 02:20:00  112.854  112.906  112.851  112.878       0\n",
       "2017-10-02 02:25:00  112.876  112.924  112.865  112.912       0\n",
       "...                      ...      ...      ...      ...     ...\n",
       "2017-10-02 21:30:00  112.976  112.988  112.928  112.933       0\n",
       "2017-10-02 21:35:00  112.934  113.005  112.934  112.970       0\n",
       "2017-10-02 21:40:00  112.969  112.978  112.950  112.961       0\n",
       "2017-10-02 21:45:00  112.962  113.076  112.951  113.059       0\n",
       "2017-10-02 21:50:00  113.057  113.062  113.021  113.056       0\n",
       "2017-10-02 21:55:00  113.055  113.170  113.055  113.148       0\n",
       "2017-10-02 22:00:00  113.147  113.147  113.118  113.142       0\n",
       "2017-10-02 22:05:00  113.143  113.161  113.115  113.117       0\n",
       "2017-10-02 22:10:00  113.119  113.151  113.056  113.068       0\n",
       "2017-10-02 22:15:00  113.070  113.100  113.067  113.080       0\n",
       "2017-10-02 22:20:00  113.082  113.095  113.075  113.086       0\n",
       "2017-10-02 22:25:00  113.086  113.122  113.068  113.099       0\n",
       "2017-10-02 22:30:00  113.099  113.120  113.084  113.092       0\n",
       "2017-10-02 22:35:00  113.091  113.091  113.050  113.060       0\n",
       "2017-10-02 22:40:00  113.061  113.066  113.050  113.058       0\n",
       "2017-10-02 22:45:00  113.059  113.064  113.050  113.059       0\n",
       "2017-10-02 22:50:00  113.060  113.068  113.054  113.066       0\n",
       "2017-10-02 22:55:00  113.069  113.077  113.065  113.072       0\n",
       "2017-10-02 23:00:00  113.073  113.082  113.056  113.072       0\n",
       "2017-10-02 23:05:00  113.073  113.073  113.064  113.064       0\n",
       "2017-10-02 23:10:00  113.063  113.063  113.026  113.043       0\n",
       "2017-10-02 23:15:00  113.045  113.068  113.031  113.064       0\n",
       "2017-10-02 23:20:00  113.065  113.084  113.064  113.071       0\n",
       "2017-10-02 23:25:00  113.080  113.105  113.080  113.089       0\n",
       "2017-10-02 23:30:00  113.088  113.127  113.078  113.124       0\n",
       "2017-10-02 23:35:00  113.124  113.155  113.124  113.148       0\n",
       "2017-10-02 23:40:00  113.147  113.147  113.111  113.135       0\n",
       "2017-10-02 23:45:00  113.135  113.175  113.129  113.169       0\n",
       "2017-10-02 23:50:00  113.167  113.178  113.125  113.137       0\n",
       "2017-10-02 23:55:00  113.139  113.155  113.128  113.142       0\n",
       "\n",
       "[288 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd.data()\n",
    "#len(hist_data.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FXTrade(1000000, 0.08, hd, logger=logger)\n",
    "#env = FXTrade(1000000, 0.08, h, logger=logger)\n",
    "prepared_model_filename = None #'Keras-RL_DQN_FX_model_meanq1.440944e+06_episode00003.h5'\n",
    "dfx = DeepFX(env, prepared_model_filename=prepared_model_filename, episodes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/11/05 19:59:31\n",
      "Training for 861 steps ...\n",
      "Training for 861 steps ...\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "Step 00001: model improved\n",
      "  from 0.000000e+00\n",
      "    to 0.000000e+00, saving model to ./models/Keras-RL_DQN_FX_model_meanq0.000000e+00_episode00000\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq0.000000e+00_episode00000 has done.\n",
      "max mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "   1/861: episode: 1, duration: 0.063s, episode steps: 1, steps per second: 16, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "   1/861: episode: 1, duration: 0.064s, episode steps: 1, steps per second: 16, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "   2/861: episode: 2, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "   2/861: episode: 2, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "   3/861: episode: 3, duration: 0.032s, episode steps: 1, steps per second: 32, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "   3/861: episode: 3, duration: 0.033s, episode steps: 1, steps per second: 31, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "   4/861: episode: 4, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "   4/861: episode: 4, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "   5/861: episode: 5, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "   5/861: episode: 5, duration: 0.039s, episode steps: 1, steps per second: 26, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "   6/861: episode: 6, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "   6/861: episode: 6, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "   7/861: episode: 7, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "   7/861: episode: 7, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "   8/861: episode: 8, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "   8/861: episode: 8, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "   9/861: episode: 9, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "   9/861: episode: 9, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  10/861: episode: 10, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  10/861: episode: 10, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  11/861: episode: 11, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  11/861: episode: 11, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  12/861: episode: 12, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  12/861: episode: 12, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  13/861: episode: 13, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  13/861: episode: 13, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  14/861: episode: 14, duration: 0.031s, episode steps: 1, steps per second: 33, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  14/861: episode: 14, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  15/861: episode: 15, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  15/861: episode: 15, duration: 0.035s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  16/861: episode: 16, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  16/861: episode: 16, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000000.000000\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115207.739151\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000000.000000\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  17/861: episode: 17, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  17/861: episode: 17, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  19/861: episode: 18, duration: 0.053s, episode steps: 2, steps per second: 38, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "  19/861: episode: 18, duration: 0.053s, episode steps: 2, steps per second: 37, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  20/861: episode: 19, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  20/861: episode: 19, duration: 0.032s, episode steps: 1, steps per second: 32, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  21/861: episode: 20, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  21/861: episode: 20, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  22/861: episode: 21, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  22/861: episode: 21, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  23/861: episode: 22, duration: 0.026s, episode steps: 1, steps per second: 38, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  23/861: episode: 22, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115207.739151\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000000.000000\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  25/861: episode: 23, duration: 0.050s, episode steps: 2, steps per second: 40, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "  25/861: episode: 23, duration: 0.051s, episode steps: 2, steps per second: 39, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  26/861: episode: 24, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  26/861: episode: 24, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  27/861: episode: 25, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  27/861: episode: 25, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  28/861: episode: 26, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  28/861: episode: 26, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  29/861: episode: 27, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  29/861: episode: 27, duration: 0.028s, episode steps: 1, steps per second: 35, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  30/861: episode: 28, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  30/861: episode: 28, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reward: -115207.739151\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  32/861: episode: 29, duration: 0.046s, episode steps: 2, steps per second: 43, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "  32/861: episode: 29, duration: 0.048s, episode steps: 2, steps per second: 41, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  33/861: episode: 30, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  33/861: episode: 30, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  34/861: episode: 31, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  34/861: episode: 31, duration: 0.035s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  35/861: episode: 32, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  35/861: episode: 32, duration: 0.036s, episode steps: 1, steps per second: 27, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  36/861: episode: 33, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  36/861: episode: 33, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  37/861: episode: 34, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  37/861: episode: 34, duration: 0.039s, episode steps: 1, steps per second: 26, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  38/861: episode: 35, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  38/861: episode: 35, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  39/861: episode: 36, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  39/861: episode: 36, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  40/861: episode: 37, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  40/861: episode: 37, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  41/861: episode: 38, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  41/861: episode: 38, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  42/861: episode: 39, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  42/861: episode: 39, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  43/861: episode: 40, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  43/861: episode: 40, duration: 0.028s, episode steps: 1, steps per second: 36, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  44/861: episode: 41, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  44/861: episode: 41, duration: 0.035s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  45/861: episode: 42, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  45/861: episode: 42, duration: 0.035s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  46/861: episode: 43, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  46/861: episode: 43, duration: 0.035s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  47/861: episode: 44, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  47/861: episode: 44, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  48/861: episode: 45, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  48/861: episode: 45, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  49/861: episode: 46, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  49/861: episode: 46, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  50/861: episode: 47, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  50/861: episode: 47, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  51/861: episode: 48, duration: 0.029s, episode steps: 1, steps per second: 35, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  51/861: episode: 48, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  52/861: episode: 49, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  52/861: episode: 49, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  53/861: episode: 50, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  53/861: episode: 50, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  54/861: episode: 51, duration: 0.035s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  54/861: episode: 51, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  55/861: episode: 52, duration: 0.032s, episode steps: 1, steps per second: 32, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  55/861: episode: 52, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  56/861: episode: 53, duration: 0.032s, episode steps: 1, steps per second: 32, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  56/861: episode: 53, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  57/861: episode: 54, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  57/861: episode: 54, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  58/861: episode: 55, duration: 0.030s, episode steps: 1, steps per second: 34, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  58/861: episode: 55, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  59/861: episode: 56, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  59/861: episode: 56, duration: 0.027s, episode steps: 1, steps per second: 37, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  60/861: episode: 57, duration: 0.033s, episode steps: 1, steps per second: 31, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  60/861: episode: 57, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  61/861: episode: 58, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  61/861: episode: 58, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  62/861: episode: 59, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  62/861: episode: 59, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  63/861: episode: 60, duration: 0.032s, episode steps: 1, steps per second: 32, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  63/861: episode: 60, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000000.000000\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115207.739151\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  64/861: episode: 61, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  64/861: episode: 61, duration: 0.038s, episode steps: 1, steps per second: 27, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  66/861: episode: 62, duration: 0.048s, episode steps: 2, steps per second: 41, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "  66/861: episode: 62, duration: 0.049s, episode steps: 2, steps per second: 41, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  67/861: episode: 63, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  67/861: episode: 63, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  68/861: episode: 64, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  68/861: episode: 64, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  69/861: episode: 65, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  69/861: episode: 65, duration: 0.033s, episode steps: 1, steps per second: 31, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  70/861: episode: 66, duration: 0.031s, episode steps: 1, steps per second: 33, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  70/861: episode: 66, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115598.714111\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115603.227431\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000209.774775\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115009.769405\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  71/861: episode: 67, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  71/861: episode: 67, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  72/861: episode: 68, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  72/861: episode: 68, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  73/861: episode: 69, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  73/861: episode: 69, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  74/861: episode: 70, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  74/861: episode: 70, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  78/861: episode: 71, duration: 0.078s, episode steps: 4, steps per second: 51, episode reward: 5116401.947, mean reward: 1279100.487 [-115009.769, 2115603.227], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: --, mean_q: --\n",
      "  78/861: episode: 71, duration: 0.079s, episode steps: 4, steps per second: 51, episode reward: 5116401.947, mean reward: 1279100.487 [-115009.769, 2115603.227], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000004.513320\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115207.739151\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000004.513320\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000000.000000\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115393.452656\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  80/861: episode: 72, duration: 0.045s, episode steps: 2, steps per second: 45, episode reward: 884796.774, mean reward: 442398.387 [-115207.739, 1000004.513], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "  80/861: episode: 72, duration: 0.045s, episode steps: 2, steps per second: 44, episode reward: 884796.774, mean reward: 442398.387 [-115207.739, 1000004.513], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  83/861: episode: 73, duration: 0.068s, episode steps: 3, steps per second: 44, episode reward: 1884611.061, mean reward: 628203.687 [-115393.453, 1000004.513], mean action: 1.333 [0.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: --, mean_q: --\n",
      "  83/861: episode: 73, duration: 0.068s, episode steps: 3, steps per second: 44, episode reward: 1884611.061, mean reward: 628203.687 [-115393.453, 1000004.513], mean action: 1.333 [0.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  84/861: episode: 74, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  84/861: episode: 74, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  85/861: episode: 75, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  85/861: episode: 75, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  86/861: episode: 76, duration: 0.035s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  86/861: episode: 76, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  87/861: episode: 77, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  87/861: episode: 77, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  88/861: episode: 78, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  88/861: episode: 78, duration: 0.032s, episode steps: 1, steps per second: 31, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  89/861: episode: 79, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  89/861: episode: 79, duration: 0.031s, episode steps: 1, steps per second: 32, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  90/861: episode: 80, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  90/861: episode: 80, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  91/861: episode: 81, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  91/861: episode: 81, duration: 0.038s, episode steps: 1, steps per second: 27, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  92/861: episode: 82, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  92/861: episode: 82, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000000.000000\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "reward: 2115207.739151\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115205.596084\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999988.082520\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_step 000004 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115239.092661\n",
      "now_datetime: 2017-10-02 00:20:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000004 [2017-10-02 00:20:00]\n",
      "   after: 000005 [2017-10-02 00:25:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  93/861: episode: 83, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  93/861: episode: 83, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  94/861: episode: 84, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  94/861: episode: 84, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "  95/861: episode: 85, duration: 0.033s, episode steps: 1, steps per second: 31, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "  95/861: episode: 85, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      " 100/861: episode: 86, duration: 0.105s, episode steps: 5, steps per second: 48, episode reward: 6115162.325, mean reward: 1223032.465 [-115239.093, 2115207.739], mean action: 1.400 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: --, mean_q: --\n",
      " 100/861: episode: 86, duration: 0.106s, episode steps: 5, steps per second: 47, episode reward: 6115162.325, mean reward: 1223032.465 [-115239.093, 2115207.739], mean action: 1.400 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 5.702987e+01\n",
      "Step 00102: model improved\n",
      "  from 0.000000e+00\n",
      "    to 5.702987e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.702987e+01_episode00086\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.702987e+01_episode00086 has done.\n",
      "max mean_q value: 5.702987e+01\n",
      "========== /Model Saver output =============\n",
      " 102/861: episode: 87, duration: 0.457s, episode steps: 2, steps per second: 4, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 122630856704.000000, mean_q: 57.029865\n",
      " 102/861: episode: 87, duration: 0.458s, episode steps: 2, steps per second: 4, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 122630856704.000000, mean_q: 57.029865\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 5.670848e+01\n",
      "========== /Model Saver output =============\n",
      " 104/861: episode: 88, duration: 0.061s, episode steps: 2, steps per second: 33, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 192360415232.000000, mean_q: 56.708477\n",
      " 104/861: episode: 88, duration: 0.061s, episode steps: 2, steps per second: 33, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 192360415232.000000, mean_q: 56.708477\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 5.671294e+01\n",
      "========== /Model Saver output =============\n",
      " 106/861: episode: 89, duration: 0.056s, episode steps: 2, steps per second: 36, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 211443105792.000000, mean_q: 56.712944\n",
      " 106/861: episode: 89, duration: 0.057s, episode steps: 2, steps per second: 35, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 211443105792.000000, mean_q: 56.712944\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 5.684443e+01\n",
      "========== /Model Saver output =============\n",
      " 108/861: episode: 90, duration: 0.065s, episode steps: 2, steps per second: 31, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 122626801664.000000, mean_q: 56.844429\n",
      " 108/861: episode: 90, duration: 0.066s, episode steps: 2, steps per second: 31, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 122626801664.000000, mean_q: 56.844429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 5.693508e+01\n",
      "========== /Model Saver output =============\n",
      " 110/861: episode: 91, duration: 0.079s, episode steps: 2, steps per second: 25, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 118598230016.000000, mean_q: 56.935081\n",
      " 110/861: episode: 91, duration: 0.081s, episode steps: 2, steps per second: 25, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 118598230016.000000, mean_q: 56.935081\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 5.704161e+01\n",
      "Step 00112: model improved\n",
      "  from 5.702987e+01\n",
      "    to 5.704161e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.704161e+01_episode00091\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.704161e+01_episode00091 has done.\n",
      "max mean_q value: 5.704161e+01\n",
      "========== /Model Saver output =============\n",
      " 112/861: episode: 92, duration: 0.081s, episode steps: 2, steps per second: 25, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 138053648384.000000, mean_q: 57.041611\n",
      " 112/861: episode: 92, duration: 0.082s, episode steps: 2, steps per second: 24, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 138053648384.000000, mean_q: 57.041611\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 5.712515e+01\n",
      "Step 00114: model improved\n",
      "  from 5.704161e+01\n",
      "    to 5.712515e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.712515e+01_episode00092\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.712515e+01_episode00092 has done.\n",
      "max mean_q value: 5.712515e+01\n",
      "========== /Model Saver output =============\n",
      " 114/861: episode: 93, duration: 0.083s, episode steps: 2, steps per second: 24, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 138044047360.000000, mean_q: 57.125153\n",
      " 114/861: episode: 93, duration: 0.085s, episode steps: 2, steps per second: 24, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 138044047360.000000, mean_q: 57.125153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 5.723707e+01\n",
      "Step 00116: model improved\n",
      "  from 5.712515e+01\n",
      "    to 5.723707e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.723707e+01_episode00093\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.723707e+01_episode00093 has done.\n",
      "max mean_q value: 5.723707e+01\n",
      "========== /Model Saver output =============\n",
      " 116/861: episode: 94, duration: 0.091s, episode steps: 2, steps per second: 22, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 196012916736.000000, mean_q: 57.237068\n",
      " 116/861: episode: 94, duration: 0.092s, episode steps: 2, steps per second: 22, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 196012916736.000000, mean_q: 57.237068\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 5.743137e+01\n",
      "Step 00118: model improved\n",
      "  from 5.723707e+01\n",
      "    to 5.743137e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.743137e+01_episode00094\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.743137e+01_episode00094 has done.\n",
      "max mean_q value: 5.743137e+01\n",
      "========== /Model Saver output =============\n",
      " 118/861: episode: 95, duration: 0.078s, episode steps: 2, steps per second: 25, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 161165574144.000000, mean_q: 57.431366\n",
      " 118/861: episode: 95, duration: 0.080s, episode steps: 2, steps per second: 25, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 161165574144.000000, mean_q: 57.431366\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 5.764782e+01\n",
      "Step 00120: model improved\n",
      "  from 5.743137e+01\n",
      "    to 5.764782e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.764782e+01_episode00095\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.764782e+01_episode00095 has done.\n",
      "max mean_q value: 5.764782e+01\n",
      "========== /Model Saver output =============\n",
      " 120/861: episode: 96, duration: 0.091s, episode steps: 2, steps per second: 22, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 362600398848.000000, mean_q: 57.647816\n",
      " 120/861: episode: 96, duration: 0.092s, episode steps: 2, steps per second: 22, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 362600398848.000000, mean_q: 57.647816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 3230804.310195\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 3230808.823515\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115415.370859\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000195.826679\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_step 000004 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115031.235690\n",
      "now_datetime: 2017-10-02 00:20:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000004 [2017-10-02 00:20:00]\n",
      "   after: 000005 [2017-10-02 00:25:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115210.109404\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999997.856933\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115391.308829\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115210.109404\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999997.856933\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115391.308829\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 5.811091e+01\n",
      "Step 00125: model improved\n",
      "  from 5.764782e+01\n",
      "    to 5.811091e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.811091e+01_episode00096\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.811091e+01_episode00096 has done.\n",
      "max mean_q value: 5.811091e+01\n",
      "========== /Model Saver output =============\n",
      " 125/861: episode: 97, duration: 0.171s, episode steps: 5, steps per second: 29, episode reward: 9462193.096, mean reward: 1892438.619 [-115031.236, 3230808.824], mean action: 1.600 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 187505803264.000000, mean_q: 58.110912\n",
      " 125/861: episode: 97, duration: 0.171s, episode steps: 5, steps per second: 29, episode reward: 9462193.096, mean reward: 1892438.619 [-115031.236, 3230808.824], mean action: 1.600 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 187505803264.000000, mean_q: 58.110912\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 5.867035e+01\n",
      "Step 00128: model improved\n",
      "  from 5.811091e+01\n",
      "    to 5.867035e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.867035e+01_episode00097\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.867035e+01_episode00097 has done.\n",
      "max mean_q value: 5.867035e+01\n",
      "========== /Model Saver output =============\n",
      " 128/861: episode: 98, duration: 0.109s, episode steps: 3, steps per second: 28, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 290413543424.000000, mean_q: 58.670345\n",
      " 128/861: episode: 98, duration: 0.111s, episode steps: 3, steps per second: 27, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 290413543424.000000, mean_q: 58.670345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115210.109404\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999997.856933\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115391.308829\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115210.109404\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999997.856933\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 5.909130e+01\n",
      "Step 00131: model improved\n",
      "  from 5.867035e+01\n",
      "    to 5.909130e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.909130e+01_episode00098\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.909130e+01_episode00098 has done.\n",
      "max mean_q value: 5.909130e+01\n",
      "========== /Model Saver output =============\n",
      " 131/861: episode: 99, duration: 0.107s, episode steps: 3, steps per second: 28, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 277454946304.000000, mean_q: 59.091297\n",
      " 131/861: episode: 99, duration: 0.109s, episode steps: 3, steps per second: 27, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 277454946304.000000, mean_q: 59.091297\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 5.951100e+01\n",
      "Step 00134: model improved\n",
      "  from 5.909130e+01\n",
      "    to 5.951100e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.951100e+01_episode00099\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.951100e+01_episode00099 has done.\n",
      "max mean_q value: 5.951100e+01\n",
      "========== /Model Saver output =============\n",
      " 134/861: episode: 100, duration: 0.116s, episode steps: 3, steps per second: 26, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 241027710976.000000, mean_q: 59.511002\n",
      " 134/861: episode: 100, duration: 0.117s, episode steps: 3, steps per second: 26, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 241027710976.000000, mean_q: 59.511002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115391.308829\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115210.109404\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 3230413.335235\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115019.883339\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999800.338439\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_step 000004 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115426.723890\n",
      "now_datetime: 2017-10-02 00:20:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000004 [2017-10-02 00:20:00]\n",
      "   after: 000005 [2017-10-02 00:25:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.015216e+01\n",
      "Step 00137: model improved\n",
      "  from 5.951100e+01\n",
      "    to 6.015216e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.015216e+01_episode00100\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.015216e+01_episode00100 has done.\n",
      "max mean_q value: 6.015216e+01\n",
      "========== /Model Saver output =============\n",
      " 137/861: episode: 101, duration: 0.121s, episode steps: 3, steps per second: 25, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 316103852032.000000, mean_q: 60.152161\n",
      " 137/861: episode: 101, duration: 0.122s, episode steps: 3, steps per second: 25, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 316103852032.000000, mean_q: 60.152161\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.079180e+01\n",
      "Step 00142: model improved\n",
      "  from 6.015216e+01\n",
      "    to 6.079180e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.079180e+01_episode00101\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.079180e+01_episode00101 has done.\n",
      "max mean_q value: 6.079180e+01\n",
      "========== /Model Saver output =============\n",
      " 142/861: episode: 102, duration: 0.163s, episode steps: 5, steps per second: 31, episode reward: 8345016.943, mean reward: 1669003.389 [-115426.724, 3230413.335], mean action: 1.800 [1.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 359633190912.000000, mean_q: 60.791798\n",
      " 142/861: episode: 102, duration: 0.164s, episode steps: 5, steps per second: 31, episode reward: 8345016.943, mean reward: 1669003.389 [-115426.724, 3230413.335], mean action: 1.800 [1.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 359633190912.000000, mean_q: 60.791798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115210.109404\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999997.856933\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115391.308829\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115210.109404\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999997.856933\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000002.143827\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115215.369737\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.143285e+01\n",
      "Step 00145: model improved\n",
      "  from 6.079180e+01\n",
      "    to 6.143285e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.143285e+01_episode00102\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.143285e+01_episode00102 has done.\n",
      "max mean_q value: 6.143285e+01\n",
      "========== /Model Saver output =============\n",
      " 145/861: episode: 103, duration: 0.113s, episode steps: 3, steps per second: 27, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 266917953536.000000, mean_q: 61.432846\n",
      " 145/861: episode: 103, duration: 0.113s, episode steps: 3, steps per second: 26, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 266917953536.000000, mean_q: 61.432846\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.205228e+01\n",
      "Step 00149: model improved\n",
      "  from 6.143285e+01\n",
      "    to 6.205228e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.205228e+01_episode00103\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.205228e+01_episode00103 has done.\n",
      "max mean_q value: 6.205228e+01\n",
      "========== /Model Saver output =============\n",
      " 149/861: episode: 104, duration: 0.138s, episode steps: 4, steps per second: 29, episode reward: 3999994.740, mean reward: 999998.685 [-115215.370, 2115210.109], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 289004847104.000000, mean_q: 62.052284\n",
      " 149/861: episode: 104, duration: 0.140s, episode steps: 4, steps per second: 29, episode reward: 3999994.740, mean reward: 999998.685 [-115215.370, 2115210.109], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 289004847104.000000, mean_q: 62.052284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.253835e+01\n",
      "Step 00150: model improved\n",
      "  from 6.205228e+01\n",
      "    to 6.253835e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.253835e+01_episode00104\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.253835e+01_episode00104 has done.\n",
      "max mean_q value: 6.253835e+01\n",
      "========== /Model Saver output =============\n",
      " 150/861: episode: 105, duration: 0.071s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 579702423552.000000, mean_q: 62.538345\n",
      " 150/861: episode: 105, duration: 0.072s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 579702423552.000000, mean_q: 62.538345\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.286855e+01\n",
      "Step 00151: model improved\n",
      "  from 6.253835e+01\n",
      "    to 6.286855e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.286855e+01_episode00105\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.286855e+01_episode00105 has done.\n",
      "max mean_q value: 6.286855e+01\n",
      "========== /Model Saver output =============\n",
      " 151/861: episode: 106, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 664848302080.000000, mean_q: 62.868553\n",
      " 151/861: episode: 106, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 664848302080.000000, mean_q: 62.868553\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.319674e+01\n",
      "Step 00152: model improved\n",
      "  from 6.286855e+01\n",
      "    to 6.319674e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.319674e+01_episode00106\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.319674e+01_episode00106 has done.\n",
      "max mean_q value: 6.319674e+01\n",
      "========== /Model Saver output =============\n",
      " 152/861: episode: 107, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 440344248320.000000, mean_q: 63.196743\n",
      " 152/861: episode: 107, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 440344248320.000000, mean_q: 63.196743\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.353591e+01\n",
      "Step 00153: model improved\n",
      "  from 6.319674e+01\n",
      "    to 6.353591e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.353591e+01_episode00107\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.353591e+01_episode00107 has done.\n",
      "max mean_q value: 6.353591e+01\n",
      "========== /Model Saver output =============\n",
      " 153/861: episode: 108, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 548885889024.000000, mean_q: 63.535908\n",
      " 153/861: episode: 108, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 548885889024.000000, mean_q: 63.535908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.375993e+01\n",
      "Step 00154: model improved\n",
      "  from 6.353591e+01\n",
      "    to 6.375993e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.375993e+01_episode00108\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.375993e+01_episode00108 has done.\n",
      "max mean_q value: 6.375993e+01\n",
      "========== /Model Saver output =============\n",
      " 154/861: episode: 109, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 362557112320.000000, mean_q: 63.759933\n",
      " 154/861: episode: 109, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 362557112320.000000, mean_q: 63.759933\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.390266e+01\n",
      "Step 00155: model improved\n",
      "  from 6.375993e+01\n",
      "    to 6.390266e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.390266e+01_episode00109\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.390266e+01_episode00109 has done.\n",
      "max mean_q value: 6.390266e+01\n",
      "========== /Model Saver output =============\n",
      " 155/861: episode: 110, duration: 0.065s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 572351578112.000000, mean_q: 63.902664\n",
      " 155/861: episode: 110, duration: 0.066s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 572351578112.000000, mean_q: 63.902664\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.424794e+01\n",
      "Step 00156: model improved\n",
      "  from 6.390266e+01\n",
      "    to 6.424794e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.424794e+01_episode00110\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.424794e+01_episode00110 has done.\n",
      "max mean_q value: 6.424794e+01\n",
      "========== /Model Saver output =============\n",
      " 156/861: episode: 111, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 408812027904.000000, mean_q: 64.247940\n",
      " 156/861: episode: 111, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 408812027904.000000, mean_q: 64.247940\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.449301e+01\n",
      "Step 00157: model improved\n",
      "  from 6.424794e+01\n",
      "    to 6.449301e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.449301e+01_episode00111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.449301e+01_episode00111 has done.\n",
      "max mean_q value: 6.449301e+01\n",
      "========== /Model Saver output =============\n",
      " 157/861: episode: 112, duration: 0.057s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 277409693696.000000, mean_q: 64.493011\n",
      " 157/861: episode: 112, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 277409693696.000000, mean_q: 64.493011\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.486917e+01\n",
      "Step 00158: model improved\n",
      "  from 6.449301e+01\n",
      "    to 6.486917e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.486917e+01_episode00112\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.486917e+01_episode00112 has done.\n",
      "max mean_q value: 6.486917e+01\n",
      "========== /Model Saver output =============\n",
      " 158/861: episode: 113, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 525400834048.000000, mean_q: 64.869171\n",
      " 158/861: episode: 113, duration: 0.062s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 525400834048.000000, mean_q: 64.869171\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.514439e+01\n",
      "Step 00159: model improved\n",
      "  from 6.486917e+01\n",
      "    to 6.514439e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.514439e+01_episode00113\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.514439e+01_episode00113 has done.\n",
      "max mean_q value: 6.514439e+01\n",
      "========== /Model Saver output =============\n",
      " 159/861: episode: 114, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 323723198464.000000, mean_q: 65.144386\n",
      " 159/861: episode: 114, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 323723198464.000000, mean_q: 65.144386\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.545038e+01\n",
      "Step 00160: model improved\n",
      "  from 6.514439e+01\n",
      "    to 6.545038e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.545038e+01_episode00114\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.545038e+01_episode00114 has done.\n",
      "max mean_q value: 6.545038e+01\n",
      "========== /Model Saver output =============\n",
      " 160/861: episode: 115, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 401418485760.000000, mean_q: 65.450378\n",
      " 160/861: episode: 115, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 401418485760.000000, mean_q: 65.450378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.562999e+01\n",
      "Step 00161: model improved\n",
      "  from 6.545038e+01\n",
      "    to 6.562999e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.562999e+01_episode00115\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.562999e+01_episode00115 has done.\n",
      "max mean_q value: 6.562999e+01\n",
      "========== /Model Saver output =============\n",
      " 161/861: episode: 116, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 804253204480.000000, mean_q: 65.629990\n",
      " 161/861: episode: 116, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 804253204480.000000, mean_q: 65.629990\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.601778e+01\n",
      "Step 00162: model improved\n",
      "  from 6.562999e+01\n",
      "    to 6.601778e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.601778e+01_episode00116\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.601778e+01_episode00116 has done.\n",
      "max mean_q value: 6.601778e+01\n",
      "========== /Model Saver output =============\n",
      " 162/861: episode: 117, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 493912981504.000000, mean_q: 66.017784\n",
      " 162/861: episode: 117, duration: 0.057s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 493912981504.000000, mean_q: 66.017784\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.633187e+01\n",
      "Step 00163: model improved\n",
      "  from 6.601778e+01\n",
      "    to 6.633187e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.633187e+01_episode00117\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.633187e+01_episode00117 has done.\n",
      "max mean_q value: 6.633187e+01\n",
      "========== /Model Saver output =============\n",
      " 163/861: episode: 118, duration: 0.066s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238582988800.000000, mean_q: 66.331871\n",
      " 163/861: episode: 118, duration: 0.067s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238582988800.000000, mean_q: 66.331871\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.649621e+01\n",
      "Step 00164: model improved\n",
      "  from 6.633187e+01\n",
      "    to 6.649621e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.649621e+01_episode00118\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.649621e+01_episode00118 has done."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "max mean_q value: 6.649621e+01\n",
      "========== /Model Saver output =============\n",
      " 164/861: episode: 119, duration: 0.063s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 377959088128.000000, mean_q: 66.496208\n",
      " 164/861: episode: 119, duration: 0.065s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 377959088128.000000, mean_q: 66.496208\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.685916e+01\n",
      "Step 00165: model improved\n",
      "  from 6.649621e+01\n",
      "    to 6.685916e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.685916e+01_episode00119\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.685916e+01_episode00119 has done.\n",
      "max mean_q value: 6.685916e+01\n",
      "========== /Model Saver output =============\n",
      " 165/861: episode: 120, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207730049024.000000, mean_q: 66.859161\n",
      " 165/861: episode: 120, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207730049024.000000, mean_q: 66.859161\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.707757e+01\n",
      "Step 00166: model improved\n",
      "  from 6.685916e+01\n",
      "    to 6.707757e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.707757e+01_episode00120\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.707757e+01_episode00120 has done.\n",
      "max mean_q value: 6.707757e+01\n",
      "========== /Model Saver output =============\n",
      " 166/861: episode: 121, duration: 0.069s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207750037504.000000, mean_q: 67.077568\n",
      " 166/861: episode: 121, duration: 0.070s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207750037504.000000, mean_q: 67.077568\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.734657e+01\n",
      "Step 00167: model improved\n",
      "  from 6.707757e+01\n",
      "    to 6.734657e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.734657e+01_episode00121\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.734657e+01_episode00121 has done.\n",
      "max mean_q value: 6.734657e+01\n",
      "========== /Model Saver output =============\n",
      " 167/861: episode: 122, duration: 0.057s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 308244250624.000000, mean_q: 67.346565\n",
      " 167/861: episode: 122, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 308244250624.000000, mean_q: 67.346565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.759195e+01\n",
      "Step 00168: model improved\n",
      "  from 6.734657e+01\n",
      "    to 6.759195e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.759195e+01_episode00122\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.759195e+01_episode00122 has done.\n",
      "max mean_q value: 6.759195e+01\n",
      "========== /Model Saver output =============\n",
      " 168/861: episode: 123, duration: 0.062s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 664860557312.000000, mean_q: 67.591949\n",
      " 168/861: episode: 123, duration: 0.063s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 664860557312.000000, mean_q: 67.591949\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.776732e+01\n",
      "Step 00169: model improved\n",
      "  from 6.759195e+01\n",
      "    to 6.776732e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.776732e+01_episode00123\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.776732e+01_episode00123 has done.\n",
      "max mean_q value: 6.776732e+01\n",
      "========== /Model Saver output =============\n",
      " 169/861: episode: 124, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 525471121408.000000, mean_q: 67.767319\n",
      " 169/861: episode: 124, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 525471121408.000000, mean_q: 67.767319\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.802083e+01\n",
      "Step 00170: model improved\n",
      "  from 6.776732e+01\n",
      "    to 6.802083e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.802083e+01_episode00124\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.802083e+01_episode00124 has done.\n",
      "max mean_q value: 6.802083e+01\n",
      "========== /Model Saver output =============\n",
      " 170/861: episode: 125, duration: 0.062s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 331745853440.000000, mean_q: 68.020828\n",
      " 170/861: episode: 125, duration: 0.063s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 331745853440.000000, mean_q: 68.020828\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.817994e+01\n",
      "Step 00171: model improved\n",
      "  from 6.802083e+01\n",
      "    to 6.817994e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.817994e+01_episode00125\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.817994e+01_episode00125 has done.\n",
      "max mean_q value: 6.817994e+01\n",
      "========== /Model Saver output =============\n",
      " 171/861: episode: 126, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 323674570752.000000, mean_q: 68.179939\n",
      " 171/861: episode: 126, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 323674570752.000000, mean_q: 68.179939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.846835e+01\n",
      "Step 00172: model improved\n",
      "  from 6.817994e+01\n",
      "    to 6.846835e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.846835e+01_episode00126\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.846835e+01_episode00126 has done.\n",
      "max mean_q value: 6.846835e+01\n",
      "========== /Model Saver output =============\n",
      " 172/861: episode: 127, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 323702816768.000000, mean_q: 68.468346\n",
      " 172/861: episode: 127, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 323702816768.000000, mean_q: 68.468346\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.875215e+01\n",
      "Step 00173: model improved\n",
      "  from 6.846835e+01\n",
      "    to 6.875215e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.875215e+01_episode00127\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.875215e+01_episode00127 has done.\n",
      "max mean_q value: 6.875215e+01\n",
      "========== /Model Saver output =============\n",
      " 173/861: episode: 128, duration: 0.065s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 168858435584.000000, mean_q: 68.752151\n",
      " 173/861: episode: 128, duration: 0.066s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 168858435584.000000, mean_q: 68.752151\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.886790e+01\n",
      "Step 00174: model improved\n",
      "  from 6.875215e+01\n",
      "    to 6.886790e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.886790e+01_episode00128\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.886790e+01_episode00128 has done.\n",
      "max mean_q value: 6.886790e+01\n",
      "========== /Model Saver output =============\n",
      " 174/861: episode: 129, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 362542858240.000000, mean_q: 68.867905\n",
      " 174/861: episode: 129, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 362542858240.000000, mean_q: 68.867905\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.913611e+01\n",
      "Step 00175: model improved\n",
      "  from 6.886790e+01\n",
      "    to 6.913611e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.913611e+01_episode00129\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.913611e+01_episode00129 has done.\n",
      "max mean_q value: 6.913611e+01\n",
      "========== /Model Saver output =============\n",
      " 175/861: episode: 130, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238561574912.000000, mean_q: 69.136108\n",
      " 175/861: episode: 130, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238561574912.000000, mean_q: 69.136108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.937350e+01\n",
      "Step 00176: model improved\n",
      "  from 6.913611e+01\n",
      "    to 6.937350e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.937350e+01_episode00130\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.937350e+01_episode00130 has done.\n",
      "max mean_q value: 6.937350e+01\n",
      "========== /Model Saver output =============\n",
      " 176/861: episode: 131, duration: 0.066s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 269415530496.000000, mean_q: 69.373505\n",
      " 176/861: episode: 131, duration: 0.067s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 269415530496.000000, mean_q: 69.373505\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.951754e+01\n",
      "Step 00177: model improved\n",
      "  from 6.937350e+01\n",
      "    to 6.951754e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.951754e+01_episode00131\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.951754e+01_episode00131 has done.\n",
      "max mean_q value: 6.951754e+01\n",
      "========== /Model Saver output =============\n",
      " 177/861: episode: 132, duration: 0.054s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 354456829952.000000, mean_q: 69.517540\n",
      " 177/861: episode: 132, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 354456829952.000000, mean_q: 69.517540\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.984207e+01\n",
      "Step 00178: model improved\n",
      "  from 6.951754e+01\n",
      "    to 6.984207e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.984207e+01_episode00132\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.984207e+01_episode00132 has done.\n",
      "max mean_q value: 6.984207e+01\n",
      "========== /Model Saver output =============\n",
      " 178/861: episode: 133, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 292850106368.000000, mean_q: 69.842072\n",
      " 178/861: episode: 133, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 292850106368.000000, mean_q: 69.842072\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.003867e+01\n",
      "Step 00179: model improved\n",
      "  from 6.984207e+01\n",
      "    to 7.003867e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.003867e+01_episode00133\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.003867e+01_episode00133 has done.\n",
      "max mean_q value: 7.003867e+01\n",
      "========== /Model Saver output =============\n",
      " 179/861: episode: 134, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 618640113664.000000, mean_q: 70.038673\n",
      " 179/861: episode: 134, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 618640113664.000000, mean_q: 70.038673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.034180e+01\n",
      "Step 00180: model improved\n",
      "  from 7.003867e+01\n",
      "    to 7.034180e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.034180e+01_episode00134\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.034180e+01_episode00134 has done.\n",
      "max mean_q value: 7.034180e+01\n",
      "========== /Model Saver output =============\n",
      " 180/861: episode: 135, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 253974167552.000000, mean_q: 70.341797\n",
      " 180/861: episode: 135, duration: 0.057s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 253974167552.000000, mean_q: 70.341797\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.057616e+01\n",
      "Step 00181: model improved\n",
      "  from 7.034180e+01\n",
      "    to 7.057616e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.057616e+01_episode00135\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.057616e+01_episode00135 has done.\n",
      "max mean_q value: 7.057616e+01\n",
      "========== /Model Saver output =============\n",
      " 181/861: episode: 136, duration: 0.057s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 501952643072.000000, mean_q: 70.576157\n",
      " 181/861: episode: 136, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 501952643072.000000, mean_q: 70.576157\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.080647e+01\n",
      "Step 00182: model improved\n",
      "  from 7.057616e+01\n",
      "    to 7.080647e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.080647e+01_episode00136\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.080647e+01_episode00136 has done.\n",
      "max mean_q value: 7.080647e+01\n",
      "========== /Model Saver output =============\n",
      " 182/861: episode: 137, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207746203648.000000, mean_q: 70.806473\n",
      " 182/861: episode: 137, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207746203648.000000, mean_q: 70.806473\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.104128e+01\n",
      "Step 00183: model improved\n",
      "  from 7.080647e+01\n",
      "    to 7.104128e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.104128e+01_episode00137\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.104128e+01_episode00137 has done.\n",
      "max mean_q value: 7.104128e+01\n",
      "========== /Model Saver output =============\n",
      " 183/861: episode: 138, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 494596718592.000000, mean_q: 71.041275\n",
      " 183/861: episode: 138, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 494596718592.000000, mean_q: 71.041275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.128209e+01\n",
      "Step 00184: model improved\n",
      "  from 7.104128e+01\n",
      "    to 7.128209e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.128209e+01_episode00138\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.128209e+01_episode00138 has done.\n",
      "max mean_q value: 7.128209e+01\n",
      "========== /Model Saver output =============\n",
      " 184/861: episode: 139, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 122606485504.000000, mean_q: 71.282089\n",
      " 184/861: episode: 139, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 122606485504.000000, mean_q: 71.282089\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.156934e+01\n",
      "Step 00185: model improved\n",
      "  from 7.128209e+01\n",
      "    to 7.156934e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.156934e+01_episode00139\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.156934e+01_episode00139 has done.\n",
      "max mean_q value: 7.156934e+01\n",
      "========== /Model Saver output =============\n",
      " 185/861: episode: 140, duration: 0.062s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 362558324736.000000, mean_q: 71.569344\n",
      " 185/861: episode: 140, duration: 0.063s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 362558324736.000000, mean_q: 71.569344\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.176254e+01\n",
      "Step 00186: model improved\n",
      "  from 7.156934e+01\n",
      "    to 7.176254e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.176254e+01_episode00140\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.176254e+01_episode00140 has done.\n",
      "max mean_q value: 7.176254e+01\n",
      "========== /Model Saver output =============\n",
      " 186/861: episode: 141, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 153445187584.000000, mean_q: 71.762535\n",
      " 186/861: episode: 141, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 153445187584.000000, mean_q: 71.762535\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.199341e+01\n",
      "Step 00187: model improved\n",
      "  from 7.176254e+01\n",
      "    to 7.199341e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.199341e+01_episode00141\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.199341e+01_episode00141 has done.\n",
      "max mean_q value: 7.199341e+01\n",
      "========== /Model Saver output =============\n",
      " 187/861: episode: 142, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 494623293440.000000, mean_q: 71.993408\n",
      " 187/861: episode: 142, duration: 0.054s, episode steps: 1, steps per second: 19, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 494623293440.000000, mean_q: 71.993408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.220738e+01\n",
      "Step 00188: model improved\n",
      "  from 7.199341e+01\n",
      "    to 7.220738e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.220738e+01_episode00142\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.220738e+01_episode00142 has done.\n",
      "max mean_q value: 7.220738e+01\n",
      "========== /Model Saver output =============\n",
      " 188/861: episode: 143, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 231173079040.000000, mean_q: 72.207382\n",
      " 188/861: episode: 143, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 231173079040.000000, mean_q: 72.207382\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.235223e+01\n",
      "Step 00189: model improved\n",
      "  from 7.220738e+01\n",
      "    to 7.235223e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.235223e+01_episode00143\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.235223e+01_episode00143 has done.\n",
      "max mean_q value: 7.235223e+01\n",
      "========== /Model Saver output =============\n",
      " 189/861: episode: 144, duration: 0.057s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 331730190336.000000, mean_q: 72.352234\n",
      " 189/861: episode: 144, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 331730190336.000000, mean_q: 72.352234\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.256085e+01\n",
      "Step 00190: model improved\n",
      "  from 7.235223e+01\n",
      "    to 7.256085e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.256085e+01_episode00144\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.256085e+01_episode00144 has done.\n",
      "max mean_q value: 7.256085e+01\n",
      "========== /Model Saver output =============\n",
      " 190/861: episode: 145, duration: 0.054s, episode steps: 1, steps per second: 19, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 416892059648.000000, mean_q: 72.560852\n",
      " 190/861: episode: 145, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 416892059648.000000, mean_q: 72.560852\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.264526e+01\n",
      "Step 00191: model improved\n",
      "  from 7.256085e+01\n",
      "    to 7.264526e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.264526e+01_episode00145\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.264526e+01_episode00145 has done.\n",
      "max mean_q value: 7.264526e+01\n",
      "========== /Model Saver output =============\n",
      " 191/861: episode: 146, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 540848357376.000000, mean_q: 72.645264\n",
      " 191/861: episode: 146, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 540848357376.000000, mean_q: 72.645264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.298027e+01\n",
      "Step 00192: model improved\n",
      "  from 7.264526e+01\n",
      "    to 7.298027e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.298027e+01_episode00146\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.298027e+01_episode00146 has done.\n",
      "max mean_q value: 7.298027e+01\n",
      "========== /Model Saver output =============\n",
      " 192/861: episode: 147, duration: 0.049s, episode steps: 1, steps per second: 20, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 253932109824.000000, mean_q: 72.980270\n",
      " 192/861: episode: 147, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 253932109824.000000, mean_q: 72.980270\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.304012e+01\n",
      "Step 00193: model improved\n",
      "  from 7.298027e+01\n",
      "    to 7.304012e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.304012e+01_episode00147\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.304012e+01_episode00147 has done.\n",
      "max mean_q value: 7.304012e+01\n",
      "========== /Model Saver output =============\n",
      " 193/861: episode: 148, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 168899805184.000000, mean_q: 73.040123\n",
      " 193/861: episode: 148, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 168899805184.000000, mean_q: 73.040123\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.325912e+01\n",
      "Step 00194: model improved\n",
      "  from 7.304012e+01\n",
      "    to 7.325912e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.325912e+01_episode00148\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.325912e+01_episode00148 has done.\n",
      "max mean_q value: 7.325912e+01\n",
      "========== /Model Saver output =============\n",
      " 194/861: episode: 149, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238557364224.000000, mean_q: 73.259125\n",
      " 194/861: episode: 149, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238557364224.000000, mean_q: 73.259125\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.339457e+01\n",
      "Step 00195: model improved\n",
      "  from 7.325912e+01\n",
      "    to 7.339457e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.339457e+01_episode00149\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.339457e+01_episode00149 has done.\n",
      "max mean_q value: 7.339457e+01\n",
      "========== /Model Saver output =============\n",
      " 195/861: episode: 150, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 525381533696.000000, mean_q: 73.394569\n",
      " 195/861: episode: 150, duration: 0.057s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 525381533696.000000, mean_q: 73.394569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.363832e+01\n",
      "Step 00196: model improved\n",
      "  from 7.339457e+01\n",
      "    to 7.363832e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.363832e+01_episode00150\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.363832e+01_episode00150 has done.\n",
      "max mean_q value: 7.363832e+01\n",
      "========== /Model Saver output =============\n",
      " 196/861: episode: 151, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 401491165184.000000, mean_q: 73.638321\n",
      " 196/861: episode: 151, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 401491165184.000000, mean_q: 73.638321\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.387891e+01\n",
      "Step 00197: model improved\n",
      "  from 7.363832e+01\n",
      "    to 7.387891e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.387891e+01_episode00151\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.387891e+01_episode00151 has done.\n",
      "max mean_q value: 7.387891e+01\n",
      "========== /Model Saver output =============\n",
      " 197/861: episode: 152, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 494652620800.000000, mean_q: 73.878906\n",
      " 197/861: episode: 152, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 494652620800.000000, mean_q: 73.878906\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.403047e+01\n",
      "Step 00198: model improved\n",
      "  from 7.387891e+01\n",
      "    to 7.403047e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.403047e+01_episode00152\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.403047e+01_episode00152 has done.\n",
      "max mean_q value: 7.403047e+01\n",
      "========== /Model Saver output =============\n",
      " 198/861: episode: 153, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 231174291456.000000, mean_q: 74.030472\n",
      " 198/861: episode: 153, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 231174291456.000000, mean_q: 74.030472\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.423793e+01\n",
      "Step 00199: model improved\n",
      "  from 7.403047e+01\n",
      "    to 7.423793e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.423793e+01_episode00153\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.423793e+01_episode00153 has done.\n",
      "max mean_q value: 7.423793e+01\n",
      "========== /Model Saver output =============\n",
      " 199/861: episode: 154, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 107217731584.000000, mean_q: 74.237930\n",
      " 199/861: episode: 154, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 107217731584.000000, mean_q: 74.237930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.433198e+01\n",
      "Step 00200: model improved\n",
      "  from 7.423793e+01\n",
      "    to 7.433198e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.433198e+01_episode00154\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.433198e+01_episode00154 has done.\n",
      "max mean_q value: 7.433198e+01\n",
      "========== /Model Saver output =============\n",
      " 200/861: episode: 155, duration: 0.049s, episode steps: 1, steps per second: 20, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 408827756544.000000, mean_q: 74.331978\n",
      " 200/861: episode: 155, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 408827756544.000000, mean_q: 74.331978\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.457745e+01\n",
      "Step 00201: model improved\n",
      "  from 7.433198e+01\n",
      "    to 7.457745e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.457745e+01_episode00155\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.457745e+01_episode00155 has done.\n",
      "max mean_q value: 7.457745e+01\n",
      "========== /Model Saver output =============\n",
      " 201/861: episode: 156, duration: 0.054s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 122594279424.000000, mean_q: 74.577454\n",
      " 201/861: episode: 156, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 122594279424.000000, mean_q: 74.577454\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.470733e+01\n",
      "Step 00202: model improved\n",
      "  from 7.457745e+01\n",
      "    to 7.470733e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.470733e+01_episode00156\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.470733e+01_episode00156 has done.\n",
      "max mean_q value: 7.470733e+01\n",
      "========== /Model Saver output =============\n",
      " 202/861: episode: 157, duration: 0.065s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 277395210240.000000, mean_q: 74.707329\n",
      " 202/861: episode: 157, duration: 0.066s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 277395210240.000000, mean_q: 74.707329\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.488405e+01\n",
      "Step 00203: model improved\n",
      "  from 7.470733e+01\n",
      "    to 7.488405e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.488405e+01_episode00157\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.488405e+01_episode00157 has done.\n",
      "max mean_q value: 7.488405e+01\n",
      "========== /Model Saver output =============\n",
      " 203/861: episode: 158, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 331688804352.000000, mean_q: 74.884048\n",
      " 203/861: episode: 158, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 331688804352.000000, mean_q: 74.884048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000002.143827\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000002.143827\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.495419e+01\n",
      "Step 00204: model improved\n",
      "  from 7.488405e+01\n",
      "    to 7.495419e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.495419e+01_episode00158\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.495419e+01_episode00158 has done.\n",
      "max mean_q value: 7.495419e+01\n",
      "========== /Model Saver output =============\n",
      " 204/861: episode: 159, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 277462024192.000000, mean_q: 74.954185\n",
      " 204/861: episode: 159, duration: 0.057s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 277462024192.000000, mean_q: 74.954185\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.521895e+01\n",
      "Step 00206: model improved\n",
      "  from 7.495419e+01\n",
      "    to 7.521895e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.521895e+01_episode00159\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.521895e+01_episode00159 has done.\n",
      "max mean_q value: 7.521895e+01\n",
      "========== /Model Saver output =============\n",
      " 206/861: episode: 160, duration: 0.081s, episode steps: 2, steps per second: 25, episode reward: 884796.549, mean reward: 442398.274 [-115205.595, 1000002.144], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 261683970048.000000, mean_q: 75.218948\n",
      " 206/861: episode: 160, duration: 0.083s, episode steps: 2, steps per second: 24, episode reward: 884796.549, mean reward: 442398.274 [-115205.595, 1000002.144], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 261683970048.000000, mean_q: 75.218948\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.545744e+01\n",
      "Step 00208: model improved\n",
      "  from 7.521895e+01\n",
      "    to 7.545744e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.545744e+01_episode00160\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.545744e+01_episode00160 has done.\n",
      "max mean_q value: 7.545744e+01\n",
      "========== /Model Saver output =============\n",
      " 208/861: episode: 161, duration: 0.084s, episode steps: 2, steps per second: 24, episode reward: 884796.549, mean reward: 442398.274 [-115205.595, 1000002.144], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 308267286528.000000, mean_q: 75.457436\n",
      " 208/861: episode: 161, duration: 0.085s, episode steps: 2, steps per second: 23, episode reward: 884796.549, mean reward: 442398.274 [-115205.595, 1000002.144], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 308267286528.000000, mean_q: 75.457436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.568047e+01\n",
      "Step 00209: model improved\n",
      "  from 7.545744e+01\n",
      "    to 7.568047e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.568047e+01_episode00161\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.568047e+01_episode00161 has done.\n",
      "max mean_q value: 7.568047e+01\n",
      "========== /Model Saver output =============\n",
      " 209/861: episode: 162, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 518092914688.000000, mean_q: 75.680466\n",
      " 209/861: episode: 162, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 518092914688.000000, mean_q: 75.680466\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.587459e+01\n",
      "Step 00210: model improved\n",
      "  from 7.568047e+01\n",
      "    to 7.587459e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.587459e+01_episode00162\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.587459e+01_episode00162 has done.\n",
      "max mean_q value: 7.587459e+01\n",
      "========== /Model Saver output =============\n",
      " 210/861: episode: 163, duration: 0.068s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 269373145088.000000, mean_q: 75.874588\n",
      " 210/861: episode: 163, duration: 0.070s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 269373145088.000000, mean_q: 75.874588\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.605444e+01\n",
      "Step 00211: model improved\n",
      "  from 7.587459e+01\n",
      "    to 7.605444e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.605444e+01_episode00163\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.605444e+01_episode00163 has done.\n",
      "max mean_q value: 7.605444e+01\n",
      "========== /Model Saver output =============\n",
      " 211/861: episode: 164, duration: 0.054s, episode steps: 1, steps per second: 19, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 424903704576.000000, mean_q: 76.054443\n",
      " 211/861: episode: 164, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 424903704576.000000, mean_q: 76.054443\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.624197e+01\n",
      "Step 00212: model improved\n",
      "  from 7.605444e+01\n",
      "    to 7.624197e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.624197e+01_episode00164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115600.857938\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115605.371258\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000211.918602\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115007.625578\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.624197e+01_episode00164 has done.\n",
      "max mean_q value: 7.624197e+01\n",
      "========== /Model Saver output =============\n",
      " 212/861: episode: 165, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 331659378688.000000, mean_q: 76.241966\n",
      " 212/861: episode: 165, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 331659378688.000000, mean_q: 76.241966\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.654352e+01\n",
      "Step 00216: model improved\n",
      "  from 7.624197e+01\n",
      "    to 7.654352e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.654352e+01_episode00165\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.654352e+01_episode00165 has done.\n",
      "max mean_q value: 7.654352e+01\n",
      "========== /Model Saver output =============\n",
      " 216/861: episode: 166, duration: 0.141s, episode steps: 4, steps per second: 28, episode reward: 5116410.522, mean reward: 1279102.631 [-115007.626, 2115605.371], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 235071078400.000000, mean_q: 76.543518\n",
      " 216/861: episode: 166, duration: 0.143s, episode steps: 4, steps per second: 28, episode reward: 5116410.522, mean reward: 1279102.631 [-115007.626, 2115605.371], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 235071078400.000000, mean_q: 76.543518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000002.143827\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115391.308829\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.684107e+01\n",
      "Step 00218: model improved\n",
      "  from 7.654352e+01\n",
      "    to 7.684107e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.684107e+01_episode00166\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.684107e+01_episode00166 has done.\n",
      "max mean_q value: 7.684107e+01\n",
      "========== /Model Saver output =============\n",
      " 218/861: episode: 167, duration: 0.096s, episode steps: 2, steps per second: 21, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 506018136064.000000, mean_q: 76.841072\n",
      " 218/861: episode: 167, duration: 0.097s, episode steps: 2, steps per second: 21, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 506018136064.000000, mean_q: 76.841072\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.719550e+01\n",
      "Step 00221: model improved\n",
      "  from 7.684107e+01\n",
      "    to 7.719550e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.719550e+01_episode00167\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.719550e+01_episode00167 has done.\n",
      "max mean_q value: 7.719550e+01\n",
      "========== /Model Saver output =============\n",
      " 221/861: episode: 168, duration: 0.100s, episode steps: 3, steps per second: 30, episode reward: 1884617.492, mean reward: 628205.831 [-115391.309, 1000006.657], mean action: 1.333 [0.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 300902678528.000000, mean_q: 77.195503\n",
      " 221/861: episode: 168, duration: 0.101s, episode steps: 3, steps per second: 30, episode reward: 1884617.492, mean reward: 628205.831 [-115391.309, 1000006.657], mean action: 1.333 [0.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 300902678528.000000, mean_q: 77.195503\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.740874e+01\n",
      "Step 00222: model improved\n",
      "  from 7.719550e+01\n",
      "    to 7.740874e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.740874e+01_episode00168\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.740874e+01_episode00168 has done.\n",
      "max mean_q value: 7.740874e+01\n",
      "========== /Model Saver output =============\n",
      " 222/861: episode: 169, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 277454159872.000000, mean_q: 77.408745\n",
      " 222/861: episode: 169, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 277454159872.000000, mean_q: 77.408745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.750723e+01\n",
      "Step 00223: model improved\n",
      "  from 7.740874e+01\n",
      "    to 7.750723e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.750723e+01_episode00169\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.750723e+01_episode00169 has done.\n",
      "max mean_q value: 7.750723e+01\n",
      "========== /Model Saver output =============\n",
      " 223/861: episode: 170, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 471166287872.000000, mean_q: 77.507225\n",
      " 223/861: episode: 170, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 471166287872.000000, mean_q: 77.507225\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.771619e+01\n",
      "Step 00224: model improved\n",
      "  from 7.750723e+01\n",
      "    to 7.771619e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.771619e+01_episode00170\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.771619e+01_episode00170 has done.\n",
      "max mean_q value: 7.771619e+01\n",
      "========== /Model Saver output =============\n",
      " 224/861: episode: 171, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 300973064192.000000, mean_q: 77.716187\n",
      " 224/861: episode: 171, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 300973064192.000000, mean_q: 77.716187\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.789220e+01\n",
      "Step 00225: model improved\n",
      "  from 7.771619e+01\n",
      "    to 7.789220e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.789220e+01_episode00171\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.789220e+01_episode00171 has done.\n",
      "max mean_q value: 7.789220e+01\n",
      "========== /Model Saver output =============\n",
      " 225/861: episode: 172, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 269410861056.000000, mean_q: 77.892197\n",
      " 225/861: episode: 172, duration: 0.054s, episode steps: 1, steps per second: 18, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 269410861056.000000, mean_q: 77.892197\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.806179e+01\n",
      "Step 00226: model improved\n",
      "  from 7.789220e+01\n",
      "    to 7.806179e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.806179e+01_episode00172\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.806179e+01_episode00172 has done.\n",
      "max mean_q value: 7.806179e+01\n",
      "========== /Model Saver output =============\n",
      " 226/861: episode: 173, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 455747436544.000000, mean_q: 78.061790\n",
      " 226/861: episode: 173, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 455747436544.000000, mean_q: 78.061790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115600.857938\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115605.371258\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000211.918602\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115007.625578\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.819745e+01\n",
      "Step 00227: model improved\n",
      "  from 7.806179e+01\n",
      "    to 7.819745e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.819745e+01_episode00173\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.819745e+01_episode00173 has done.\n",
      "max mean_q value: 7.819745e+01\n",
      "========== /Model Saver output =============\n",
      " 227/861: episode: 174, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 153465094144.000000, mean_q: 78.197449\n",
      " 227/861: episode: 174, duration: 0.054s, episode steps: 1, steps per second: 19, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 153465094144.000000, mean_q: 78.197449\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.846362e+01\n",
      "Step 00231: model improved\n",
      "  from 7.819745e+01\n",
      "    to 7.846362e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.846362e+01_episode00174\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.846362e+01_episode00174 has done.\n",
      "max mean_q value: 7.846362e+01\n",
      "========== /Model Saver output =============\n",
      " 231/861: episode: 175, duration: 0.133s, episode steps: 4, steps per second: 30, episode reward: 5116410.522, mean reward: 1279102.631 [-115007.626, 2115605.371], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 347328151552.000000, mean_q: 78.463623\n",
      " 231/861: episode: 175, duration: 0.134s, episode steps: 4, steps per second: 30, episode reward: 5116410.522, mean reward: 1279102.631 [-115007.626, 2115605.371], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 347328151552.000000, mean_q: 78.463623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.875285e+01\n",
      "Step 00233: model improved\n",
      "  from 7.846362e+01\n",
      "    to 7.875285e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.875285e+01_episode00175\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.875285e+01_episode00175 has done.\n",
      "max mean_q value: 7.875285e+01\n",
      "========== /Model Saver output =============\n",
      " 233/861: episode: 176, duration: 0.074s, episode steps: 2, steps per second: 27, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 312329633792.000000, mean_q: 78.752846\n",
      " 233/861: episode: 176, duration: 0.076s, episode steps: 2, steps per second: 26, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 312329633792.000000, mean_q: 78.752846\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.902068e+01\n",
      "Step 00235: model improved\n",
      "  from 7.875285e+01\n",
      "    to 7.902068e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.902068e+01_episode00176\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.902068e+01_episode00176 has done.\n",
      "max mean_q value: 7.902068e+01\n",
      "========== /Model Saver output =============\n",
      " 235/861: episode: 177, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 327740882944.000000, mean_q: 79.020676\n",
      " 235/861: episode: 177, duration: 0.079s, episode steps: 2, steps per second: 25, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 327740882944.000000, mean_q: 79.020676\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.926279e+01\n",
      "Step 00237: model improved\n",
      "  from 7.902068e+01\n",
      "    to 7.926279e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.926279e+01_episode00177\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.926279e+01_episode00177 has done.\n",
      "max mean_q value: 7.926279e+01\n",
      "========== /Model Saver output =============\n",
      " 237/861: episode: 178, duration: 0.083s, episode steps: 2, steps per second: 24, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 467136479232.000000, mean_q: 79.262794\n",
      " 237/861: episode: 178, duration: 0.089s, episode steps: 2, steps per second: 22, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 467136479232.000000, mean_q: 79.262794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.966446e+01\n",
      "Step 00239: model improved\n",
      "  from 7.926279e+01\n",
      "    to 7.966446e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.966446e+01_episode00178\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.966446e+01_episode00178 has done.\n",
      "max mean_q value: 7.966446e+01\n",
      "========== /Model Saver output =============\n",
      " 239/861: episode: 179, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 258026717184.000000, mean_q: 79.664459\n",
      " 239/861: episode: 179, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 258026717184.000000, mean_q: 79.664459\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.002950e+01\n",
      "Step 00241: model improved\n",
      "  from 7.966446e+01\n",
      "    to 8.002950e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.002950e+01_episode00179\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.002950e+01_episode00179 has done.\n",
      "max mean_q value: 8.002950e+01\n",
      "========== /Model Saver output =============\n",
      " 241/861: episode: 180, duration: 0.081s, episode steps: 2, steps per second: 25, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 296568684544.000000, mean_q: 80.029503\n",
      " 241/861: episode: 180, duration: 0.082s, episode steps: 2, steps per second: 24, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 296568684544.000000, mean_q: 80.029503\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.042519e+01\n",
      "Step 00243: model improved\n",
      "  from 8.002950e+01\n",
      "    to 8.042519e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.042519e+01_episode00180\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.042519e+01_episode00180 has done.\n",
      "max mean_q value: 8.042519e+01\n",
      "========== /Model Saver output =============\n",
      " 243/861: episode: 181, duration: 0.082s, episode steps: 2, steps per second: 24, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 343459463168.000000, mean_q: 80.425194\n",
      " 243/861: episode: 181, duration: 0.083s, episode steps: 2, steps per second: 24, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 343459463168.000000, mean_q: 80.425194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.080588e+01\n",
      "Step 00245: model improved\n",
      "  from 8.042519e+01\n",
      "    to 8.080588e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.080588e+01_episode00181\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.080588e+01_episode00181 has done.\n",
      "max mean_q value: 8.080588e+01\n",
      "========== /Model Saver output =============\n",
      " 245/861: episode: 182, duration: 0.082s, episode steps: 2, steps per second: 24, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 262034325504.000000, mean_q: 80.805878\n",
      " 245/861: episode: 182, duration: 0.083s, episode steps: 2, steps per second: 24, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 262034325504.000000, mean_q: 80.805878\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.115170e+01\n",
      "Step 00247: model improved\n",
      "  from 8.080588e+01\n",
      "    to 8.115170e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.115170e+01_episode00182\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.115170e+01_episode00182 has done.\n",
      "max mean_q value: 8.115170e+01\n",
      "========== /Model Saver output =============\n",
      " 247/861: episode: 183, duration: 0.080s, episode steps: 2, steps per second: 25, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 238600847360.000000, mean_q: 81.151703\n",
      " 247/861: episode: 183, duration: 0.081s, episode steps: 2, steps per second: 25, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 238600847360.000000, mean_q: 81.151703\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.144689e+01\n",
      "Step 00249: model improved\n",
      "  from 8.115170e+01\n",
      "    to 8.144689e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.144689e+01_episode00183\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.144689e+01_episode00183 has done.\n",
      "max mean_q value: 8.144689e+01\n",
      "========== /Model Saver output =============\n",
      " 249/861: episode: 184, duration: 0.068s, episode steps: 2, steps per second: 29, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 506039369728.000000, mean_q: 81.446892\n",
      " 249/861: episode: 184, duration: 0.069s, episode steps: 2, steps per second: 29, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 506039369728.000000, mean_q: 81.446892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.172611e+01\n",
      "Step 00251: model improved\n",
      "  from 8.144689e+01\n",
      "    to 8.172611e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.172611e+01_episode00184\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.172611e+01_episode00184 has done.\n",
      "max mean_q value: 8.172611e+01\n",
      "========== /Model Saver output =============\n",
      " 251/861: episode: 185, duration: 0.081s, episode steps: 2, steps per second: 25, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 122643587072.000000, mean_q: 81.726112\n",
      " 251/861: episode: 185, duration: 0.082s, episode steps: 2, steps per second: 24, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 122643587072.000000, mean_q: 81.726112\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.200652e+01\n",
      "Step 00253: model improved\n",
      "  from 8.172611e+01\n",
      "    to 8.200652e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.200652e+01_episode00185\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.200652e+01_episode00185 has done.\n",
      "max mean_q value: 8.200652e+01\n",
      "========== /Model Saver output =============\n",
      " 253/861: episode: 186, duration: 0.085s, episode steps: 2, steps per second: 23, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 513715044352.000000, mean_q: 82.006516\n",
      " 253/861: episode: 186, duration: 0.087s, episode steps: 2, steps per second: 23, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 513715044352.000000, mean_q: 82.006516\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.228333e+01\n",
      "Step 00255: model improved\n",
      "  from 8.200652e+01\n",
      "    to 8.228333e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.228333e+01_episode00186\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.228333e+01_episode00186 has done.\n",
      "max mean_q value: 8.228333e+01\n",
      "========== /Model Saver output =============\n",
      " 255/861: episode: 187, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 300580470784.000000, mean_q: 82.283325\n",
      " 255/861: episode: 187, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 300580470784.000000, mean_q: 82.283325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.258978e+01\n",
      "Step 00257: model improved\n",
      "  from 8.228333e+01\n",
      "    to 8.258978e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.258978e+01_episode00187\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.258978e+01_episode00187 has done.\n",
      "max mean_q value: 8.258978e+01\n",
      "========== /Model Saver output =============\n",
      " 257/861: episode: 188, duration: 0.075s, episode steps: 2, steps per second: 27, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 343472865280.000000, mean_q: 82.589783\n",
      " 257/861: episode: 188, duration: 0.076s, episode steps: 2, steps per second: 26, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 343472865280.000000, mean_q: 82.589783\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.290869e+01\n",
      "Step 00259: model improved\n",
      "  from 8.258978e+01\n",
      "    to 8.290869e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.290869e+01_episode00188\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.290869e+01_episode00188 has done.\n",
      "max mean_q value: 8.290869e+01\n",
      "========== /Model Saver output =============\n",
      " 259/861: episode: 189, duration: 0.073s, episode steps: 2, steps per second: 28, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 281146425344.000000, mean_q: 82.908691\n",
      " 259/861: episode: 189, duration: 0.073s, episode steps: 2, steps per second: 27, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 281146425344.000000, mean_q: 82.908691\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.320514e+01\n",
      "Step 00261: model improved\n",
      "  from 8.290869e+01\n",
      "    to 8.320514e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.320514e+01_episode00189\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.320514e+01_episode00189 has done.\n",
      "max mean_q value: 8.320514e+01\n",
      "========== /Model Saver output =============\n",
      " 261/861: episode: 190, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 103192305664.000000, mean_q: 83.205139\n",
      " 261/861: episode: 190, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 103192305664.000000, mean_q: 83.205139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.344484e+01\n",
      "Step 00263: model improved\n",
      "  from 8.320514e+01\n",
      "    to 8.344484e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.344484e+01_episode00190\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.344484e+01_episode00190 has done.\n",
      "max mean_q value: 8.344484e+01\n",
      "========== /Model Saver output =============\n",
      " 263/861: episode: 191, duration: 0.075s, episode steps: 2, steps per second: 27, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 444002533376.000000, mean_q: 83.444839\n",
      " 263/861: episode: 191, duration: 0.079s, episode steps: 2, steps per second: 25, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 444002533376.000000, mean_q: 83.444839\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.377069e+01\n",
      "Step 00265: model improved\n",
      "  from 8.344484e+01\n",
      "    to 8.377069e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.377069e+01_episode00191\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.377069e+01_episode00191 has done.\n",
      "max mean_q value: 8.377069e+01\n",
      "========== /Model Saver output =============\n",
      " 265/861: episode: 192, duration: 0.075s, episode steps: 2, steps per second: 27, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 296556036096.000000, mean_q: 83.770691\n",
      " 265/861: episode: 192, duration: 0.076s, episode steps: 2, steps per second: 26, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 296556036096.000000, mean_q: 83.770691\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.411950e+01\n",
      "Step 00267: model improved\n",
      "  from 8.377069e+01\n",
      "    to 8.411950e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.411950e+01_episode00192\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.411950e+01_episode00192 has done.\n",
      "max mean_q value: 8.411950e+01\n",
      "========== /Model Saver output =============\n",
      " 267/861: episode: 193, duration: 0.086s, episode steps: 2, steps per second: 23, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 343474962432.000000, mean_q: 84.119499\n",
      " 267/861: episode: 193, duration: 0.086s, episode steps: 2, steps per second: 23, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 343474962432.000000, mean_q: 84.119499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.448273e+01\n",
      "Step 00269: model improved\n",
      "  from 8.411950e+01\n",
      "    to 8.448273e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.448273e+01_episode00193\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.448273e+01_episode00193 has done.\n",
      "max mean_q value: 8.448273e+01\n",
      "========== /Model Saver output =============\n",
      " 269/861: episode: 194, duration: 0.089s, episode steps: 2, steps per second: 23, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 238590230528.000000, mean_q: 84.482727\n",
      " 269/861: episode: 194, duration: 0.090s, episode steps: 2, steps per second: 22, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 238590230528.000000, mean_q: 84.482727\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.477702e+01\n",
      "Step 00271: model improved\n",
      "  from 8.448273e+01\n",
      "    to 8.477702e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.477702e+01_episode00194\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.477702e+01_episode00194 has done.\n",
      "max mean_q value: 8.477702e+01\n",
      "========== /Model Saver output =============\n",
      " 271/861: episode: 195, duration: 0.086s, episode steps: 2, steps per second: 23, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 416853164032.000000, mean_q: 84.777023\n",
      " 271/861: episode: 195, duration: 0.086s, episode steps: 2, steps per second: 23, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 416853164032.000000, mean_q: 84.777023\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.510937e+01\n",
      "Step 00273: model improved\n",
      "  from 8.477702e+01\n",
      "    to 8.510937e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.510937e+01_episode00195\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.510937e+01_episode00195 has done.\n",
      "max mean_q value: 8.510937e+01\n",
      "========== /Model Saver output =============\n",
      " 273/861: episode: 196, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 300569919488.000000, mean_q: 85.109367\n",
      " 273/861: episode: 196, duration: 0.079s, episode steps: 2, steps per second: 25, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 300569919488.000000, mean_q: 85.109367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.542181e+01\n",
      "Step 00275: model improved\n",
      "  from 8.510937e+01\n",
      "    to 8.542181e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.542181e+01_episode00196\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.542181e+01_episode00196 has done.\n",
      "max mean_q value: 8.542181e+01\n",
      "========== /Model Saver output =============\n",
      " 275/861: episode: 197, duration: 0.073s, episode steps: 2, steps per second: 27, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 439993925632.000000, mean_q: 85.421814\n",
      " 275/861: episode: 197, duration: 0.073s, episode steps: 2, steps per second: 27, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 439993925632.000000, mean_q: 85.421814\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.576137e+01\n",
      "Step 00277: model improved\n",
      "  from 8.542181e+01\n",
      "    to 8.576137e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.576137e+01_episode00197\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.576137e+01_episode00197 has done.\n",
      "max mean_q value: 8.576137e+01\n",
      "========== /Model Saver output =============\n",
      " 277/861: episode: 198, duration: 0.083s, episode steps: 2, steps per second: 24, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 335434678272.000000, mean_q: 85.761368\n",
      " 277/861: episode: 198, duration: 0.084s, episode steps: 2, steps per second: 24, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 335434678272.000000, mean_q: 85.761368\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.608961e+01\n",
      "Step 00279: model improved\n",
      "  from 8.576137e+01\n",
      "    to 8.608961e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.608961e+01_episode00198\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.608961e+01_episode00198 has done.\n",
      "max mean_q value: 8.608961e+01\n",
      "========== /Model Saver output =============\n",
      " 279/861: episode: 199, duration: 0.090s, episode steps: 2, steps per second: 22, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 273080287232.000000, mean_q: 86.089607\n",
      " 279/861: episode: 199, duration: 0.091s, episode steps: 2, steps per second: 22, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 273080287232.000000, mean_q: 86.089607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115605.371258\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "reward: 3230813.110409\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 3230810.967342\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115593.453778\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_step 000004 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 3230820.854547\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000004 [2017-10-02 00:20:00]\n",
      "   after: 000005 [2017-10-02 00:25:00]\n",
      "_step ENDED\n",
      "_step 000005 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115290.560792\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000005 [2017-10-02 00:25:00]\n",
      "   after: 000006 [2017-10-02 00:30:00]\n",
      "_step ENDED\n",
      "_step 000006 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 3230830.741688\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000006 [2017-10-02 00:30:00]\n",
      "   after: 000007 [2017-10-02 00:35:00]\n",
      "_step ENDED\n",
      "_step 000007 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115241.801902\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000007 [2017-10-02 00:35:00]\n",
      "   after: 000008 [2017-10-02 00:40:00]\n",
      "_step ENDED\n",
      "_step 000008 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999565.908653\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000008 [2017-10-02 00:40:00]\n",
      "   after: 000009 [2017-10-02 00:45:00]\n",
      "_step ENDED\n",
      "_step 000009 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115967.770136\n",
      "now_datetime: 2017-10-02 00:45:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000009 [2017-10-02 00:45:00]\n",
      "   after: 000010 [2017-10-02 00:50:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115212.253231\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000000.000760\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115389.165002\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115212.253231\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000000.000760\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000004.287654\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.684649e+01\n",
      "Step 00289: model improved\n",
      "  from 8.608961e+01\n",
      "    to 8.684649e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.684649e+01_episode00199\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.684649e+01_episode00199 has done.\n",
      "max mean_q value: 8.684649e+01\n",
      "========== /Model Saver output =============\n",
      " 289/861: episode: 200, duration: 0.266s, episode steps: 10, steps per second: 38, episode reward: 22268605.000, mean reward: 2226860.500 [-115967.770, 3230830.742], mean action: 1.500 [0.000, 2.000], mean observation: 59.158 [1.000, 112.841], loss: 390533840896.000000, mean_q: 86.846489\n",
      " 289/861: episode: 200, duration: 0.267s, episode steps: 10, steps per second: 37, episode reward: 22268605.000, mean reward: 2226860.500 [-115967.770, 3230830.742], mean action: 1.500 [0.000, 2.000], mean observation: 59.158 [1.000, 112.841], loss: 390533840896.000000, mean_q: 86.846489\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.767953e+01\n",
      "Step 00292: model improved\n",
      "  from 8.684649e+01\n",
      "    to 8.767953e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.767953e+01_episode00200\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.767953e+01_episode00200 has done.\n",
      "max mean_q value: 8.767953e+01\n",
      "========== /Model Saver output =============\n",
      " 292/861: episode: 201, duration: 0.103s, episode steps: 3, steps per second: 29, episode reward: 2999823.089, mean reward: 999941.030 [-115389.165, 2115212.253], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 326369181696.000000, mean_q: 87.679527\n",
      " 292/861: episode: 201, duration: 0.104s, episode steps: 3, steps per second: 29, episode reward: 2999823.089, mean reward: 999941.030 [-115389.165, 2115212.253], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 326369181696.000000, mean_q: 87.679527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115213.225910\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.814890e+01\n",
      "Step 00296: model improved\n",
      "  from 8.767953e+01\n",
      "    to 8.814890e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.814890e+01_episode00201\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.814890e+01_episode00201 has done.\n",
      "max mean_q value: 8.814890e+01\n",
      "========== /Model Saver output =============\n",
      " 296/861: episode: 202, duration: 0.124s, episode steps: 4, steps per second: 32, episode reward: 4000003.316, mean reward: 1000000.829 [-115213.226, 2115212.253], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 350836097024.000000, mean_q: 88.148895\n",
      " 296/861: episode: 202, duration: 0.125s, episode steps: 4, steps per second: 32, episode reward: 4000003.316, mean reward: 1000000.829 [-115213.226, 2115212.253], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 350836097024.000000, mean_q: 88.148895\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.860452e+01\n",
      "Step 00297: model improved\n",
      "  from 8.814890e+01\n",
      "    to 8.860452e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.860452e+01_episode00202\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.860452e+01_episode00202 has done.\n",
      "max mean_q value: 8.860452e+01\n",
      "========== /Model Saver output =============\n",
      " 297/861: episode: 203, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238590918656.000000, mean_q: 88.604523\n",
      " 297/861: episode: 203, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238590918656.000000, mean_q: 88.604523\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.883789e+01\n",
      "Step 00298: model improved\n",
      "  from 8.860452e+01\n",
      "    to 8.883789e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.883789e+01_episode00203\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.883789e+01_episode00203 has done.\n",
      "max mean_q value: 8.883789e+01\n",
      "========== /Model Saver output =============\n",
      " 298/861: episode: 204, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 184289067008.000000, mean_q: 88.837891\n",
      " 298/861: episode: 204, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 184289067008.000000, mean_q: 88.837891\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.902483e+01\n",
      "Step 00299: model improved\n",
      "  from 8.883789e+01\n",
      "    to 8.902483e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.902483e+01_episode00204\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.902483e+01_episode00204 has done.\n",
      "max mean_q value: 8.902483e+01\n",
      "========== /Model Saver output =============\n",
      " 299/861: episode: 205, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 184285396992.000000, mean_q: 89.024826\n",
      " 299/861: episode: 205, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 184285396992.000000, mean_q: 89.024826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.920065e+01\n",
      "Step 00300: model improved\n",
      "  from 8.902483e+01\n",
      "    to 8.920065e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.920065e+01_episode00205\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.920065e+01_episode00205 has done.\n",
      "max mean_q value: 8.920065e+01\n",
      "========== /Model Saver output =============\n",
      " 300/861: episode: 206, duration: 0.054s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 300924796928.000000, mean_q: 89.200653\n",
      " 300/861: episode: 206, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 300924796928.000000, mean_q: 89.200653\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.950252e+01\n",
      "Step 00301: model improved\n",
      "  from 8.920065e+01\n",
      "    to 8.950252e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.950252e+01_episode00206\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.950252e+01_episode00206 has done.\n",
      "max mean_q value: 8.950252e+01\n",
      "========== /Model Saver output =============\n",
      " 301/861: episode: 207, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 277467758592.000000, mean_q: 89.502518\n",
      " 301/861: episode: 207, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 277467758592.000000, mean_q: 89.502518\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.974188e+01\n",
      "Step 00302: model improved\n",
      "  from 8.950252e+01\n",
      "    to 8.974188e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.974188e+01_episode00207\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.974188e+01_episode00207 has done.\n",
      "max mean_q value: 8.974188e+01\n",
      "========== /Model Saver output =============\n",
      " 302/861: episode: 208, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 517442502656.000000, mean_q: 89.741882\n",
      " 302/861: episode: 208, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 517442502656.000000, mean_q: 89.741882\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.999469e+01\n",
      "Step 00303: model improved\n",
      "  from 8.974188e+01\n",
      "    to 8.999469e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.999469e+01_episode00208\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.999469e+01_episode00208 has done.\n",
      "max mean_q value: 8.999469e+01\n",
      "========== /Model Saver output =============\n",
      " 303/861: episode: 209, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 680283602944.000000, mean_q: 89.994690\n",
      " 303/861: episode: 209, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 680283602944.000000, mean_q: 89.994690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000004.287654\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 9.028871e+01\n",
      "Step 00304: model improved\n",
      "  from 8.999469e+01\n",
      "    to 9.028871e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.028871e+01_episode00209\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.028871e+01_episode00209 has done.\n",
      "max mean_q value: 9.028871e+01\n",
      "========== /Model Saver output =============\n",
      " 304/861: episode: 210, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 199716995072.000000, mean_q: 90.288712\n",
      " 304/861: episode: 210, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 199716995072.000000, mean_q: 90.288712\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.052931e+01\n",
      "Step 00305: model improved\n",
      "  from 9.028871e+01\n",
      "    to 9.052931e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.052931e+01_episode00210\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.052931e+01_episode00210 has done.\n",
      "max mean_q value: 9.052931e+01\n",
      "========== /Model Saver output =============\n",
      " 305/861: episode: 211, duration: 0.048s, episode steps: 1, steps per second: 21, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 439696556032.000000, mean_q: 90.529312\n",
      " 305/861: episode: 211, duration: 0.049s, episode steps: 1, steps per second: 20, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 439696556032.000000, mean_q: 90.529312\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.079895e+01\n",
      "Step 00306: model improved\n",
      "  from 9.052931e+01\n",
      "    to 9.079895e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.079895e+01_episode00211\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.079895e+01_episode00211 has done.\n",
      "max mean_q value: 9.079895e+01\n",
      "========== /Model Saver output =============\n",
      " 306/861: episode: 212, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 393382821888.000000, mean_q: 90.798950\n",
      " 306/861: episode: 212, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 393382821888.000000, mean_q: 90.798950\n",
      "========== Model Saver output =============="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mean_q value: 9.121294e+01\n",
      "Step 00308: model improved\n",
      "  from 9.079895e+01\n",
      "    to 9.121294e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.121294e+01_episode00212\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.121294e+01_episode00212 has done.\n",
      "max mean_q value: 9.121294e+01\n",
      "========== /Model Saver output =============\n",
      " 308/861: episode: 213, duration: 0.084s, episode steps: 2, steps per second: 24, episode reward: 884800.836, mean reward: 442400.418 [-115203.451, 1000004.288], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 645441323008.000000, mean_q: 91.212944\n",
      " 308/861: episode: 213, duration: 0.084s, episode steps: 2, steps per second: 24, episode reward: 884800.836, mean reward: 442400.418 [-115203.451, 1000004.288], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 645441323008.000000, mean_q: 91.212944\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.157584e+01\n",
      "Step 00309: model improved\n",
      "  from 9.121294e+01\n",
      "    to 9.157584e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.157584e+01_episode00213\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.157584e+01_episode00213 has done.\n",
      "max mean_q value: 9.157584e+01\n",
      "========== /Model Saver output =============\n",
      " 309/861: episode: 214, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 447711412224.000000, mean_q: 91.575844\n",
      " 309/861: episode: 214, duration: 0.062s, episode steps: 1, steps per second: 16, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 447711412224.000000, mean_q: 91.575844\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.189137e+01\n",
      "Step 00310: model improved\n",
      "  from 9.157584e+01\n",
      "    to 9.189137e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.189137e+01_episode00214\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.189137e+01_episode00214 has done.\n",
      "max mean_q value: 9.189137e+01\n",
      "========== /Model Saver output =============\n",
      " 310/861: episode: 215, duration: 0.063s, episode steps: 1, steps per second: 16, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 168899772416.000000, mean_q: 91.891373\n",
      " 310/861: episode: 215, duration: 0.064s, episode steps: 1, steps per second: 16, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 168899772416.000000, mean_q: 91.891373\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.218802e+01\n",
      "Step 00311: model improved\n",
      "  from 9.189137e+01\n",
      "    to 9.218802e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.218802e+01_episode00215\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.218802e+01_episode00215 has done.\n",
      "max mean_q value: 9.218802e+01\n",
      "========== /Model Saver output =============\n",
      " 311/861: episode: 216, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 339125469184.000000, mean_q: 92.188019\n",
      " 311/861: episode: 216, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 339125469184.000000, mean_q: 92.188019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 9.242311e+01\n",
      "Step 00312: model improved\n",
      "  from 9.218802e+01\n",
      "    to 9.242311e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.242311e+01_episode00216\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.242311e+01_episode00216 has done.\n",
      "max mean_q value: 9.242311e+01\n",
      "========== /Model Saver output =============\n",
      " 312/861: episode: 217, duration: 0.054s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 253996154880.000000, mean_q: 92.423111\n",
      " 312/861: episode: 217, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 253996154880.000000, mean_q: 92.423111\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.270371e+01\n",
      "Step 00313: model improved\n",
      "  from 9.242311e+01\n",
      "    to 9.270371e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.270371e+01_episode00217\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.270371e+01_episode00217 has done.\n",
      "max mean_q value: 9.270371e+01\n",
      "========== /Model Saver output =============\n",
      " 313/861: episode: 218, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238541684736.000000, mean_q: 92.703712\n",
      " 313/861: episode: 218, duration: 0.051s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238541684736.000000, mean_q: 92.703712\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.293204e+01\n",
      "Step 00314: model improved\n",
      "  from 9.270371e+01\n",
      "    to 9.293204e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.293204e+01_episode00218\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.293204e+01_episode00218 has done.\n",
      "max mean_q value: 9.293204e+01\n",
      "========== /Model Saver output =============\n",
      " 314/861: episode: 219, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 564352843776.000000, mean_q: 92.932037\n",
      " 314/861: episode: 219, duration: 0.057s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 564352843776.000000, mean_q: 92.932037\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.327979e+01\n",
      "Step 00315: model improved\n",
      "  from 9.293204e+01\n",
      "    to 9.327979e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.327979e+01_episode00219\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.327979e+01_episode00219 has done.\n",
      "max mean_q value: 9.327979e+01\n",
      "========== /Model Saver output =============\n",
      " 315/861: episode: 220, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 440350932992.000000, mean_q: 93.279793\n",
      " 315/861: episode: 220, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 440350932992.000000, mean_q: 93.279793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115603.001765\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115607.515085\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000214.062429\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115005.481751\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 9.352352e+01\n",
      "Step 00316: model improved\n",
      "  from 9.327979e+01\n",
      "    to 9.352352e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.352352e+01_episode00220\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.352352e+01_episode00220 has done.\n",
      "max mean_q value: 9.352352e+01\n",
      "========== /Model Saver output =============\n",
      " 316/861: episode: 221, duration: 0.057s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 595141263360.000000, mean_q: 93.523521\n",
      " 316/861: episode: 221, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 595141263360.000000, mean_q: 93.523521\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.401430e+01\n",
      "Step 00320: model improved\n",
      "  from 9.352352e+01\n",
      "    to 9.401430e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.401430e+01_episode00221\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.401430e+01_episode00221 has done.\n",
      "max mean_q value: 9.401430e+01\n",
      "========== /Model Saver output =============\n",
      " 320/861: episode: 222, duration: 0.108s, episode steps: 4, steps per second: 37, episode reward: 5116419.098, mean reward: 1279104.774 [-115005.482, 2115607.515], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 570052509696.000000, mean_q: 94.014297\n",
      " 320/861: episode: 222, duration: 0.111s, episode steps: 4, steps per second: 36, episode reward: 5116419.098, mean reward: 1279104.774 [-115005.482, 2115607.515], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 570052509696.000000, mean_q: 94.014297\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.455015e+01\n",
      "Step 00322: model improved\n",
      "  from 9.401430e+01\n",
      "    to 9.455015e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.455015e+01_episode00222\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.455015e+01_episode00222 has done.\n",
      "max mean_q value: 9.455015e+01\n",
      "========== /Model Saver output =============\n",
      " 322/861: episode: 223, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 300572868608.000000, mean_q: 94.550148\n",
      " 322/861: episode: 223, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 300572868608.000000, mean_q: 94.550148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 9.492982e+01\n",
      "Step 00324: model improved\n",
      "  from 9.455015e+01\n",
      "    to 9.492982e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.492982e+01_episode00223\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.492982e+01_episode00223 has done.\n",
      "max mean_q value: 9.492982e+01\n",
      "========== /Model Saver output =============\n",
      " 324/861: episode: 224, duration: 0.073s, episode steps: 2, steps per second: 28, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 560276570112.000000, mean_q: 94.929817\n",
      " 324/861: episode: 224, duration: 0.073s, episode steps: 2, steps per second: 27, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 560276570112.000000, mean_q: 94.929817\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.535263e+01\n",
      "Step 00326: model improved\n",
      "  from 9.492982e+01\n",
      "    to 9.535263e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.535263e+01_episode00224\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.535263e+01_episode00224 has done.\n",
      "max mean_q value: 9.535263e+01\n",
      "========== /Model Saver output =============\n",
      " 326/861: episode: 225, duration: 0.073s, episode steps: 2, steps per second: 27, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 296231108608.000000, mean_q: 95.352631\n",
      " 326/861: episode: 225, duration: 0.074s, episode steps: 2, steps per second: 27, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 296231108608.000000, mean_q: 95.352631\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.575572e+01\n",
      "Step 00328: model improved\n",
      "  from 9.535263e+01\n",
      "    to 9.575572e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.575572e+01_episode00225\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.575572e+01_episode00225 has done.\n",
      "max mean_q value: 9.575572e+01\n",
      "========== /Model Saver output =============\n",
      " 328/861: episode: 226, duration: 0.079s, episode steps: 2, steps per second: 25, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 424604499968.000000, mean_q: 95.755722\n",
      " 328/861: episode: 226, duration: 0.080s, episode steps: 2, steps per second: 25, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 424604499968.000000, mean_q: 95.755722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000004.287654\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115389.165002\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 9.621069e+01\n",
      "Step 00330: model improved\n",
      "  from 9.575572e+01\n",
      "    to 9.621069e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.621069e+01_episode00226\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.621069e+01_episode00226 has done.\n",
      "max mean_q value: 9.621069e+01\n",
      "========== /Model Saver output =============\n",
      " 330/861: episode: 227, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 257671184384.000000, mean_q: 96.210693\n",
      " 330/861: episode: 227, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 257671184384.000000, mean_q: 96.210693\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.660117e+01\n",
      "Step 00332: model improved\n",
      "  from 9.621069e+01\n",
      "    to 9.660117e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.660117e+01_episode00227\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.660117e+01_episode00227 has done.\n",
      "max mean_q value: 9.660117e+01\n",
      "========== /Model Saver output =============\n",
      " 332/861: episode: 228, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 440306139136.000000, mean_q: 96.601166\n",
      " 332/861: episode: 228, duration: 0.079s, episode steps: 2, steps per second: 25, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 440306139136.000000, mean_q: 96.601166\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.705911e+01\n",
      "Step 00335: model improved\n",
      "  from 9.660117e+01\n",
      "    to 9.705911e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.705911e+01_episode00228\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.705911e+01_episode00228 has done.\n",
      "max mean_q value: 9.705911e+01\n",
      "========== /Model Saver output =============\n",
      " 335/861: episode: 229, duration: 0.103s, episode steps: 3, steps per second: 29, episode reward: 1884623.924, mean reward: 628207.975 [-115389.165, 1000008.801], mean action: 1.333 [0.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 388282089472.000000, mean_q: 97.059113\n",
      " 335/861: episode: 229, duration: 0.103s, episode steps: 3, steps per second: 29, episode reward: 1884623.924, mean reward: 628207.975 [-115389.165, 1000008.801], mean action: 1.333 [0.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 388282089472.000000, mean_q: 97.059113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 9.744990e+01\n",
      "Step 00336: model improved\n",
      "  from 9.705911e+01\n",
      "    to 9.744990e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.744990e+01_episode00229\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.744990e+01_episode00229 has done.\n",
      "max mean_q value: 9.744990e+01\n",
      "========== /Model Saver output =============\n",
      " 336/861: episode: 230, duration: 0.054s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 199685734400.000000, mean_q: 97.449898\n",
      " 336/861: episode: 230, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 199685734400.000000, mean_q: 97.449898\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.776976e+01\n",
      "Step 00337: model improved\n",
      "  from 9.744990e+01\n",
      "    to 9.776976e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.776976e+01_episode00230\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.776976e+01_episode00230 has done.\n",
      "max mean_q value: 9.776976e+01\n",
      "========== /Model Saver output =============\n",
      " 337/861: episode: 231, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 587129094144.000000, mean_q: 97.769760\n",
      " 337/861: episode: 231, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 587129094144.000000, mean_q: 97.769760\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.805664e+01\n",
      "Step 00338: model improved\n",
      "  from 9.776976e+01\n",
      "    to 9.805664e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.805664e+01_episode00231\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.805664e+01_episode00231 has done.\n",
      "max mean_q value: 9.805664e+01\n",
      "========== /Model Saver output =============\n",
      " 338/861: episode: 232, duration: 0.063s, episode steps: 1, steps per second: 16, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 223144935424.000000, mean_q: 98.056641\n",
      " 338/861: episode: 232, duration: 0.063s, episode steps: 1, steps per second: 16, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 223144935424.000000, mean_q: 98.056641\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.834277e+01\n",
      "Step 00339: model improved\n",
      "  from 9.805664e+01\n",
      "    to 9.834277e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.834277e+01_episode00232\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.834277e+01_episode00232 has done.\n",
      "max mean_q value: 9.834277e+01\n",
      "========== /Model Saver output =============\n",
      " 339/861: episode: 233, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 696384880640.000000, mean_q: 98.342766\n",
      " 339/861: episode: 233, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 696384880640.000000, mean_q: 98.342766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 9.863330e+01\n",
      "Step 00340: model improved\n",
      "  from 9.834277e+01\n",
      "    to 9.863330e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.863330e+01_episode00233\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.863330e+01_episode00233 has done.\n",
      "max mean_q value: 9.863330e+01\n",
      "========== /Model Saver output =============\n",
      " 340/861: episode: 234, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 540832235520.000000, mean_q: 98.633301\n",
      " 340/861: episode: 234, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 540832235520.000000, mean_q: 98.633301\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.889809e+01\n",
      "Step 00341: model improved\n",
      "  from 9.863330e+01\n",
      "    to 9.889809e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.889809e+01_episode00234\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.889809e+01_episode00234 has done.\n",
      "max mean_q value: 9.889809e+01\n",
      "========== /Model Saver output =============\n",
      " 341/861: episode: 235, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 408772968448.000000, mean_q: 98.898094\n",
      " 341/861: episode: 235, duration: 0.057s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 408772968448.000000, mean_q: 98.898094\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.924725e+01\n",
      "Step 00342: model improved\n",
      "  from 9.889809e+01\n",
      "    to 9.924725e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.924725e+01_episode00235\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.924725e+01_episode00235 has done.\n",
      "max mean_q value: 9.924725e+01\n",
      "========== /Model Saver output =============\n",
      " 342/861: episode: 236, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 168888041472.000000, mean_q: 99.247253\n",
      " 342/861: episode: 236, duration: 0.054s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 168888041472.000000, mean_q: 99.247253\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 9.955424e+01\n",
      "Step 00343: model improved\n",
      "  from 9.924725e+01\n",
      "    to 9.955424e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.955424e+01_episode00236\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.955424e+01_episode00236 has done.\n",
      "max mean_q value: 9.955424e+01\n",
      "========== /Model Saver output =============\n",
      " 343/861: episode: 237, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 385286766592.000000, mean_q: 99.554245\n",
      " 343/861: episode: 237, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 385286766592.000000, mean_q: 99.554245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 9.985065e+01\n",
      "Step 00344: model improved\n",
      "  from 9.955424e+01\n",
      "    to 9.985065e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq9.985065e+01_episode00237\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq9.985065e+01_episode00237 has done.\n",
      "max mean_q value: 9.985065e+01\n",
      "========== /Model Saver output =============\n",
      " 344/861: episode: 238, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 254002446336.000000, mean_q: 99.850647\n",
      " 344/861: episode: 238, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 254002446336.000000, mean_q: 99.850647\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.001625e+02\n",
      "Step 00345: model improved\n",
      "  from 9.985065e+01\n",
      "    to 1.001625e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.001625e+02_episode00238\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.001625e+02_episode00238 has done.\n",
      "max mean_q value: 1.001625e+02\n",
      "========== /Model Saver output =============\n",
      " 345/861: episode: 239, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 184289755136.000000, mean_q: 100.162476\n",
      " 345/861: episode: 239, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 184289755136.000000, mean_q: 100.162476\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.004347e+02\n",
      "Step 00346: model improved\n",
      "  from 1.001625e+02\n",
      "    to 1.004347e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.004347e+02_episode00239\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.004347e+02_episode00239 has done.\n",
      "max mean_q value: 1.004347e+02\n",
      "========== /Model Saver output =============\n",
      " 346/861: episode: 240, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 83749888000.000000, mean_q: 100.434677\n",
      " 346/861: episode: 240, duration: 0.062s, episode steps: 1, steps per second: 16, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 83749888000.000000, mean_q: 100.434677\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.006870e+02\n",
      "Step 00347: model improved\n",
      "  from 1.004347e+02\n",
      "    to 1.006870e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.006870e+02_episode00240\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.006870e+02_episode00240 has done.\n",
      "max mean_q value: 1.006870e+02\n",
      "========== /Model Saver output =============\n",
      " 347/861: episode: 241, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 502004088832.000000, mean_q: 100.687012\n",
      " 347/861: episode: 241, duration: 0.057s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 502004088832.000000, mean_q: 100.687012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.009285e+02\n",
      "Step 00348: model improved\n",
      "  from 1.006870e+02\n",
      "    to 1.009285e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.009285e+02_episode00241\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.009285e+02_episode00241 has done.\n",
      "max mean_q value: 1.009285e+02\n",
      "========== /Model Saver output =============\n",
      " 348/861: episode: 242, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 455730135040.000000, mean_q: 100.928535\n",
      " 348/861: episode: 242, duration: 0.057s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 455730135040.000000, mean_q: 100.928535\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.011623e+02\n",
      "Step 00349: model improved\n",
      "  from 1.009285e+02\n",
      "    to 1.011623e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.011623e+02_episode00242\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.011623e+02_episode00242 has done.\n",
      "max mean_q value: 1.011623e+02\n",
      "========== /Model Saver output =============\n",
      " 349/861: episode: 243, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207762391040.000000, mean_q: 101.162270\n",
      " 349/861: episode: 243, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207762391040.000000, mean_q: 101.162270\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.013941e+02\n",
      "Step 00350: model improved\n",
      "  from 1.011623e+02\n",
      "    to 1.013941e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.013941e+02_episode00243\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.013941e+02_episode00243 has done.\n",
      "max mean_q value: 1.013941e+02\n",
      "========== /Model Saver output =============\n",
      " 350/861: episode: 244, duration: 0.057s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 331748507648.000000, mean_q: 101.394089\n",
      " 350/861: episode: 244, duration: 0.057s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 331748507648.000000, mean_q: 101.394089\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.016316e+02\n",
      "Step 00351: model improved\n",
      "  from 1.013941e+02\n",
      "    to 1.016316e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.016316e+02_episode00244\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.016316e+02_episode00244 has done.\n",
      "max mean_q value: 1.016316e+02\n",
      "========== /Model Saver output =============\n",
      " 351/861: episode: 245, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 292211261440.000000, mean_q: 101.631569\n",
      " 351/861: episode: 245, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 292211261440.000000, mean_q: 101.631569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.018705e+02\n",
      "Step 00352: model improved\n",
      "  from 1.016316e+02\n",
      "    to 1.018705e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.018705e+02_episode00245\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.018705e+02_episode00245 has done.\n",
      "max mean_q value: 1.018705e+02\n",
      "========== /Model Saver output =============\n",
      " 352/861: episode: 246, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 339090407424.000000, mean_q: 101.870476\n",
      " 352/861: episode: 246, duration: 0.062s, episode steps: 1, steps per second: 16, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 339090407424.000000, mean_q: 101.870476\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.021326e+02\n",
      "Step 00353: model improved\n",
      "  from 1.018705e+02\n",
      "    to 1.021326e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.021326e+02_episode00246\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.021326e+02_episode00246 has done.\n",
      "max mean_q value: 1.021326e+02\n",
      "========== /Model Saver output =============\n",
      " 353/861: episode: 247, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 510033330176.000000, mean_q: 102.132584\n",
      " 353/861: episode: 247, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 510033330176.000000, mean_q: 102.132584\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.023820e+02\n",
      "Step 00354: model improved\n",
      "  from 1.021326e+02\n",
      "    to 1.023820e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.023820e+02_episode00247\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.023820e+02_episode00247 has done.\n",
      "max mean_q value: 1.023820e+02\n",
      "========== /Model Saver output =============\n",
      " 354/861: episode: 248, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 610563391488.000000, mean_q: 102.382034\n",
      " 354/861: episode: 248, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 610563391488.000000, mean_q: 102.382034\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.026434e+02\n",
      "Step 00355: model improved\n",
      "  from 1.023820e+02\n",
      "    to 1.026434e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.026434e+02_episode00248\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.026434e+02_episode00248 has done.\n",
      "max mean_q value: 1.026434e+02\n",
      "========== /Model Saver output =============\n",
      " 355/861: episode: 249, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 184296898560.000000, mean_q: 102.643448\n",
      " 355/861: episode: 249, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 184296898560.000000, mean_q: 102.643448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.028770e+02\n",
      "Step 00356: model improved\n",
      "  from 1.026434e+02\n",
      "    to 1.028770e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.028770e+02_episode00249\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.028770e+02_episode00249 has done.\n",
      "max mean_q value: 1.028770e+02\n",
      "========== /Model Saver output =============\n",
      " 356/861: episode: 250, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 315609874432.000000, mean_q: 102.877029\n",
      " 356/861: episode: 250, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 315609874432.000000, mean_q: 102.877029\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.031065e+02\n",
      "Step 00357: model improved\n",
      "  from 1.028770e+02\n",
      "    to 1.031065e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.031065e+02_episode00250\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.031065e+02_episode00250 has done.\n",
      "max mean_q value: 1.031065e+02\n",
      "========== /Model Saver output =============\n",
      " 357/861: episode: 251, duration: 0.057s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 223159189504.000000, mean_q: 103.106529\n",
      " 357/861: episode: 251, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 223159189504.000000, mean_q: 103.106529\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.033354e+02\n",
      "Step 00358: model improved\n",
      "  from 1.031065e+02\n",
      "    to 1.033354e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.033354e+02_episode00251\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.033354e+02_episode00251 has done.\n",
      "max mean_q value: 1.033354e+02\n",
      "========== /Model Saver output =============\n",
      " 358/861: episode: 252, duration: 0.062s, episode steps: 1, steps per second: 16, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 439637704704.000000, mean_q: 103.335434\n",
      " 358/861: episode: 252, duration: 0.063s, episode steps: 1, steps per second: 16, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 439637704704.000000, mean_q: 103.335434\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.035940e+02\n",
      "Step 00359: model improved\n",
      "  from 1.033354e+02\n",
      "    to 1.035940e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.035940e+02_episode00252\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.035940e+02_episode00252 has done.\n",
      "max mean_q value: 1.035940e+02\n",
      "========== /Model Saver output =============\n",
      " 359/861: episode: 253, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 486664929280.000000, mean_q: 103.593994\n",
      " 359/861: episode: 253, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 486664929280.000000, mean_q: 103.593994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.038358e+02\n",
      "Step 00360: model improved\n",
      "  from 1.035940e+02\n",
      "    to 1.038358e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.038358e+02_episode00253\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.038358e+02_episode00253 has done.\n",
      "max mean_q value: 1.038358e+02\n",
      "========== /Model Saver output =============\n",
      " 360/861: episode: 254, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 223124750336.000000, mean_q: 103.835770\n",
      " 360/861: episode: 254, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 223124750336.000000, mean_q: 103.835770\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.040867e+02\n",
      "Step 00361: model improved\n",
      "  from 1.038358e+02\n",
      "    to 1.040867e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.040867e+02_episode00254\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.040867e+02_episode00254 has done.\n",
      "max mean_q value: 1.040867e+02\n",
      "========== /Model Saver output =============\n",
      " 361/861: episode: 255, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 223168299008.000000, mean_q: 104.086693\n",
      " 361/861: episode: 255, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 223168299008.000000, mean_q: 104.086693\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.043377e+02\n",
      "Step 00362: model improved\n",
      "  from 1.040867e+02\n",
      "    to 1.043377e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.043377e+02_episode00255\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.043377e+02_episode00255 has done.\n",
      "max mean_q value: 1.043377e+02\n",
      "========== /Model Saver output =============\n",
      " 362/861: episode: 256, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 308257062912.000000, mean_q: 104.337677\n",
      " 362/861: episode: 256, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 308257062912.000000, mean_q: 104.337677\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.046084e+02\n",
      "Step 00363: model improved\n",
      "  from 1.043377e+02\n",
      "    to 1.046084e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.046084e+02_episode00256\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.046084e+02_episode00256 has done.\n",
      "max mean_q value: 1.046084e+02\n",
      "========== /Model Saver output =============\n",
      " 363/861: episode: 257, duration: 0.051s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 525520764928.000000, mean_q: 104.608360\n",
      " 363/861: episode: 257, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 525520764928.000000, mean_q: 104.608360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.048478e+02\n",
      "Step 00364: model improved\n",
      "  from 1.046084e+02\n",
      "    to 1.048478e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.048478e+02_episode00257\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.048478e+02_episode00257 has done.\n",
      "max mean_q value: 1.048478e+02\n",
      "========== /Model Saver output =============\n",
      " 364/861: episode: 258, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 331762597888.000000, mean_q: 104.847824\n",
      " 364/861: episode: 258, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 331762597888.000000, mean_q: 104.847824\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.050610e+02\n",
      "Step 00365: model improved\n",
      "  from 1.048478e+02\n",
      "    to 1.050610e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.050610e+02_episode00258\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.050610e+02_episode00258 has done.\n",
      "max mean_q value: 1.050610e+02\n",
      "========== /Model Saver output =============\n",
      " 365/861: episode: 259, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 424240414720.000000, mean_q: 105.061035\n",
      " 365/861: episode: 259, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 424240414720.000000, mean_q: 105.061035\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.052920e+02\n",
      "Step 00366: model improved\n",
      "  from 1.050610e+02\n",
      "    to 1.052920e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.052920e+02_episode00259\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.052920e+02_episode00259 has done.\n",
      "max mean_q value: 1.052920e+02\n",
      "========== /Model Saver output =============\n",
      " 366/861: episode: 260, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207756984320.000000, mean_q: 105.291962\n",
      " 366/861: episode: 260, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207756984320.000000, mean_q: 105.291962\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.055199e+02\n",
      "Step 00367: model improved\n",
      "  from 1.052920e+02\n",
      "    to 1.055199e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.055199e+02_episode00260\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.055199e+02_episode00260 has done.\n",
      "max mean_q value: 1.055199e+02\n",
      "========== /Model Saver output =============\n",
      " 367/861: episode: 261, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 262047989760.000000, mean_q: 105.519897\n",
      " 367/861: episode: 261, duration: 0.061s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 262047989760.000000, mean_q: 105.519897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115603.001765\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115607.515085\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.057146e+02\n",
      "Step 00368: model improved\n",
      "  from 1.055199e+02\n",
      "    to 1.057146e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.057146e+02_episode00261\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.057146e+02_episode00261 has done.\n",
      "max mean_q value: 1.057146e+02\n",
      "========== /Model Saver output =============\n",
      " 368/861: episode: 262, duration: 0.068s, episode steps: 1, steps per second: 15, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 548909285376.000000, mean_q: 105.714645\n",
      " 368/861: episode: 262, duration: 0.068s, episode steps: 1, steps per second: 15, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 548909285376.000000, mean_q: 105.714645\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.059069e+02\n",
      "Step 00369: model improved\n",
      "  from 1.057146e+02\n",
      "    to 1.059069e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.059069e+02_episode00262\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.059069e+02_episode00262 has done.\n",
      "max mean_q value: 1.059069e+02\n",
      "========== /Model Saver output =============\n",
      " 369/861: episode: 263, duration: 0.048s, episode steps: 1, steps per second: 21, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 284862283776.000000, mean_q: 105.906921\n",
      " 369/861: episode: 263, duration: 0.049s, episode steps: 1, steps per second: 20, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 284862283776.000000, mean_q: 105.906921\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.061054e+02\n",
      "Step 00370: model improved\n",
      "  from 1.059069e+02\n",
      "    to 1.061054e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.061054e+02_episode00263\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.061054e+02_episode00263 has done.\n",
      "max mean_q value: 1.061054e+02\n",
      "========== /Model Saver output =============\n",
      " 370/861: episode: 264, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 479254347776.000000, mean_q: 106.105354\n",
      " 370/861: episode: 264, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 479254347776.000000, mean_q: 106.105354\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.063155e+02\n",
      "Step 00371: model improved\n",
      "  from 1.061054e+02\n",
      "    to 1.063155e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.063155e+02_episode00264\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.063155e+02_episode00264 has done.\n",
      "max mean_q value: 1.063155e+02\n",
      "========== /Model Saver output =============\n",
      " 371/861: episode: 265, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 432286629888.000000, mean_q: 106.315491\n",
      " 371/861: episode: 265, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 432286629888.000000, mean_q: 106.315491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000214.062429\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115005.481751\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.066900e+02\n",
      "Step 00375: model improved\n",
      "  from 1.063155e+02\n",
      "    to 1.066900e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.066900e+02_episode00265\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.066900e+02_episode00265 has done.\n",
      "max mean_q value: 1.066900e+02\n",
      "========== /Model Saver output =============\n",
      " 375/861: episode: 266, duration: 0.119s, episode steps: 4, steps per second: 34, episode reward: 5116419.098, mean reward: 1279104.774 [-115005.482, 2115607.515], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 364610748416.000000, mean_q: 106.690010\n",
      " 375/861: episode: 266, duration: 0.120s, episode steps: 4, steps per second: 33, episode reward: 5116419.098, mean reward: 1279104.774 [-115005.482, 2115607.515], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 364610748416.000000, mean_q: 106.690010\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.071140e+02\n",
      "Step 00377: model improved\n",
      "  from 1.066900e+02\n",
      "    to 1.071140e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.071140e+02_episode00266\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.071140e+02_episode00266 has done.\n",
      "max mean_q value: 1.071140e+02\n",
      "========== /Model Saver output =============\n",
      " 377/861: episode: 267, duration: 0.073s, episode steps: 2, steps per second: 27, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 358556073984.000000, mean_q: 107.114014\n",
      " 377/861: episode: 267, duration: 0.075s, episode steps: 2, steps per second: 27, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 358556073984.000000, mean_q: 107.114014\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.074258e+02\n",
      "Step 00379: model improved\n",
      "  from 1.071140e+02\n",
      "    to 1.074258e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.074258e+02_episode00267\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.074258e+02_episode00267 has done.\n",
      "max mean_q value: 1.074258e+02\n",
      "========== /Model Saver output =============\n",
      " 379/861: episode: 268, duration: 0.080s, episode steps: 2, steps per second: 25, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 296902918144.000000, mean_q: 107.425789\n",
      " 379/861: episode: 268, duration: 0.081s, episode steps: 2, steps per second: 25, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 296902918144.000000, mean_q: 107.425789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.077509e+02\n",
      "Step 00381: model improved\n",
      "  from 1.074258e+02\n",
      "    to 1.077509e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.077509e+02_episode00268\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.077509e+02_episode00268 has done.\n",
      "max mean_q value: 1.077509e+02\n",
      "========== /Model Saver output =============\n",
      " 381/861: episode: 269, duration: 0.076s, episode steps: 2, steps per second: 26, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 435950977024.000000, mean_q: 107.750946\n",
      " 381/861: episode: 269, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 435950977024.000000, mean_q: 107.750946\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.080946e+02\n",
      "Step 00383: model improved\n",
      "  from 1.077509e+02\n",
      "    to 1.080946e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.080946e+02_episode00269\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.080946e+02_episode00269 has done.\n",
      "max mean_q value: 1.080946e+02\n",
      "========== /Model Saver output =============\n",
      " 383/861: episode: 270, duration: 0.076s, episode steps: 2, steps per second: 26, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 316338405376.000000, mean_q: 108.094589\n",
      " 383/861: episode: 270, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 316338405376.000000, mean_q: 108.094589\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.084124e+02\n",
      "Step 00385: model improved\n",
      "  from 1.080946e+02\n",
      "    to 1.084124e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.084124e+02_episode00270\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.084124e+02_episode00270 has done.\n",
      "max mean_q value: 1.084124e+02\n",
      "========== /Model Saver output =============\n",
      " 385/861: episode: 271, duration: 0.084s, episode steps: 2, steps per second: 24, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 110902329344.000000, mean_q: 108.412399\n",
      " 385/861: episode: 271, duration: 0.085s, episode steps: 2, steps per second: 24, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 110902329344.000000, mean_q: 108.412399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.086796e+02\n",
      "Step 00387: model improved\n",
      "  from 1.084124e+02\n",
      "    to 1.086796e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.086796e+02_episode00271\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.086796e+02_episode00271 has done.\n",
      "max mean_q value: 1.086796e+02\n",
      "========== /Model Saver output =============\n",
      " 387/861: episode: 272, duration: 0.085s, episode steps: 2, steps per second: 24, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 184320032768.000000, mean_q: 108.679642\n",
      " 387/861: episode: 272, duration: 0.087s, episode steps: 2, steps per second: 23, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 184320032768.000000, mean_q: 108.679642\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.089305e+02\n",
      "Step 00389: model improved\n",
      "  from 1.086796e+02\n",
      "    to 1.089305e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.089305e+02_episode00272\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.089305e+02_episode00272 has done.\n",
      "max mean_q value: 1.089305e+02\n",
      "========== /Model Saver output =============\n",
      " 389/861: episode: 273, duration: 0.085s, episode steps: 2, steps per second: 24, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 374315745280.000000, mean_q: 108.930489\n",
      " 389/861: episode: 273, duration: 0.086s, episode steps: 2, steps per second: 23, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 374315745280.000000, mean_q: 108.930489\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.091730e+02\n",
      "Step 00391: model improved\n",
      "  from 1.089305e+02\n",
      "    to 1.091730e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.091730e+02_episode00273\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.091730e+02_episode00273 has done.\n",
      "max mean_q value: 1.091730e+02\n",
      "========== /Model Saver output =============\n",
      " 391/861: episode: 274, duration: 0.084s, episode steps: 2, steps per second: 24, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 242599952384.000000, mean_q: 109.172958\n",
      " 391/861: episode: 274, duration: 0.084s, episode steps: 2, steps per second: 24, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 242599952384.000000, mean_q: 109.172958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.094341e+02\n",
      "Step 00393: model improved\n",
      "  from 1.091730e+02\n",
      "    to 1.094341e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.094341e+02_episode00274\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.094341e+02_episode00274 has done.\n",
      "max mean_q value: 1.094341e+02\n",
      "========== /Model Saver output =============\n",
      " 393/861: episode: 275, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 207417114624.000000, mean_q: 109.434120\n",
      " 393/861: episode: 275, duration: 0.079s, episode steps: 2, steps per second: 25, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 207417114624.000000, mean_q: 109.434120\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.097187e+02\n",
      "Step 00395: model improved\n",
      "  from 1.094341e+02\n",
      "    to 1.097187e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.097187e+02_episode00275\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.097187e+02_episode00275 has done.\n",
      "max mean_q value: 1.097187e+02\n",
      "========== /Model Saver output =============\n",
      " 395/861: episode: 276, duration: 0.073s, episode steps: 2, steps per second: 27, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 211451232256.000000, mean_q: 109.718689\n",
      " 395/861: episode: 276, duration: 0.075s, episode steps: 2, steps per second: 27, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 211451232256.000000, mean_q: 109.718689\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.100309e+02\n",
      "Step 00397: model improved\n",
      "  from 1.097187e+02\n",
      "    to 1.100309e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.100309e+02_episode00276\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.100309e+02_episode00276 has done.\n",
      "max mean_q value: 1.100309e+02\n",
      "========== /Model Saver output =============\n",
      " 397/861: episode: 277, duration: 0.074s, episode steps: 2, steps per second: 27, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 269776191488.000000, mean_q: 110.030853\n",
      " 397/861: episode: 277, duration: 0.075s, episode steps: 2, steps per second: 27, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 269776191488.000000, mean_q: 110.030853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.103205e+02\n",
      "Step 00399: model improved\n",
      "  from 1.100309e+02\n",
      "    to 1.103205e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.103205e+02_episode00277\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.103205e+02_episode00277 has done.\n",
      "max mean_q value: 1.103205e+02\n",
      "========== /Model Saver output =============\n",
      " 399/861: episode: 278, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 207430500352.000000, mean_q: 110.320496\n",
      " 399/861: episode: 278, duration: 0.079s, episode steps: 2, steps per second: 25, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 207430500352.000000, mean_q: 110.320496\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.106559e+02\n",
      "Step 00401: model improved\n",
      "  from 1.103205e+02\n",
      "    to 1.106559e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.106559e+02_episode00278\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.106559e+02_episode00278 has done.\n",
      "max mean_q value: 1.106559e+02\n",
      "========== /Model Saver output =============\n",
      " 401/861: episode: 279, duration: 0.074s, episode steps: 2, steps per second: 27, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 168895217664.000000, mean_q: 110.655853\n",
      " 401/861: episode: 279, duration: 0.074s, episode steps: 2, steps per second: 27, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 168895217664.000000, mean_q: 110.655853\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.109528e+02\n",
      "Step 00403: model improved\n",
      "  from 1.106559e+02\n",
      "    to 1.109528e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.109528e+02_episode00279\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.109528e+02_episode00279 has done.\n",
      "max mean_q value: 1.109528e+02\n",
      "========== /Model Saver output =============\n",
      " 403/861: episode: 280, duration: 0.088s, episode steps: 2, steps per second: 23, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 242270912512.000000, mean_q: 110.952774\n",
      " 403/861: episode: 280, duration: 0.090s, episode steps: 2, steps per second: 22, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 242270912512.000000, mean_q: 110.952774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.112487e+02\n",
      "Step 00405: model improved\n",
      "  from 1.109528e+02\n",
      "    to 1.112487e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.112487e+02_episode00280\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.112487e+02_episode00280 has done.\n",
      "max mean_q value: 1.112487e+02\n",
      "========== /Model Saver output =============\n",
      " 405/861: episode: 281, duration: 0.083s, episode steps: 2, steps per second: 24, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 560299769856.000000, mean_q: 111.248741\n",
      " 405/861: episode: 281, duration: 0.084s, episode steps: 2, steps per second: 24, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 560299769856.000000, mean_q: 111.248741\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.115879e+02\n",
      "Step 00407: model improved\n",
      "  from 1.112487e+02\n",
      "    to 1.115879e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.115879e+02_episode00281\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.115879e+02_episode00281 has done.\n",
      "max mean_q value: 1.115879e+02\n",
      "========== /Model Saver output =============\n",
      " 407/861: episode: 282, duration: 0.079s, episode steps: 2, steps per second: 25, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 401125474304.000000, mean_q: 111.587906\n",
      " 407/861: episode: 282, duration: 0.080s, episode steps: 2, steps per second: 25, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 401125474304.000000, mean_q: 111.587906\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.119118e+02\n",
      "Step 00409: model improved\n",
      "  from 1.115879e+02\n",
      "    to 1.119118e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.119118e+02_episode00282\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.119118e+02_episode00282 has done.\n",
      "max mean_q value: 1.119118e+02\n",
      "========== /Model Saver output =============\n",
      " 409/861: episode: 283, duration: 0.074s, episode steps: 2, steps per second: 27, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 424587919360.000000, mean_q: 111.911835\n",
      " 409/861: episode: 283, duration: 0.075s, episode steps: 2, steps per second: 27, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 424587919360.000000, mean_q: 111.911835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.122416e+02\n",
      "Step 00411: model improved\n",
      "  from 1.119118e+02\n",
      "    to 1.122416e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.122416e+02_episode00283\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.122416e+02_episode00283 has done.\n",
      "max mean_q value: 1.122416e+02\n",
      "========== /Model Saver output =============\n",
      " 411/861: episode: 284, duration: 0.089s, episode steps: 2, steps per second: 22, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 261678759936.000000, mean_q: 112.241577\n",
      " 411/861: episode: 284, duration: 0.090s, episode steps: 2, steps per second: 22, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 261678759936.000000, mean_q: 112.241577\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.126082e+02\n",
      "Step 00413: model improved\n",
      "  from 1.122416e+02\n",
      "    to 1.126082e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.126082e+02_episode00284\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.126082e+02_episode00284 has done.\n",
      "max mean_q value: 1.126082e+02\n",
      "========== /Model Saver output =============\n",
      " 413/861: episode: 285, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 284813000704.000000, mean_q: 112.608231\n",
      " 413/861: episode: 285, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 284813000704.000000, mean_q: 112.608231\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.129879e+02\n",
      "Step 00415: model improved\n",
      "  from 1.126082e+02\n",
      "    to 1.129879e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.129879e+02_episode00285\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.129879e+02_episode00285 has done.\n",
      "max mean_q value: 1.129879e+02\n",
      "========== /Model Saver output =============\n",
      " 415/861: episode: 286, duration: 0.073s, episode steps: 2, steps per second: 27, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 362247356416.000000, mean_q: 112.987946\n",
      " 415/861: episode: 286, duration: 0.073s, episode steps: 2, steps per second: 27, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 362247356416.000000, mean_q: 112.987946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115203.451497\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000008.800974\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.133887e+02\n",
      "Step 00417: model improved\n",
      "  from 1.129879e+02\n",
      "    to 1.133887e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.133887e+02_episode00286\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.133887e+02_episode00286 has done.\n",
      "max mean_q value: 1.133887e+02\n",
      "========== /Model Saver output =============\n",
      " 417/861: episode: 287, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 288858013696.000000, mean_q: 113.388748\n",
      " 417/861: episode: 287, duration: 0.079s, episode steps: 2, steps per second: 25, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 288858013696.000000, mean_q: 113.388748\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.137471e+02\n",
      "Step 00419: model improved\n",
      "  from 1.133887e+02\n",
      "    to 1.137471e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.137471e+02_episode00287\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.137471e+02_episode00287 has done.\n",
      "max mean_q value: 1.137471e+02\n",
      "========== /Model Saver output =============\n",
      " 419/861: episode: 288, duration: 0.072s, episode steps: 2, steps per second: 28, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 192005210112.000000, mean_q: 113.747131\n",
      " 419/861: episode: 288, duration: 0.072s, episode steps: 2, steps per second: 28, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 192005210112.000000, mean_q: 113.747131\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.140689e+02\n",
      "Step 00421: model improved\n",
      "  from 1.137471e+02\n",
      "    to 1.140689e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.140689e+02_episode00288\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.140689e+02_episode00288 has done.\n",
      "max mean_q value: 1.140689e+02\n",
      "========== /Model Saver output =============\n",
      " 421/861: episode: 289, duration: 0.086s, episode steps: 2, steps per second: 23, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 315662598144.000000, mean_q: 114.068924\n",
      " 421/861: episode: 289, duration: 0.087s, episode steps: 2, steps per second: 23, episode reward: 884805.349, mean reward: 442402.675 [-115203.451, 1000008.801], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 315662598144.000000, mean_q: 114.068924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "positions_buy_or_sell: 1\n",
      "reward: 1000004.287654\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115389.165002\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.144661e+02\n",
      "Step 00424: model improved\n",
      "  from 1.140689e+02\n",
      "    to 1.144661e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.144661e+02_episode00289\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.144661e+02_episode00289 has done.\n",
      "max mean_q value: 1.144661e+02\n",
      "========== /Model Saver output =============\n",
      " 424/861: episode: 290, duration: 0.091s, episode steps: 3, steps per second: 33, episode reward: 1884623.924, mean reward: 628207.975 [-115389.165, 1000008.801], mean action: 1.333 [0.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 235913216000.000000, mean_q: 114.466087\n",
      " 424/861: episode: 290, duration: 0.092s, episode steps: 3, steps per second: 33, episode reward: 1884623.924, mean reward: 628207.975 [-115389.165, 1000008.801], mean action: 1.333 [0.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 235913216000.000000, mean_q: 114.466087\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.147816e+02\n",
      "Step 00425: model improved\n",
      "  from 1.144661e+02\n",
      "    to 1.147816e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.147816e+02_episode00290\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.147816e+02_episode00290 has done.\n",
      "max mean_q value: 1.147816e+02\n",
      "========== /Model Saver output =============\n",
      " 425/861: episode: 291, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 215119888384.000000, mean_q: 114.781570\n",
      " 425/861: episode: 291, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 215119888384.000000, mean_q: 114.781570\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.149875e+02\n",
      "Step 00426: model improved\n",
      "  from 1.147816e+02\n",
      "    to 1.149875e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.149875e+02_episode00291\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.149875e+02_episode00291 has done.\n",
      "max mean_q value: 1.149875e+02\n",
      "========== /Model Saver output =============\n",
      " 426/861: episode: 292, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 284815392768.000000, mean_q: 114.987473\n",
      " 426/861: episode: 292, duration: 0.057s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 284815392768.000000, mean_q: 114.987473\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.152599e+02\n",
      "Step 00427: model improved\n",
      "  from 1.149875e+02\n",
      "    to 1.152599e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.152599e+02_episode00292\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.152599e+02_episode00292 has done.\n",
      "max mean_q value: 1.152599e+02\n",
      "========== /Model Saver output =============\n",
      " 427/861: episode: 293, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 292853776384.000000, mean_q: 115.259918\n",
      " 427/861: episode: 293, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 292853776384.000000, mean_q: 115.259918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.153775e+02\n",
      "Step 00428: model improved\n",
      "  from 1.152599e+02\n",
      "    to 1.153775e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.153775e+02_episode00293\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.153775e+02_episode00293 has done.\n",
      "max mean_q value: 1.153775e+02\n",
      "========== /Model Saver output =============\n",
      " 428/861: episode: 294, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 215095328768.000000, mean_q: 115.377495\n",
      " 428/861: episode: 294, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 215095328768.000000, mean_q: 115.377495\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.155903e+02\n",
      "Step 00429: model improved\n",
      "  from 1.153775e+02\n",
      "    to 1.155903e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.155903e+02_episode00294\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.155903e+02_episode00294 has done.\n",
      "max mean_q value: 1.155903e+02\n",
      "========== /Model Saver output =============\n",
      " 429/861: episode: 295, duration: 0.048s, episode steps: 1, steps per second: 21, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 525398212608.000000, mean_q: 115.590302\n",
      " 429/861: episode: 295, duration: 0.049s, episode steps: 1, steps per second: 20, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 525398212608.000000, mean_q: 115.590302\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.158018e+02\n",
      "Step 00430: model improved\n",
      "  from 1.155903e+02\n",
      "    to 1.158018e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.158018e+02_episode00295\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.158018e+02_episode00295 has done.\n",
      "max mean_q value: 1.158018e+02\n",
      "========== /Model Saver output =============\n",
      " 430/861: episode: 296, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 401485594624.000000, mean_q: 115.801796\n",
      " 430/861: episode: 296, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 401485594624.000000, mean_q: 115.801796\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.160041e+02\n",
      "Step 00431: model improved\n",
      "  from 1.158018e+02\n",
      "    to 1.160041e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.160041e+02_episode00296\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.160041e+02_episode00296 has done.\n",
      "max mean_q value: 1.160041e+02\n",
      "========== /Model Saver output =============\n",
      " 431/861: episode: 297, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 145425383424.000000, mean_q: 116.004089\n",
      " 431/861: episode: 297, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 145425383424.000000, mean_q: 116.004089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000004.287654\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "reward: 2115212.026805\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115209.883738\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999992.370174\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_step 000004 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115234.805007\n",
      "now_datetime: 2017-10-02 00:20:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000004 [2017-10-02 00:20:00]\n",
      "   after: 000005 [2017-10-02 00:25:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999611.169627\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115601.082844\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.162011e+02\n",
      "Step 00432: model improved\n",
      "  from 1.160041e+02\n",
      "    to 1.162011e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.162011e+02_episode00297\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.162011e+02_episode00297 has done.\n",
      "max mean_q value: 1.162011e+02\n",
      "========== /Model Saver output =============\n",
      " 432/861: episode: 298, duration: 0.068s, episode steps: 1, steps per second: 15, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 595186548736.000000, mean_q: 116.201096\n",
      " 432/861: episode: 298, duration: 0.069s, episode steps: 1, steps per second: 14, episode reward: -115594.426, mean reward: -115594.426 [-115594.426, -115594.426], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 595186548736.000000, mean_q: 116.201096\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.166878e+02\n",
      "Step 00437: model improved\n",
      "  from 1.162011e+02\n",
      "    to 1.166878e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.166878e+02_episode00298\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.166878e+02_episode00298 has done.\n",
      "max mean_q value: 1.166878e+02\n",
      "========== /Model Saver output =============\n",
      " 437/861: episode: 299, duration: 0.146s, episode steps: 5, steps per second: 34, episode reward: 6115183.763, mean reward: 1223036.753 [-115234.805, 2115212.027], mean action: 1.400 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 360831090688.000000, mean_q: 116.687820\n",
      " 437/861: episode: 299, duration: 0.147s, episode steps: 5, steps per second: 34, episode reward: 6115183.763, mean reward: 1223036.753 [-115234.805, 2115212.027], mean action: 1.400 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 360831090688.000000, mean_q: 116.687820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999611.169627\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115601.082844\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999611.169627\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115601.082844\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999611.169627\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.172241e+02\n",
      "Step 00439: model improved\n",
      "  from 1.166878e+02\n",
      "    to 1.172241e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.172241e+02_episode00299\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.172241e+02_episode00299 has done.\n",
      "max mean_q value: 1.172241e+02\n",
      "========== /Model Saver output =============\n",
      " 439/861: episode: 300, duration: 0.083s, episode steps: 2, steps per second: 24, episode reward: 884010.087, mean reward: 442005.043 [-115601.083, 999611.170], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 261735268352.000000, mean_q: 117.224091\n",
      " 439/861: episode: 300, duration: 0.085s, episode steps: 2, steps per second: 24, episode reward: 884010.087, mean reward: 442005.043 [-115601.083, 999611.170], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 261735268352.000000, mean_q: 117.224091\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.175763e+02\n",
      "Step 00441: model improved\n",
      "  from 1.172241e+02\n",
      "    to 1.175763e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.175763e+02_episode00300\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.175763e+02_episode00300 has done.\n",
      "max mean_q value: 1.175763e+02\n",
      "========== /Model Saver output =============\n",
      " 441/861: episode: 301, duration: 0.081s, episode steps: 2, steps per second: 25, episode reward: 884010.087, mean reward: 442005.043 [-115601.083, 999611.170], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 366597111808.000000, mean_q: 117.576324\n",
      " 441/861: episode: 301, duration: 0.082s, episode steps: 2, steps per second: 24, episode reward: 884010.087, mean reward: 442005.043 [-115601.083, 999611.170], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 366597111808.000000, mean_q: 117.576324\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.178870e+02\n",
      "Step 00443: model improved\n",
      "  from 1.175763e+02\n",
      "    to 1.178870e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.178870e+02_episode00301\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.178870e+02_episode00301 has done.\n",
      "max mean_q value: 1.178870e+02\n",
      "========== /Model Saver output =============\n",
      " 443/861: episode: 302, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 884010.087, mean reward: 442005.043 [-115601.083, 999611.170], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 311939203072.000000, mean_q: 117.886993\n",
      " 443/861: episode: 302, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 884010.087, mean reward: 442005.043 [-115601.083, 999611.170], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 311939203072.000000, mean_q: 117.886993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115601.082844\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 3230808.597849\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 3230813.111169\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115419.658513\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000200.114333\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_step 000004 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115427.627914\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000004 [2017-10-02 00:20:00]\n",
      "   after: 000005 [2017-10-02 00:25:00]\n",
      "_step ENDED\n",
      "_step 000005 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 3230961.418779\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000005 [2017-10-02 00:25:00]\n",
      "   after: 000006 [2017-10-02 00:30:00]\n",
      "_step ENDED\n",
      "_step 000006 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115421.350693\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000006 [2017-10-02 00:30:00]\n",
      "   after: 000007 [2017-10-02 00:35:00]\n",
      "_step ENDED\n",
      "_step 000007 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999832.974977\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000007 [2017-10-02 00:35:00]\n",
      "   after: 000008 [2017-10-02 00:40:00]\n",
      "_step ENDED\n",
      "_step 000008 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115841.902946\n",
      "now_datetime: 2017-10-02 00:40:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.182486e+02\n",
      "Step 00445: model improved\n",
      "  from 1.178870e+02\n",
      "    to 1.182486e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.182486e+02_episode00302\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.182486e+02_episode00302 has done.\n",
      "max mean_q value: 1.182486e+02\n",
      "========== /Model Saver output =============\n",
      " 445/861: episode: 303, duration: 0.153s, episode steps: 2, steps per second: 13, episode reward: 884010.087, mean reward: 442005.043 [-115601.083, 999611.170], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 552619671552.000000, mean_q: 118.248596\n",
      " 445/861: episode: 303, duration: 0.154s, episode steps: 2, steps per second: 13, episode reward: 884010.087, mean reward: 442005.043 [-115601.083, 999611.170], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 552619671552.000000, mean_q: 118.248596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  before: 000008 [2017-10-02 00:40:00]\n",
      "   after: 000009 [2017-10-02 00:45:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115214.397058\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000002.144587\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115387.021175\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 3230813.111169\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115605.372018\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000214.062429\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115007.512025\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.189350e+02\n",
      "Step 00454: model improved\n",
      "  from 1.182486e+02\n",
      "    to 1.189350e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.189350e+02_episode00303\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.189350e+02_episode00303 has done.\n",
      "max mean_q value: 1.189350e+02\n",
      "========== /Model Saver output =============\n",
      " 454/861: episode: 304, duration: 0.219s, episode steps: 9, steps per second: 41, episode reward: 17923042.951, mean reward: 1991449.217 [-115841.903, 3230961.419], mean action: 1.556 [0.000, 2.000], mean observation: 58.908 [1.000, 112.841], loss: 299578458112.000000, mean_q: 118.935005\n",
      " 454/861: episode: 304, duration: 0.220s, episode steps: 9, steps per second: 41, episode reward: 17923042.951, mean reward: 1991449.217 [-115841.903, 3230961.419], mean action: 1.556 [0.000, 2.000], mean observation: 58.908 [1.000, 112.841], loss: 299578458112.000000, mean_q: 118.935005\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.197191e+02\n",
      "Step 00457: model improved\n",
      "  from 1.189350e+02\n",
      "    to 1.197191e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.197191e+02_episode00304\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.197191e+02_episode00304 has done.\n",
      "max mean_q value: 1.197191e+02\n",
      "========== /Model Saver output =============\n",
      " 457/861: episode: 305, duration: 0.095s, episode steps: 3, steps per second: 31, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 411498676224.000000, mean_q: 119.719116\n",
      " 457/861: episode: 305, duration: 0.096s, episode steps: 3, steps per second: 31, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 411498676224.000000, mean_q: 119.719116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115214.397058\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000002.144587\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115387.021175\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115214.397058\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000002.144587\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115387.021175\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.202103e+02\n",
      "Step 00461: model improved\n",
      "  from 1.197191e+02\n",
      "    to 1.202103e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.202103e+02_episode00305\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.202103e+02_episode00305 has done.\n",
      "max mean_q value: 1.202103e+02\n",
      "========== /Model Saver output =============\n",
      " 461/861: episode: 306, duration: 0.126s, episode steps: 4, steps per second: 32, episode reward: 6231625.034, mean reward: 1557906.258 [-115007.512, 3230813.111], mean action: 1.750 [1.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 461303087104.000000, mean_q: 120.210281\n",
      " 461/861: episode: 306, duration: 0.129s, episode steps: 4, steps per second: 31, episode reward: 6231625.034, mean reward: 1557906.258 [-115007.512, 3230813.111], mean action: 1.750 [1.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 461303087104.000000, mean_q: 120.210281\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.207527e+02\n",
      "Step 00464: model improved\n",
      "  from 1.202103e+02\n",
      "    to 1.207527e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.207527e+02_episode00306\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.207527e+02_episode00306 has done.\n",
      "max mean_q value: 1.207527e+02\n",
      "========== /Model Saver output =============\n",
      " 464/861: episode: 307, duration: 0.096s, episode steps: 3, steps per second: 31, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 331501633536.000000, mean_q: 120.752747\n",
      " 464/861: episode: 307, duration: 0.098s, episode steps: 3, steps per second: 30, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 331501633536.000000, mean_q: 120.752747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115214.397058\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000002.144587\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115387.021175\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115214.397058\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000002.144587\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115387.021175\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.212980e+02\n",
      "Step 00467: model improved\n",
      "  from 1.207527e+02\n",
      "    to 1.212980e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.212980e+02_episode00307\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.212980e+02_episode00307 has done.\n",
      "max mean_q value: 1.212980e+02\n",
      "========== /Model Saver output =============\n",
      " 467/861: episode: 308, duration: 0.097s, episode steps: 3, steps per second: 31, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 326150356992.000000, mean_q: 121.298035\n",
      " 467/861: episode: 308, duration: 0.098s, episode steps: 3, steps per second: 31, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 326150356992.000000, mean_q: 121.298035\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.217891e+02\n",
      "Step 00470: model improved\n",
      "  from 1.212980e+02\n",
      "    to 1.217891e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.217891e+02_episode00308\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.217891e+02_episode00308 has done.\n",
      "max mean_q value: 1.217891e+02\n",
      "========== /Model Saver output =============\n",
      " 470/861: episode: 309, duration: 0.091s, episode steps: 3, steps per second: 33, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 584679882752.000000, mean_q: 121.789055\n",
      " 470/861: episode: 309, duration: 0.091s, episode steps: 3, steps per second: 33, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 584679882752.000000, mean_q: 121.789055\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.222629e+02\n",
      "Step 00473: model improved\n",
      "  from 1.217891e+02\n",
      "    to 1.222629e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.222629e+02_episode00309\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.222629e+02_episode00309 has done.\n",
      "max mean_q value: 1.222629e+02\n",
      "========== /Model Saver output =============\n",
      " 473/861: episode: 310, duration: 0.093s, episode steps: 3, steps per second: 32, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 329070575616.000000, mean_q: 122.262939\n",
      " 473/861: episode: 310, duration: 0.093s, episode steps: 3, steps per second: 32, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 329070575616.000000, mean_q: 122.262939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115214.397058\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000002.144587\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115387.021175\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115214.397058\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000002.144587\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115387.021175\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115214.397058\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000002.144587\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115387.021175\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.226555e+02\n",
      "Step 00476: model improved\n",
      "  from 1.222629e+02\n",
      "    to 1.226555e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.226555e+02_episode00310\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.226555e+02_episode00310 has done.\n",
      "max mean_q value: 1.226555e+02\n",
      "========== /Model Saver output =============\n",
      " 476/861: episode: 311, duration: 0.102s, episode steps: 3, steps per second: 29, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 514943713280.000000, mean_q: 122.655457\n",
      " 476/861: episode: 311, duration: 0.102s, episode steps: 3, steps per second: 29, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 514943713280.000000, mean_q: 122.655457\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.231776e+02\n",
      "Step 00479: model improved\n",
      "  from 1.226555e+02\n",
      "    to 1.231776e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.231776e+02_episode00311\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.231776e+02_episode00311 has done.\n",
      "max mean_q value: 1.231776e+02\n",
      "========== /Model Saver output =============\n",
      " 479/861: episode: 312, duration: 0.109s, episode steps: 3, steps per second: 28, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 434756157440.000000, mean_q: 123.177551\n",
      " 479/861: episode: 312, duration: 0.111s, episode steps: 3, steps per second: 27, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 434756157440.000000, mean_q: 123.177551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115214.397058\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000002.144587\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115387.021175\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115214.397058\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000002.144587\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115387.021175\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.236796e+02\n",
      "Step 00482: model improved\n",
      "  from 1.231776e+02\n",
      "    to 1.236796e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.236796e+02_episode00312\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.236796e+02_episode00312 has done.\n",
      "max mean_q value: 1.236796e+02\n",
      "========== /Model Saver output =============\n",
      " 482/861: episode: 313, duration: 0.092s, episode steps: 3, steps per second: 33, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 543341051904.000000, mean_q: 123.679649\n",
      " 482/861: episode: 313, duration: 0.093s, episode steps: 3, steps per second: 32, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 543341051904.000000, mean_q: 123.679649\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.242230e+02\n",
      "Step 00485: model improved\n",
      "  from 1.236796e+02\n",
      "    to 1.242230e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.242230e+02_episode00313\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.242230e+02_episode00313 has done.\n",
      "max mean_q value: 1.242230e+02\n",
      "========== /Model Saver output =============\n",
      " 485/861: episode: 314, duration: 0.088s, episode steps: 3, steps per second: 34, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 447659245568.000000, mean_q: 124.222954\n",
      " 485/861: episode: 314, duration: 0.089s, episode steps: 3, steps per second: 34, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 447659245568.000000, mean_q: 124.222954\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.247776e+02\n",
      "Step 00488: model improved\n",
      "  from 1.242230e+02\n",
      "    to 1.247776e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.247776e+02_episode00314\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.247776e+02_episode00314 has done.\n",
      "max mean_q value: 1.247776e+02\n",
      "========== /Model Saver output =============\n",
      " 488/861: episode: 315, duration: 0.096s, episode steps: 3, steps per second: 31, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 460637241344.000000, mean_q: 124.777618\n",
      " 488/861: episode: 315, duration: 0.097s, episode steps: 3, steps per second: 31, episode reward: 2999829.520, mean reward: 999943.173 [-115387.021, 2115214.397], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 460637241344.000000, mean_q: 124.777618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115214.397058\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115209.883738\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999816.431082\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115403.113098\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999611.169627\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115601.082844\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115209.883738\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000002.144587\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115389.165002\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.254506e+02\n",
      "Step 00492: model improved\n",
      "  from 1.247776e+02\n",
      "    to 1.254506e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.254506e+02_episode00315\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.254506e+02_episode00315 has done.\n",
      "max mean_q value: 1.254506e+02\n",
      "========== /Model Saver output =============\n",
      " 492/861: episode: 316, duration: 0.108s, episode steps: 4, steps per second: 37, episode reward: 5114837.599, mean reward: 1278709.400 [-115403.113, 2115214.397], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 434115248128.000000, mean_q: 125.450592\n",
      " 492/861: episode: 316, duration: 0.110s, episode steps: 4, steps per second: 37, episode reward: 5114837.599, mean reward: 1278709.400 [-115403.113, 2115214.397], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 434115248128.000000, mean_q: 125.450592\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.260103e+02\n",
      "Step 00494: model improved\n",
      "  from 1.254506e+02\n",
      "    to 1.260103e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.260103e+02_episode00316\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.260103e+02_episode00316 has done.\n",
      "max mean_q value: 1.260103e+02\n",
      "========== /Model Saver output =============\n",
      " 494/861: episode: 317, duration: 0.066s, episode steps: 2, steps per second: 30, episode reward: 884010.087, mean reward: 442005.043 [-115601.083, 999611.170], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 381987651584.000000, mean_q: 126.010284\n",
      " 494/861: episode: 317, duration: 0.067s, episode steps: 2, steps per second: 30, episode reward: 884010.087, mean reward: 442005.043 [-115601.083, 999611.170], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 381987651584.000000, mean_q: 126.010284\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.264635e+02\n",
      "Step 00497: model improved\n",
      "  from 1.260103e+02\n",
      "    to 1.264635e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.264635e+02_episode00317\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.264635e+02_episode00317 has done.\n",
      "max mean_q value: 1.264635e+02\n",
      "========== /Model Saver output =============\n",
      " 497/861: episode: 318, duration: 0.099s, episode steps: 3, steps per second: 30, episode reward: 2999822.863, mean reward: 999940.954 [-115389.165, 2115209.884], mean action: 1.667 [1.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 344447320064.000000, mean_q: 126.463539\n",
      " 497/861: episode: 318, duration: 0.099s, episode steps: 3, steps per second: 30, episode reward: 2999822.863, mean reward: 999940.954 [-115389.165, 2115209.884], mean action: 1.667 [1.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 344447320064.000000, mean_q: 126.463539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999611.169627\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115601.082844\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999611.169627\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115601.082844\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999611.169627\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115601.082844\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999611.169627\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.268811e+02\n",
      "Step 00499: model improved\n",
      "  from 1.264635e+02\n",
      "    to 1.268811e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.268811e+02_episode00318\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.268811e+02_episode00318 has done.\n",
      "max mean_q value: 1.268811e+02\n",
      "========== /Model Saver output =============\n",
      " 499/861: episode: 319, duration: 0.075s, episode steps: 2, steps per second: 27, episode reward: 884010.087, mean reward: 442005.043 [-115601.083, 999611.170], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 219151269888.000000, mean_q: 126.881073\n",
      " 499/861: episode: 319, duration: 0.076s, episode steps: 2, steps per second: 26, episode reward: 884010.087, mean reward: 442005.043 [-115601.083, 999611.170], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 219151269888.000000, mean_q: 126.881073\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.272481e+02\n",
      "Step 00501: model improved\n",
      "  from 1.268811e+02\n",
      "    to 1.272481e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.272481e+02_episode00319\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.272481e+02_episode00319 has done.\n",
      "max mean_q value: 1.272481e+02\n",
      "========== /Model Saver output =============\n",
      " 501/861: episode: 320, duration: 0.068s, episode steps: 2, steps per second: 29, episode reward: 884010.087, mean reward: 442005.043 [-115601.083, 999611.170], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 424595226624.000000, mean_q: 127.248077\n",
      " 501/861: episode: 320, duration: 0.069s, episode steps: 2, steps per second: 29, episode reward: 884010.087, mean reward: 442005.043 [-115601.083, 999611.170], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 424595226624.000000, mean_q: 127.248077\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.275852e+02\n",
      "Step 00503: model improved\n",
      "  from 1.272481e+02\n",
      "    to 1.275852e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.275852e+02_episode00320\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.275852e+02_episode00320 has done.\n",
      "max mean_q value: 1.275852e+02\n",
      "========== /Model Saver output =============\n",
      " 503/861: episode: 321, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 884010.087, mean reward: 442005.043 [-115601.083, 999611.170], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 478516019200.000000, mean_q: 127.585205\n",
      " 503/861: episode: 321, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 884010.087, mean reward: 442005.043 [-115601.083, 999611.170], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 478516019200.000000, mean_q: 127.585205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "positions_buy_or_sell: 1\n",
      "reward: 2114814.395458\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2114814.396218\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999596.882654\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_step 000004 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115630.292527\n",
      "now_datetime: 2017-10-02 00:20:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000004 [2017-10-02 00:20:00]\n",
      "   after: 000005 [2017-10-02 00:25:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.281704e+02\n",
      "Step 00508: model improved\n",
      "  from 1.275852e+02\n",
      "    to 1.281704e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.281704e+02_episode00321\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.281704e+02_episode00321 has done.\n",
      "max mean_q value: 1.281704e+02\n",
      "========== /Model Saver output =============\n",
      " 508/861: episode: 322, duration: 0.136s, episode steps: 5, steps per second: 37, episode reward: 6113206.551, mean reward: 1222641.310 [-115630.293, 2114814.396], mean action: 1.400 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 380903686144.000000, mean_q: 128.170441\n",
      " 508/861: episode: 322, duration: 0.137s, episode steps: 5, steps per second: 36, episode reward: 6113206.551, mean reward: 1222641.310 [-115630.293, 2114814.396], mean action: 1.400 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 380903686144.000000, mean_q: 128.170441\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.288200e+02\n",
      "Step 00510: model improved\n",
      "  from 1.281704e+02\n",
      "    to 1.288200e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.288200e+02_episode00322\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.288200e+02_episode00322 has done.\n",
      "max mean_q value: 1.288200e+02\n",
      "========== /Model Saver output =============\n",
      " 510/861: episode: 323, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 370236915712.000000, mean_q: 128.819962\n",
      " 510/861: episode: 323, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 370236915712.000000, mean_q: 128.819962\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.292602e+02\n",
      "Step 00512: model improved\n",
      "  from 1.288200e+02\n",
      "    to 1.292602e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.292602e+02_episode00323\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.292602e+02_episode00323 has done.\n",
      "max mean_q value: 1.292602e+02\n",
      "========== /Model Saver output =============\n",
      " 512/861: episode: 324, duration: 0.070s, episode steps: 2, steps per second: 29, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 401114169344.000000, mean_q: 129.260162\n",
      " 512/861: episode: 324, duration: 0.072s, episode steps: 2, steps per second: 28, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 401114169344.000000, mean_q: 129.260162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.296823e+02\n",
      "Step 00514: model improved\n",
      "  from 1.292602e+02\n",
      "    to 1.296823e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.296823e+02_episode00324\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.296823e+02_episode00324 has done.\n",
      "max mean_q value: 1.296823e+02\n",
      "========== /Model Saver output =============\n",
      " 514/861: episode: 325, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 506016366592.000000, mean_q: 129.682251\n",
      " 514/861: episode: 325, duration: 0.079s, episode steps: 2, steps per second: 25, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 506016366592.000000, mean_q: 129.682251\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.300324e+02\n",
      "Step 00516: model improved\n",
      "  from 1.296823e+02\n",
      "    to 1.300324e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.300324e+02_episode00325\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.300324e+02_episode00325 has done.\n",
      "max mean_q value: 1.300324e+02\n",
      "========== /Model Saver output =============\n",
      " 516/861: episode: 326, duration: 0.070s, episode steps: 2, steps per second: 29, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 525092028416.000000, mean_q: 130.032425\n",
      " 516/861: episode: 326, duration: 0.071s, episode steps: 2, steps per second: 28, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 525092028416.000000, mean_q: 130.032425\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.305027e+02\n",
      "Step 00518: model improved\n",
      "  from 1.300324e+02\n",
      "    to 1.305027e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.305027e+02_episode00326\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.305027e+02_episode00326 has done.\n",
      "max mean_q value: 1.305027e+02\n",
      "========== /Model Saver output =============\n",
      " 518/861: episode: 327, duration: 0.076s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 261682298880.000000, mean_q: 130.502747\n",
      " 518/861: episode: 327, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 261682298880.000000, mean_q: 130.502747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.309371e+02\n",
      "Step 00520: model improved\n",
      "  from 1.305027e+02\n",
      "    to 1.309371e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.309371e+02_episode00327\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.309371e+02_episode00327 has done.\n",
      "max mean_q value: 1.309371e+02\n",
      "========== /Model Saver output =============\n",
      " 520/861: episode: 328, duration: 0.068s, episode steps: 2, steps per second: 29, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 339442663424.000000, mean_q: 130.937134\n",
      " 520/861: episode: 328, duration: 0.069s, episode steps: 2, steps per second: 29, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 339442663424.000000, mean_q: 130.937134\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.313341e+02\n",
      "Step 00522: model improved\n",
      "  from 1.309371e+02\n",
      "    to 1.313341e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.313341e+02_episode00328\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.313341e+02_episode00328 has done.\n",
      "max mean_q value: 1.313341e+02\n",
      "========== /Model Saver output =============\n",
      " 522/861: episode: 329, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 509673111552.000000, mean_q: 131.334122\n",
      " 522/861: episode: 329, duration: 0.079s, episode steps: 2, steps per second: 25, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 509673111552.000000, mean_q: 131.334122\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.316748e+02\n",
      "Step 00524: model improved\n",
      "  from 1.313341e+02\n",
      "    to 1.316748e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.316748e+02_episode00329\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.316748e+02_episode00329 has done.\n",
      "max mean_q value: 1.316748e+02\n",
      "========== /Model Saver output =============\n",
      " 524/861: episode: 330, duration: 0.080s, episode steps: 2, steps per second: 25, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 490257645568.000000, mean_q: 131.674820\n",
      " 524/861: episode: 330, duration: 0.081s, episode steps: 2, steps per second: 25, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 490257645568.000000, mean_q: 131.674820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.321198e+02\n",
      "Step 00526: model improved\n",
      "  from 1.316748e+02\n",
      "    to 1.321198e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.321198e+02_episode00330\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.321198e+02_episode00330 has done.\n",
      "max mean_q value: 1.321198e+02\n",
      "========== /Model Saver output =============\n",
      " 526/861: episode: 331, duration: 0.073s, episode steps: 2, steps per second: 27, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 362531913728.000000, mean_q: 132.119766\n",
      " 526/861: episode: 331, duration: 0.074s, episode steps: 2, steps per second: 27, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 362531913728.000000, mean_q: 132.119766\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.324037e+02\n",
      "Step 00528: model improved\n",
      "  from 1.321198e+02\n",
      "    to 1.324037e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.324037e+02_episode00331\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.324037e+02_episode00331 has done.\n",
      "max mean_q value: 1.324037e+02\n",
      "========== /Model Saver output =============\n",
      " 528/861: episode: 332, duration: 0.069s, episode steps: 2, steps per second: 29, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 284795797504.000000, mean_q: 132.403748\n",
      " 528/861: episode: 332, duration: 0.069s, episode steps: 2, steps per second: 29, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 284795797504.000000, mean_q: 132.403748\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.327859e+02\n",
      "Step 00530: model improved\n",
      "  from 1.324037e+02\n",
      "    to 1.327859e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.327859e+02_episode00332\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.327859e+02_episode00332 has done.\n",
      "max mean_q value: 1.327859e+02\n",
      "========== /Model Saver output =============\n",
      " 530/861: episode: 333, duration: 0.081s, episode steps: 2, steps per second: 25, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 544538722304.000000, mean_q: 132.785950\n",
      " 530/861: episode: 333, duration: 0.081s, episode steps: 2, steps per second: 25, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 544538722304.000000, mean_q: 132.785950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.331210e+02\n",
      "Step 00532: model improved\n",
      "  from 1.327859e+02\n",
      "    to 1.331210e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.331210e+02_episode00333\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.331210e+02_episode00333 has done.\n",
      "max mean_q value: 1.331210e+02\n",
      "========== /Model Saver output =============\n",
      " 532/861: episode: 334, duration: 0.082s, episode steps: 2, steps per second: 24, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 412840034304.000000, mean_q: 133.121002\n",
      " 532/861: episode: 334, duration: 0.088s, episode steps: 2, steps per second: 23, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 412840034304.000000, mean_q: 133.121002\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.334987e+02\n",
      "Step 00534: model improved\n",
      "  from 1.331210e+02\n",
      "    to 1.334987e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.334987e+02_episode00334\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.334987e+02_episode00334 has done.\n",
      "max mean_q value: 1.334987e+02\n",
      "========== /Model Saver output =============\n",
      " 534/861: episode: 335, duration: 0.071s, episode steps: 2, steps per second: 28, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 575332286464.000000, mean_q: 133.498688\n",
      " 534/861: episode: 335, duration: 0.072s, episode steps: 2, steps per second: 28, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 575332286464.000000, mean_q: 133.498688\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.339350e+02\n",
      "Step 00536: model improved\n",
      "  from 1.334987e+02\n",
      "    to 1.339350e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.339350e+02_episode00335\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.339350e+02_episode00335 has done.\n",
      "max mean_q value: 1.339350e+02\n",
      "========== /Model Saver output =============\n",
      " 536/861: episode: 336, duration: 0.071s, episode steps: 2, steps per second: 28, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 436302708736.000000, mean_q: 133.934998\n",
      " 536/861: episode: 336, duration: 0.071s, episode steps: 2, steps per second: 28, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 436302708736.000000, mean_q: 133.934998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.343648e+02\n",
      "Step 00538: model improved\n",
      "  from 1.339350e+02\n",
      "    to 1.343648e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.343648e+02_episode00336\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.343648e+02_episode00336 has done.\n",
      "max mean_q value: 1.343648e+02\n",
      "========== /Model Saver output =============\n",
      " 538/861: episode: 337, duration: 0.073s, episode steps: 2, steps per second: 27, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 308265615360.000000, mean_q: 134.364807\n",
      " 538/861: episode: 337, duration: 0.074s, episode steps: 2, steps per second: 27, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 308265615360.000000, mean_q: 134.364807\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.346835e+02\n",
      "Step 00540: model improved\n",
      "  from 1.343648e+02\n",
      "    to 1.346835e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.346835e+02_episode00337\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.346835e+02_episode00337 has done.\n",
      "max mean_q value: 1.346835e+02\n",
      "========== /Model Saver output =============\n",
      " 540/861: episode: 338, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 358487293952.000000, mean_q: 134.683456\n",
      " 540/861: episode: 338, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 358487293952.000000, mean_q: 134.683456\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.351281e+02\n",
      "Step 00542: model improved\n",
      "  from 1.346835e+02\n",
      "    to 1.351281e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.351281e+02_episode00338\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.351281e+02_episode00338 has done.\n",
      "max mean_q value: 1.351281e+02\n",
      "========== /Model Saver output =============\n",
      " 542/861: episode: 339, duration: 0.079s, episode steps: 2, steps per second: 25, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 412795338752.000000, mean_q: 135.128098\n",
      " 542/861: episode: 339, duration: 0.080s, episode steps: 2, steps per second: 25, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 412795338752.000000, mean_q: 135.128098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114814.396218\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.354467e+02\n",
      "Step 00544: model improved\n",
      "  from 1.351281e+02\n",
      "    to 1.354467e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.354467e+02_episode00339\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.354467e+02_episode00339 has done.\n",
      "max mean_q value: 1.354467e+02\n",
      "========== /Model Saver output =============\n",
      " 544/861: episode: 340, duration: 0.073s, episode steps: 2, steps per second: 28, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 738193571840.000000, mean_q: 135.446716\n",
      " 544/861: episode: 340, duration: 0.074s, episode steps: 2, steps per second: 27, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 738193571840.000000, mean_q: 135.446716\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.358638e+02\n",
      "Step 00546: model improved\n",
      "  from 1.354467e+02\n",
      "    to 1.358638e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.358638e+02_episode00340\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.358638e+02_episode00340 has done.\n",
      "max mean_q value: 1.358638e+02\n",
      "========== /Model Saver output =============\n",
      " 546/861: episode: 341, duration: 0.074s, episode steps: 2, steps per second: 27, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 478473158656.000000, mean_q: 135.863815\n",
      " 546/861: episode: 341, duration: 0.075s, episode steps: 2, steps per second: 27, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 478473158656.000000, mean_q: 135.863815\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.362621e+02\n",
      "Step 00548: model improved\n",
      "  from 1.358638e+02\n",
      "    to 1.362621e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.362621e+02_episode00341\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.362621e+02_episode00341 has done.\n",
      "max mean_q value: 1.362621e+02\n",
      "========== /Model Saver output =============\n",
      " 548/861: episode: 342, duration: 0.076s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 548543856640.000000, mean_q: 136.262070\n",
      " 548/861: episode: 342, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 548543856640.000000, mean_q: 136.262070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999606.657067\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115784.652522\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.367506e+02\n",
      "Step 00551: model improved\n",
      "  from 1.362621e+02\n",
      "    to 1.367506e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.367506e+02_episode00342\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.367506e+02_episode00342 has done.\n",
      "max mean_q value: 1.367506e+02\n",
      "========== /Model Saver output =============\n",
      " 551/861: episode: 343, duration: 0.105s, episode steps: 3, steps per second: 29, episode reward: 2998636.401, mean reward: 999545.467 [-115784.653, 2114814.396], mean action: 1.667 [1.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 385784643584.000000, mean_q: 136.750610\n",
      " 551/861: episode: 343, duration: 0.105s, episode steps: 3, steps per second: 28, episode reward: 2998636.401, mean reward: 999545.467 [-115784.653, 2114814.396], mean action: 1.667 [1.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 385784643584.000000, mean_q: 136.750610\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.372418e+02\n",
      "Step 00553: model improved\n",
      "  from 1.367506e+02\n",
      "    to 1.372418e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.372418e+02_episode00343\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.372418e+02_episode00343 has done.\n",
      "max mean_q value: 1.372418e+02\n",
      "========== /Model Saver output =============\n",
      " 553/861: episode: 344, duration: 0.076s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 401087004672.000000, mean_q: 137.241760\n",
      " 553/861: episode: 344, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 401087004672.000000, mean_q: 137.241760\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.376033e+02\n",
      "Step 00555: model improved\n",
      "  from 1.372418e+02\n",
      "    to 1.376033e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.376033e+02_episode00344\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.376033e+02_episode00344 has done.\n",
      "max mean_q value: 1.376033e+02\n",
      "========== /Model Saver output =============\n",
      " 555/861: episode: 345, duration: 0.075s, episode steps: 2, steps per second: 27, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 524735545344.000000, mean_q: 137.603302\n",
      " 555/861: episode: 345, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 524735545344.000000, mean_q: 137.603302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.380421e+02\n",
      "Step 00557: model improved\n",
      "  from 1.376033e+02\n",
      "    to 1.380421e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.380421e+02_episode00345\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.380421e+02_episode00345 has done.\n",
      "max mean_q value: 1.380421e+02\n",
      "========== /Model Saver output =============\n",
      " 557/861: episode: 346, duration: 0.075s, episode steps: 2, steps per second: 27, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 296142700544.000000, mean_q: 138.042084\n",
      " 557/861: episode: 346, duration: 0.076s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 296142700544.000000, mean_q: 138.042084\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.384510e+02\n",
      "Step 00559: model improved\n",
      "  from 1.380421e+02\n",
      "    to 1.384510e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.384510e+02_episode00346\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.384510e+02_episode00346 has done.\n",
      "max mean_q value: 1.384510e+02\n",
      "========== /Model Saver output =============\n",
      " 559/861: episode: 347, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 335080423424.000000, mean_q: 138.451019\n",
      " 559/861: episode: 347, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 335080423424.000000, mean_q: 138.451019\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.388906e+02\n",
      "Step 00561: model improved\n",
      "  from 1.384510e+02\n",
      "    to 1.388906e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.388906e+02_episode00347\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.388906e+02_episode00347 has done.\n",
      "max mean_q value: 1.388906e+02\n",
      "========== /Model Saver output =============\n",
      " 561/861: episode: 348, duration: 0.094s, episode steps: 2, steps per second: 21, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 385283981312.000000, mean_q: 138.890625\n",
      " 561/861: episode: 348, duration: 0.095s, episode steps: 2, steps per second: 21, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 385283981312.000000, mean_q: 138.890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.392816e+02\n",
      "Step 00563: model improved\n",
      "  from 1.388906e+02\n",
      "    to 1.392816e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.392816e+02_episode00348\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.392816e+02_episode00348 has done.\n",
      "max mean_q value: 1.392816e+02\n",
      "========== /Model Saver output =============\n",
      " 563/861: episode: 349, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 365799473152.000000, mean_q: 139.281586\n",
      " 563/861: episode: 349, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 365799473152.000000, mean_q: 139.281586\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.398015e+02\n",
      "Step 00565: model improved\n",
      "  from 1.392816e+02\n",
      "    to 1.398015e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.398015e+02_episode00349\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.398015e+02_episode00349 has done.\n",
      "max mean_q value: 1.398015e+02\n",
      "========== /Model Saver output =============\n",
      " 565/861: episode: 350, duration: 0.055s, episode steps: 2, steps per second: 36, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 362512056320.000000, mean_q: 139.801483\n",
      " 565/861: episode: 350, duration: 0.056s, episode steps: 2, steps per second: 36, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 362512056320.000000, mean_q: 139.801483\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.401757e+02\n",
      "Step 00567: model improved\n",
      "  from 1.398015e+02\n",
      "    to 1.401757e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.401757e+02_episode00350\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.401757e+02_episode00350 has done.\n",
      "max mean_q value: 1.401757e+02\n",
      "========== /Model Saver output =============\n",
      " 567/861: episode: 351, duration: 0.055s, episode steps: 2, steps per second: 36, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 489826418688.000000, mean_q: 140.175735\n",
      " 567/861: episode: 351, duration: 0.056s, episode steps: 2, steps per second: 36, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 489826418688.000000, mean_q: 140.175735\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.405265e+02\n",
      "Step 00569: model improved\n",
      "  from 1.401757e+02\n",
      "    to 1.405265e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.405265e+02_episode00351\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.405265e+02_episode00351 has done.\n",
      "max mean_q value: 1.405265e+02\n",
      "========== /Model Saver output =============\n",
      " 569/861: episode: 352, duration: 0.051s, episode steps: 2, steps per second: 39, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 343124967424.000000, mean_q: 140.526489\n",
      " 569/861: episode: 352, duration: 0.051s, episode steps: 2, steps per second: 39, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 343124967424.000000, mean_q: 140.526489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.409961e+02\n",
      "Step 00571: model improved\n",
      "  from 1.405265e+02\n",
      "    to 1.409961e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.409961e+02_episode00352\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.409961e+02_episode00352 has done.\n",
      "max mean_q value: 1.409961e+02\n",
      "========== /Model Saver output =============\n",
      " 571/861: episode: 353, duration: 0.054s, episode steps: 2, steps per second: 37, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 497920573440.000000, mean_q: 140.996063\n",
      " 571/861: episode: 353, duration: 0.055s, episode steps: 2, steps per second: 37, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 497920573440.000000, mean_q: 140.996063\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.413716e+02\n",
      "Step 00573: model improved\n",
      "  from 1.409961e+02\n",
      "    to 1.413716e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.413716e+02_episode00353\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.413716e+02_episode00353 has done.\n",
      "max mean_q value: 1.413716e+02\n",
      "========== /Model Saver output =============\n",
      " 573/861: episode: 354, duration: 0.059s, episode steps: 2, steps per second: 34, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 532738342912.000000, mean_q: 141.371643\n",
      " 573/861: episode: 354, duration: 0.059s, episode steps: 2, steps per second: 34, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 532738342912.000000, mean_q: 141.371643\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.417865e+02\n",
      "Step 00575: model improved\n",
      "  from 1.413716e+02\n",
      "    to 1.417865e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.417865e+02_episode00354\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.417865e+02_episode00354 has done.\n",
      "max mean_q value: 1.417865e+02\n",
      "========== /Model Saver output =============\n",
      " 575/861: episode: 355, duration: 0.068s, episode steps: 2, steps per second: 30, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 439906533376.000000, mean_q: 141.786499\n",
      " 575/861: episode: 355, duration: 0.068s, episode steps: 2, steps per second: 29, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 439906533376.000000, mean_q: 141.786499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.422461e+02\n",
      "Step 00577: model improved\n",
      "  from 1.417865e+02\n",
      "    to 1.422461e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.422461e+02_episode00355\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.422461e+02_episode00355 has done.\n",
      "max mean_q value: 1.422461e+02\n",
      "========== /Model Saver output =============\n",
      " 577/861: episode: 356, duration: 0.073s, episode steps: 2, steps per second: 27, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 319277236224.000000, mean_q: 142.246124\n",
      " 577/861: episode: 356, duration: 0.074s, episode steps: 2, steps per second: 27, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 319277236224.000000, mean_q: 142.246124\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.426712e+02\n",
      "Step 00579: model improved\n",
      "  from 1.422461e+02\n",
      "    to 1.426712e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.426712e+02_episode00356\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.426712e+02_episode00356 has done.\n",
      "max mean_q value: 1.426712e+02\n",
      "========== /Model Saver output =============\n",
      " 579/861: episode: 357, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 373872001024.000000, mean_q: 142.671173\n",
      " 579/861: episode: 357, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 373872001024.000000, mean_q: 142.671173\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.432072e+02\n",
      "Step 00581: model improved\n",
      "  from 1.426712e+02\n",
      "    to 1.432072e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.432072e+02_episode00357\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.432072e+02_episode00357 has done.\n",
      "max mean_q value: 1.432072e+02\n",
      "========== /Model Saver output =============\n",
      " 581/861: episode: 358, duration: 0.078s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 532724776960.000000, mean_q: 143.207230\n",
      " 581/861: episode: 358, duration: 0.078s, episode steps: 2, steps per second: 25, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 532724776960.000000, mean_q: 143.207230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.435921e+02\n",
      "Step 00583: model improved\n",
      "  from 1.432072e+02\n",
      "    to 1.435921e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.435921e+02_episode00358\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.435921e+02_episode00358 has done.\n",
      "max mean_q value: 1.435921e+02\n",
      "========== /Model Saver output =============\n",
      " 583/861: episode: 359, duration: 0.087s, episode steps: 2, steps per second: 23, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 370220138496.000000, mean_q: 143.592102\n",
      " 583/861: episode: 359, duration: 0.088s, episode steps: 2, steps per second: 23, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 370220138496.000000, mean_q: 143.592102\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.439396e+02\n",
      "Step 00585: model improved\n",
      "  from 1.435921e+02\n",
      "    to 1.439396e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.439396e+02_episode00359\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.439396e+02_episode00359 has done.\n",
      "max mean_q value: 1.439396e+02\n",
      "========== /Model Saver output =============\n",
      " 585/861: episode: 360, duration: 0.084s, episode steps: 2, steps per second: 24, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 494147272704.000000, mean_q: 143.939621\n",
      " 585/861: episode: 360, duration: 0.086s, episode steps: 2, steps per second: 23, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 494147272704.000000, mean_q: 143.939621\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.444228e+02\n",
      "Step 00587: model improved\n",
      "  from 1.439396e+02\n",
      "    to 1.444228e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.444228e+02_episode00360\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.444228e+02_episode00360 has done.\n",
      "max mean_q value: 1.444228e+02\n",
      "========== /Model Saver output =============\n",
      " 587/861: episode: 361, duration: 0.076s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 428222742528.000000, mean_q: 144.422821\n",
      " 587/861: episode: 361, duration: 0.076s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 428222742528.000000, mean_q: 144.422821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.448171e+02\n",
      "Step 00589: model improved\n",
      "  from 1.444228e+02\n",
      "    to 1.448171e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.448171e+02_episode00361\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.448171e+02_episode00361 has done.\n",
      "max mean_q value: 1.448171e+02\n",
      "========== /Model Saver output =============\n",
      " 589/861: episode: 362, duration: 0.092s, episode steps: 2, steps per second: 22, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 393321381888.000000, mean_q: 144.817078\n",
      " 589/861: episode: 362, duration: 0.093s, episode steps: 2, steps per second: 21, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 393321381888.000000, mean_q: 144.817078\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.452139e+02\n",
      "Step 00591: model improved\n",
      "  from 1.448171e+02\n",
      "    to 1.452139e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.452139e+02_episode00362\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.452139e+02_episode00362 has done.\n",
      "max mean_q value: 1.452139e+02\n",
      "========== /Model Saver output =============\n",
      " 591/861: episode: 363, duration: 0.081s, episode steps: 2, steps per second: 25, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 432264445952.000000, mean_q: 145.213898\n",
      " 591/861: episode: 363, duration: 0.081s, episode steps: 2, steps per second: 25, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 432264445952.000000, mean_q: 145.213898\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.456070e+02\n",
      "Step 00593: model improved\n",
      "  from 1.452139e+02\n",
      "    to 1.456070e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.456070e+02_episode00363\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.456070e+02_episode00363 has done.\n",
      "max mean_q value: 1.456070e+02\n",
      "========== /Model Saver output =============\n",
      " 593/861: episode: 364, duration: 0.075s, episode steps: 2, steps per second: 27, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 362099507200.000000, mean_q: 145.606995\n",
      " 593/861: episode: 364, duration: 0.083s, episode steps: 2, steps per second: 24, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 362099507200.000000, mean_q: 145.606995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 3230413.110329\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 3230417.623649\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115024.170993\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999804.626813\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.461142e+02\n",
      "Step 00595: model improved\n",
      "  from 1.456070e+02\n",
      "    to 1.461142e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.461142e+02_episode00364\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.461142e+02_episode00364 has done.\n",
      "max mean_q value: 1.461142e+02\n",
      "========== /Model Saver output =============\n",
      " 595/861: episode: 365, duration: 0.075s, episode steps: 2, steps per second: 27, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 516891607040.000000, mean_q: 146.114227\n",
      " 595/861: episode: 365, duration: 0.076s, episode steps: 2, steps per second: 26, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 516891607040.000000, mean_q: 146.114227\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.464673e+02\n",
      "Step 00597: model improved\n",
      "  from 1.461142e+02\n",
      "    to 1.464673e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.464673e+02_episode00365\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.464673e+02_episode00365 has done.\n",
      "max mean_q value: 1.464673e+02\n",
      "========== /Model Saver output =============\n",
      " 597/861: episode: 366, duration: 0.070s, episode steps: 2, steps per second: 29, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 439898210304.000000, mean_q: 146.467285\n",
      " 597/861: episode: 366, duration: 0.071s, episode steps: 2, steps per second: 28, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 439898210304.000000, mean_q: 146.467285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000004 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115422.435556\n",
      "now_datetime: 2017-10-02 00:20:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000004 [2017-10-02 00:20:00]\n",
      "   after: 000005 [2017-10-02 00:25:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 3230417.623649\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115209.884498\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999818.574909\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115402.999545\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114818.909538\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999606.657067\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.470837e+02\n",
      "Step 00602: model improved\n",
      "  from 1.464673e+02\n",
      "    to 1.470837e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.470837e+02_episode00366\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.470837e+02_episode00366 has done.\n",
      "max mean_q value: 1.470837e+02\n",
      "========== /Model Saver output =============\n",
      " 602/861: episode: 367, duration: 0.154s, episode steps: 5, steps per second: 33, episode reward: 9460237.096, mean reward: 1892047.419 [-115422.436, 3230417.624], mean action: 1.600 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 399476752384.000000, mean_q: 147.083740\n",
      " 602/861: episode: 367, duration: 0.155s, episode steps: 5, steps per second: 32, episode reward: 9460237.096, mean reward: 1892047.419 [-115422.436, 3230417.624], mean action: 1.600 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 399476752384.000000, mean_q: 147.083740\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.478761e+02\n",
      "Step 00606: model improved\n",
      "  from 1.470837e+02\n",
      "    to 1.478761e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.478761e+02_episode00367\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.478761e+02_episode00367 has done.\n",
      "max mean_q value: 1.478761e+02\n",
      "========== /Model Saver output =============\n",
      " 606/861: episode: 368, duration: 0.124s, episode steps: 4, steps per second: 32, episode reward: 6230043.084, mean reward: 1557510.771 [-115403.000, 3230417.624], mean action: 1.750 [1.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 391705886720.000000, mean_q: 147.876144\n",
      " 606/861: episode: 368, duration: 0.125s, episode steps: 4, steps per second: 32, episode reward: 6230043.084, mean reward: 1557510.771 [-115403.000, 3230417.624], mean action: 1.750 [1.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 391705886720.000000, mean_q: 147.876144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115782.508695\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114818.909538\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999606.657067\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115782.508695\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114818.909538\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999606.657067\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115782.508695\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.484863e+02\n",
      "Step 00609: model improved\n",
      "  from 1.478761e+02\n",
      "    to 1.484863e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.484863e+02_episode00368\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.484863e+02_episode00368 has done.\n",
      "max mean_q value: 1.484863e+02\n",
      "========== /Model Saver output =============\n",
      " 609/861: episode: 369, duration: 0.133s, episode steps: 3, steps per second: 23, episode reward: 2998643.058, mean reward: 999547.686 [-115782.509, 2114818.910], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 403557023744.000000, mean_q: 148.486313\n",
      " 609/861: episode: 369, duration: 0.134s, episode steps: 3, steps per second: 22, episode reward: 2998643.058, mean reward: 999547.686 [-115782.509, 2114818.910], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 403557023744.000000, mean_q: 148.486313\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.490518e+02\n",
      "Step 00612: model improved\n",
      "  from 1.484863e+02\n",
      "    to 1.490518e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.490518e+02_episode00369\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.490518e+02_episode00369 has done.\n",
      "max mean_q value: 1.490518e+02\n",
      "========== /Model Saver output =============\n",
      " 612/861: episode: 370, duration: 0.115s, episode steps: 3, steps per second: 26, episode reward: 2998643.058, mean reward: 999547.686 [-115782.509, 2114818.910], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 336660692992.000000, mean_q: 149.051804\n",
      " 612/861: episode: 370, duration: 0.117s, episode steps: 3, steps per second: 26, episode reward: 2998643.058, mean reward: 999547.686 [-115782.509, 2114818.910], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 336660692992.000000, mean_q: 149.051804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114818.909538\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999606.657067\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115782.508695\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114818.909538\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999606.657067\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115782.508695\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.495587e+02\n",
      "Step 00615: model improved\n",
      "  from 1.490518e+02\n",
      "    to 1.495587e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.495587e+02_episode00370\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.495587e+02_episode00370 has done.\n",
      "max mean_q value: 1.495587e+02\n",
      "========== /Model Saver output =============\n",
      " 615/861: episode: 371, duration: 0.092s, episode steps: 3, steps per second: 32, episode reward: 2998643.058, mean reward: 999547.686 [-115782.509, 2114818.910], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 659379519488.000000, mean_q: 149.558731\n",
      " 615/861: episode: 371, duration: 0.094s, episode steps: 3, steps per second: 32, episode reward: 2998643.058, mean reward: 999547.686 [-115782.509, 2114818.910], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 659379519488.000000, mean_q: 149.558731\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.500781e+02\n",
      "Step 00618: model improved\n",
      "  from 1.495587e+02\n",
      "    to 1.500781e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.500781e+02_episode00371\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.500781e+02_episode00371 has done.\n",
      "max mean_q value: 1.500781e+02\n",
      "========== /Model Saver output =============\n",
      " 618/861: episode: 372, duration: 0.085s, episode steps: 3, steps per second: 35, episode reward: 2998643.058, mean reward: 999547.686 [-115782.509, 2114818.910], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 587274977280.000000, mean_q: 150.078140\n",
      " 618/861: episode: 372, duration: 0.086s, episode steps: 3, steps per second: 35, episode reward: 2998643.058, mean reward: 999547.686 [-115782.509, 2114818.910], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 587274977280.000000, mean_q: 150.078140\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.505603e+02\n",
      "Step 00621: model improved\n",
      "  from 1.500781e+02\n",
      "    to 1.505603e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.505603e+02_episode00372\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.505603e+02_episode00372 has done.\n",
      "max mean_q value: 1.505603e+02\n",
      "========== /Model Saver output =============\n",
      " 621/861: episode: 373, duration: 0.087s, episode steps: 3, steps per second: 35, episode reward: 2998643.058, mean reward: 999547.686 [-115782.509, 2114818.910], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 264146960384.000000, mean_q: 150.560318\n",
      " 621/861: episode: 373, duration: 0.088s, episode steps: 3, steps per second: 34, episode reward: 2998643.058, mean reward: 999547.686 [-115782.509, 2114818.910], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 264146960384.000000, mean_q: 150.560318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114818.909538\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2114814.396218\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999420.943562\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115798.600618\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114814.396218\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999606.657067\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115784.652522\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.511871e+02\n",
      "Step 00625: model improved\n",
      "  from 1.505603e+02\n",
      "    to 1.511871e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.511871e+02_episode00373\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.511871e+02_episode00373 has done.\n",
      "max mean_q value: 1.511871e+02\n",
      "========== /Model Saver output =============\n",
      " 625/861: episode: 374, duration: 0.098s, episode steps: 4, steps per second: 41, episode reward: 5113255.649, mean reward: 1278313.912 [-115798.601, 2114818.910], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 476385181696.000000, mean_q: 151.187073\n",
      " 625/861: episode: 374, duration: 0.099s, episode steps: 4, steps per second: 40, episode reward: 5113255.649, mean reward: 1278313.912 [-115798.601, 2114818.910], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 476385181696.000000, mean_q: 151.187073\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.516745e+02\n",
      "Step 00627: model improved\n",
      "  from 1.511871e+02\n",
      "    to 1.516745e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.516745e+02_episode00374\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.516745e+02_episode00374 has done.\n",
      "max mean_q value: 1.516745e+02\n",
      "========== /Model Saver output =============\n",
      " 627/861: episode: 375, duration: 0.062s, episode steps: 2, steps per second: 32, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 408764514304.000000, mean_q: 151.674530\n",
      " 627/861: episode: 375, duration: 0.063s, episode steps: 2, steps per second: 32, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 408764514304.000000, mean_q: 151.674530\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.522260e+02\n",
      "Step 00630: model improved\n",
      "  from 1.516745e+02\n",
      "    to 1.522260e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.522260e+02_episode00375\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.522260e+02_episode00375 has done.\n",
      "max mean_q value: 1.522260e+02\n",
      "========== /Model Saver output =============\n",
      " 630/861: episode: 376, duration: 0.083s, episode steps: 3, steps per second: 36, episode reward: 2998636.401, mean reward: 999545.467 [-115784.653, 2114814.396], mean action: 1.667 [1.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 282554105856.000000, mean_q: 152.226028\n",
      " 630/861: episode: 376, duration: 0.084s, episode steps: 3, steps per second: 36, episode reward: 2998636.401, mean reward: 999545.467 [-115784.653, 2114814.396], mean action: 1.667 [1.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 282554105856.000000, mean_q: 152.226028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.525900e+02\n",
      "Step 00632: model improved\n",
      "  from 1.522260e+02\n",
      "    to 1.525900e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.525900e+02_episode00376\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.525900e+02_episode00376 has done.\n",
      "max mean_q value: 1.525900e+02\n",
      "========== /Model Saver output =============\n",
      " 632/861: episode: 377, duration: 0.080s, episode steps: 2, steps per second: 25, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 397026820096.000000, mean_q: 152.589996\n",
      " 632/861: episode: 377, duration: 0.080s, episode steps: 2, steps per second: 25, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 397026820096.000000, mean_q: 152.589996\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.528809e+02\n",
      "Step 00634: model improved\n",
      "  from 1.525900e+02\n",
      "    to 1.528809e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.528809e+02_episode00377\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.528809e+02_episode00377 has done.\n",
      "max mean_q value: 1.528809e+02\n",
      "========== /Model Saver output =============\n",
      " 634/861: episode: 378, duration: 0.098s, episode steps: 2, steps per second: 20, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 579309142016.000000, mean_q: 152.880859\n",
      " 634/861: episode: 378, duration: 0.099s, episode steps: 2, steps per second: 20, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 579309142016.000000, mean_q: 152.880859\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.532455e+02\n",
      "Step 00636: model improved\n",
      "  from 1.528809e+02\n",
      "    to 1.532455e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.532455e+02_episode00378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.532455e+02_episode00378 has done.\n",
      "max mean_q value: 1.532455e+02\n",
      "========== /Model Saver output =============\n",
      " 636/861: episode: 379, duration: 0.095s, episode steps: 2, steps per second: 21, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 257591820288.000000, mean_q: 153.245468\n",
      " 636/861: episode: 379, duration: 0.097s, episode steps: 2, steps per second: 21, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 257591820288.000000, mean_q: 153.245468\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.536034e+02\n",
      "Step 00638: model improved\n",
      "  from 1.532455e+02\n",
      "    to 1.536034e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.536034e+02_episode00379\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.536034e+02_episode00379 has done.\n",
      "max mean_q value: 1.536034e+02\n",
      "========== /Model Saver output =============\n",
      " 638/861: episode: 380, duration: 0.094s, episode steps: 2, steps per second: 21, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 529385324544.000000, mean_q: 153.603363\n",
      " 638/861: episode: 380, duration: 0.095s, episode steps: 2, steps per second: 21, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 529385324544.000000, mean_q: 153.603363\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.539325e+02\n",
      "Step 00640: model improved\n",
      "  from 1.536034e+02\n",
      "    to 1.539325e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.539325e+02_episode00380\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.539325e+02_episode00380 has done.\n",
      "max mean_q value: 1.539325e+02\n",
      "========== /Model Saver output =============\n",
      " 640/861: episode: 381, duration: 0.098s, episode steps: 2, steps per second: 20, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 428176637952.000000, mean_q: 153.932480\n",
      " 640/861: episode: 381, duration: 0.098s, episode steps: 2, steps per second: 20, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 428176637952.000000, mean_q: 153.932480"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.543865e+02\n",
      "Step 00642: model improved\n",
      "  from 1.539325e+02\n",
      "    to 1.543865e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.543865e+02_episode00381\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.543865e+02_episode00381 has done.\n",
      "max mean_q value: 1.543865e+02\n",
      "========== /Model Saver output =============\n",
      " 642/861: episode: 382, duration: 0.085s, episode steps: 2, steps per second: 24, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 273386045440.000000, mean_q: 154.386505\n",
      " 642/861: episode: 382, duration: 0.086s, episode steps: 2, steps per second: 23, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 273386045440.000000, mean_q: 154.386505\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.548017e+02\n",
      "Step 00644: model improved\n",
      "  from 1.543865e+02\n",
      "    to 1.548017e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.548017e+02_episode00382\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.548017e+02_episode00382 has done.\n",
      "max mean_q value: 1.548017e+02\n",
      "========== /Model Saver output =============\n",
      " 644/861: episode: 383, duration: 0.062s, episode steps: 2, steps per second: 32, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 462981562368.000000, mean_q: 154.801697\n",
      " 644/861: episode: 383, duration: 0.063s, episode steps: 2, steps per second: 32, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 462981562368.000000, mean_q: 154.801697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.550742e+02\n",
      "Step 00646: model improved\n",
      "  from 1.548017e+02\n",
      "    to 1.550742e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.550742e+02_episode00383\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.550742e+02_episode00383 has done.\n",
      "max mean_q value: 1.550742e+02\n",
      "========== /Model Saver output =============\n",
      " 646/861: episode: 384, duration: 0.062s, episode steps: 2, steps per second: 33, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 307787497472.000000, mean_q: 155.074203\n",
      " 646/861: episode: 384, duration: 0.062s, episode steps: 2, steps per second: 32, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 307787497472.000000, mean_q: 155.074203\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.555291e+02\n",
      "Step 00648: model improved\n",
      "  from 1.550742e+02\n",
      "    to 1.555291e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.555291e+02_episode00384\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.555291e+02_episode00384 has done.\n",
      "max mean_q value: 1.555291e+02\n",
      "========== /Model Saver output =============\n",
      " 648/861: episode: 385, duration: 0.101s, episode steps: 2, steps per second: 20, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 463028551680.000000, mean_q: 155.529129\n",
      " 648/861: episode: 385, duration: 0.101s, episode steps: 2, steps per second: 20, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 463028551680.000000, mean_q: 155.529129\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.559703e+02\n",
      "Step 00650: model improved\n",
      "  from 1.555291e+02\n",
      "    to 1.559703e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.559703e+02_episode00385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 3230413.110329\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 3230417.623649\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115024.170993\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999804.626813\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_step 000004 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115422.435556\n",
      "now_datetime: 2017-10-02 00:20:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000004 [2017-10-02 00:20:00]\n",
      "   after: 000005 [2017-10-02 00:25:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114818.909538\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 3230022.135369\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2114628.683473\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.559703e+02_episode00385 has done.\n",
      "max mean_q value: 1.559703e+02\n",
      "========== /Model Saver output =============\n",
      " 650/861: episode: 386, duration: 0.086s, episode steps: 2, steps per second: 23, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 443533819904.000000, mean_q: 155.970337\n",
      " 650/861: episode: 386, duration: 0.087s, episode steps: 2, steps per second: 23, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 443533819904.000000, mean_q: 155.970337\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.566518e+02\n",
      "Step 00655: model improved\n",
      "  from 1.559703e+02\n",
      "    to 1.566518e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.566518e+02_episode00386\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.566518e+02_episode00386 has done.\n",
      "max mean_q value: 1.566518e+02\n",
      "========== /Model Saver output =============\n",
      " 655/861: episode: 387, duration: 0.125s, episode steps: 5, steps per second: 40, episode reward: 9460237.096, mean reward: 1892047.419 [-115422.436, 3230417.624], mean action: 1.600 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 559274852352.000000, mean_q: 156.651764\n",
      " 655/861: episode: 387, duration: 0.126s, episode steps: 5, steps per second: 40, episode reward: 9460237.096, mean reward: 1892047.419 [-115422.436, 3230417.624], mean action: 1.600 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 559274852352.000000, mean_q: 156.651764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999409.138573\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_step 000004 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115817.923756\n",
      "now_datetime: 2017-10-02 00:20:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000004 [2017-10-02 00:20:00]\n",
      "   after: 000005 [2017-10-02 00:25:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114818.909538\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2114814.396218\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999420.943562\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115798.600618\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.575624e+02\n",
      "Step 00660: model improved\n",
      "  from 1.566518e+02\n",
      "    to 1.575624e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.575624e+02_episode00387\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.575624e+02_episode00387 has done.\n",
      "max mean_q value: 1.575624e+02\n",
      "========== /Model Saver output =============\n",
      " 660/861: episode: 388, duration: 0.123s, episode steps: 5, steps per second: 41, episode reward: 8343060.943, mean reward: 1668612.189 [-115817.924, 3230022.135], mean action: 1.800 [1.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 449360003072.000000, mean_q: 157.562408\n",
      " 660/861: episode: 388, duration: 0.124s, episode steps: 5, steps per second: 40, episode reward: 8343060.943, mean reward: 1668612.189 [-115817.924, 3230022.135], mean action: 1.800 [1.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 449360003072.000000, mean_q: 157.562408\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.583903e+02\n",
      "Step 00664: model improved\n",
      "  from 1.575624e+02\n",
      "    to 1.583903e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.583903e+02_episode00388\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.583903e+02_episode00388 has done.\n",
      "max mean_q value: 1.583903e+02\n",
      "========== /Model Saver output =============\n",
      " 664/861: episode: 389, duration: 0.101s, episode steps: 4, steps per second: 40, episode reward: 5113255.649, mean reward: 1278313.912 [-115798.601, 2114818.910], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 365992148992.000000, mean_q: 158.390335\n",
      " 664/861: episode: 389, duration: 0.102s, episode steps: 4, steps per second: 39, episode reward: 5113255.649, mean reward: 1278313.912 [-115798.601, 2114818.910], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 365992148992.000000, mean_q: 158.390335\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.588546e+02\n",
      "Step 00666: model improved\n",
      "  from 1.583903e+02\n",
      "    to 1.588546e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.588546e+02_episode00389\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.588546e+02_episode00389 has done.\n",
      "max mean_q value: 1.588546e+02\n",
      "========== /Model Saver output =============\n",
      " 666/861: episode: 390, duration: 0.071s, episode steps: 2, steps per second: 28, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 428472205312.000000, mean_q: 158.854614\n",
      " 666/861: episode: 390, duration: 0.072s, episode steps: 2, steps per second: 28, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 428472205312.000000, mean_q: 158.854614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2114418.907938\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999025.456042\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116194.088858\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.593392e+02\n",
      "Step 00668: model improved\n",
      "  from 1.588546e+02\n",
      "    to 1.593392e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.593392e+02_episode00390\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.593392e+02_episode00390 has done.\n",
      "max mean_q value: 1.593392e+02\n",
      "========== /Model Saver output =============\n",
      " 668/861: episode: 391, duration: 0.071s, episode steps: 2, steps per second: 28, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 567593926656.000000, mean_q: 159.339188\n",
      " 668/861: episode: 391, duration: 0.072s, episode steps: 2, steps per second: 28, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 567593926656.000000, mean_q: 159.339188\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.599749e+02\n",
      "Step 00672: model improved\n",
      "  from 1.593392e+02\n",
      "    to 1.599749e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.599749e+02_episode00391\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.599749e+02_episode00391 has done.\n",
      "max mean_q value: 1.599749e+02\n",
      "========== /Model Saver output =============\n",
      " 672/861: episode: 392, duration: 0.108s, episode steps: 4, steps per second: 37, episode reward: 3996465.957, mean reward: 999116.489 [-116194.089, 2114418.908], mean action: 1.750 [1.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 577419214848.000000, mean_q: 159.974945\n",
      " 672/861: episode: 392, duration: 0.109s, episode steps: 4, steps per second: 37, episode reward: 3996465.957, mean reward: 999116.489 [-116194.089, 2114418.908], mean action: 1.750 [1.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 577419214848.000000, mean_q: 159.974945\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.604009e+02\n",
      "Step 00674: model improved\n",
      "  from 1.599749e+02\n",
      "    to 1.604009e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.604009e+02_episode00392\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.604009e+02_episode00392 has done.\n",
      "max mean_q value: 1.604009e+02\n",
      "========== /Model Saver output =============\n",
      " 674/861: episode: 393, duration: 0.063s, episode steps: 2, steps per second: 32, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 335019966464.000000, mean_q: 160.400879\n",
      " 674/861: episode: 393, duration: 0.063s, episode steps: 2, steps per second: 32, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 335019966464.000000, mean_q: 160.400879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.609478e+02\n",
      "Step 00676: model improved\n",
      "  from 1.604009e+02\n",
      "    to 1.609478e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.609478e+02_episode00393\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.609478e+02_episode00393 has done.\n",
      "max mean_q value: 1.609478e+02\n",
      "========== /Model Saver output =============\n",
      " 676/861: episode: 394, duration: 0.068s, episode steps: 2, steps per second: 30, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 560173154304.000000, mean_q: 160.947815\n",
      " 676/861: episode: 394, duration: 0.069s, episode steps: 2, steps per second: 29, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 560173154304.000000, mean_q: 160.947815\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.613452e+02\n",
      "Step 00678: model improved\n",
      "  from 1.609478e+02\n",
      "    to 1.613452e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.613452e+02_episode00394\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.613452e+02_episode00394 has done.\n",
      "max mean_q value: 1.613452e+02\n",
      "========== /Model Saver output =============\n",
      " 678/861: episode: 395, duration: 0.100s, episode steps: 2, steps per second: 20, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 416406142976.000000, mean_q: 161.345154\n",
      " 678/861: episode: 395, duration: 0.104s, episode steps: 2, steps per second: 19, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 416406142976.000000, mean_q: 161.345154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.617637e+02\n",
      "Step 00680: model improved\n",
      "  from 1.613452e+02\n",
      "    to 1.617637e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.617637e+02_episode00395\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.617637e+02_episode00395 has done.\n",
      "max mean_q value: 1.617637e+02\n",
      "========== /Model Saver output =============\n",
      " 680/861: episode: 396, duration: 0.095s, episode steps: 2, steps per second: 21, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 439505190912.000000, mean_q: 161.763672\n",
      " 680/861: episode: 396, duration: 0.096s, episode steps: 2, steps per second: 21, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 439505190912.000000, mean_q: 161.763672\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.621596e+02\n",
      "Step 00682: model improved\n",
      "  from 1.617637e+02\n",
      "    to 1.621596e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.621596e+02_episode00396\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.621596e+02_episode00396 has done.\n",
      "max mean_q value: 1.621596e+02\n",
      "========== /Model Saver output =============\n",
      " 682/861: episode: 397, duration: 0.079s, episode steps: 2, steps per second: 25, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 245878849536.000000, mean_q: 162.159637\n",
      " 682/861: episode: 397, duration: 0.080s, episode steps: 2, steps per second: 25, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 245878849536.000000, mean_q: 162.159637\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.625221e+02\n",
      "Step 00684: model improved\n",
      "  from 1.621596e+02\n",
      "    to 1.625221e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.625221e+02_episode00397\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.625221e+02_episode00397 has done.\n",
      "max mean_q value: 1.625221e+02\n",
      "========== /Model Saver output =============\n",
      " 684/861: episode: 398, duration: 0.058s, episode steps: 2, steps per second: 35, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 343084236800.000000, mean_q: 162.522110\n",
      " 684/861: episode: 398, duration: 0.058s, episode steps: 2, steps per second: 34, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 343084236800.000000, mean_q: 162.522110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.629329e+02\n",
      "Step 00686: model improved\n",
      "  from 1.625221e+02\n",
      "    to 1.629329e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.629329e+02_episode00398\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.629329e+02_episode00398 has done.\n",
      "max mean_q value: 1.629329e+02\n",
      "========== /Model Saver output =============\n",
      " 686/861: episode: 399, duration: 0.066s, episode steps: 2, steps per second: 30, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 427719786496.000000, mean_q: 162.932861\n",
      " 686/861: episode: 399, duration: 0.067s, episode steps: 2, steps per second: 30, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 427719786496.000000, mean_q: 162.932861\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.634449e+02\n",
      "Step 00688: model improved\n",
      "  from 1.629329e+02\n",
      "    to 1.634449e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.634449e+02_episode00399\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.634449e+02_episode00399 has done.\n",
      "max mean_q value: 1.634449e+02\n",
      "========== /Model Saver output =============\n",
      " 688/861: episode: 400, duration: 0.079s, episode steps: 2, steps per second: 25, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 447231262720.000000, mean_q: 163.444916\n",
      " 688/861: episode: 400, duration: 0.080s, episode steps: 2, steps per second: 25, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 447231262720.000000, mean_q: 163.444916\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.637967e+02\n",
      "Step 00690: model improved\n",
      "  from 1.634449e+02\n",
      "    to 1.637967e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.637967e+02_episode00400\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.637967e+02_episode00400 has done.\n",
      "max mean_q value: 1.637967e+02\n",
      "========== /Model Saver output =============\n",
      " 690/861: episode: 401, duration: 0.073s, episode steps: 2, steps per second: 27, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 517260640256.000000, mean_q: 163.796661\n",
      " 690/861: episode: 401, duration: 0.074s, episode steps: 2, steps per second: 27, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 517260640256.000000, mean_q: 163.796661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115996.570364\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.641471e+02\n",
      "Step 00692: model improved\n",
      "  from 1.637967e+02\n",
      "    to 1.641471e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.641471e+02_episode00401\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.641471e+02_episode00401 has done.\n",
      "max mean_q value: 1.641471e+02\n",
      "========== /Model Saver output =============\n",
      " 692/861: episode: 402, duration: 0.091s, episode steps: 2, steps per second: 22, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 249873530880.000000, mean_q: 164.147095\n",
      " 692/861: episode: 402, duration: 0.093s, episode steps: 2, steps per second: 22, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 249873530880.000000, mean_q: 164.147095\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.646789e+02\n",
      "Step 00694: model improved\n",
      "  from 1.641471e+02\n",
      "    to 1.646789e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.646789e+02_episode00402\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.646789e+02_episode00402 has done.\n",
      "max mean_q value: 1.646789e+02\n",
      "========== /Model Saver output =============\n",
      " 694/861: episode: 403, duration: 0.089s, episode steps: 2, steps per second: 23, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 559900327936.000000, mean_q: 164.678925\n",
      " 694/861: episode: 403, duration: 0.089s, episode steps: 2, steps per second: 22, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 559900327936.000000, mean_q: 164.678925\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.650797e+02\n",
      "Step 00696: model improved\n",
      "  from 1.646789e+02\n",
      "    to 1.650797e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.650797e+02_episode00403\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.650797e+02_episode00403 has done.\n",
      "max mean_q value: 1.650797e+02\n",
      "========== /Model Saver output =============\n",
      " 696/861: episode: 404, duration: 0.082s, episode steps: 2, steps per second: 24, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 625846779904.000000, mean_q: 165.079681\n",
      " 696/861: episode: 404, duration: 0.083s, episode steps: 2, steps per second: 24, episode reward: 883219.112, mean reward: 441609.556 [-115996.570, 999215.682], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 625846779904.000000, mean_q: 165.079681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999215.682107\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999211.168787\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116182.283869\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.655356e+02\n",
      "Step 00699: model improved\n",
      "  from 1.650797e+02\n",
      "    to 1.655356e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.655356e+02_episode00404\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.655356e+02_episode00404 has done.\n",
      "max mean_q value: 1.655356e+02\n",
      "========== /Model Saver output =============\n",
      " 699/861: episode: 405, duration: 0.085s, episode steps: 3, steps per second: 35, episode reward: 1882244.567, mean reward: 627414.856 [-116182.284, 999215.682], mean action: 1.333 [0.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 506774847488.000000, mean_q: 165.535645\n",
      " 699/861: episode: 405, duration: 0.086s, episode steps: 3, steps per second: 35, episode reward: 1882244.567, mean reward: 627414.856 [-116182.284, 999215.682], mean action: 1.333 [0.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 506774847488.000000, mean_q: 165.535645\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.659831e+02\n",
      "Step 00700: model improved\n",
      "  from 1.655356e+02\n",
      "    to 1.659831e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.659831e+02_episode00405\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.659831e+02_episode00405 has done.\n",
      "max mean_q value: 1.659831e+02\n",
      "========== /Model Saver output =============\n",
      " 700/861: episode: 406, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 377848463360.000000, mean_q: 165.983093\n",
      " 700/861: episode: 406, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 377848463360.000000, mean_q: 165.983093\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.663143e+02\n",
      "Step 00701: model improved\n",
      "  from 1.659831e+02\n",
      "    to 1.663143e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.663143e+02_episode00406\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.663143e+02_episode00406 has done.\n",
      "max mean_q value: 1.663143e+02\n",
      "========== /Model Saver output =============\n",
      " 701/861: episode: 407, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 563403685888.000000, mean_q: 166.314255\n",
      " 701/861: episode: 407, duration: 0.048s, episode steps: 1, steps per second: 21, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 563403685888.000000, mean_q: 166.314255\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.664214e+02\n",
      "Step 00702: model improved\n",
      "  from 1.663143e+02\n",
      "    to 1.664214e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.664214e+02_episode00407\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.664214e+02_episode00407 has done.\n",
      "max mean_q value: 1.664214e+02\n",
      "========== /Model Saver output =============\n",
      " 702/861: episode: 408, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 284774924288.000000, mean_q: 166.421417\n",
      " 702/861: episode: 408, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 284774924288.000000, mean_q: 166.421417\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.667435e+02\n",
      "Step 00703: model improved\n",
      "  from 1.664214e+02\n",
      "    to 1.667435e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.667435e+02_episode00408\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.667435e+02_episode00408 has done.\n",
      "max mean_q value: 1.667435e+02\n",
      "========== /Model Saver output =============\n",
      " 703/861: episode: 409, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 454895403008.000000, mean_q: 166.743500\n",
      " 703/861: episode: 409, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 454895403008.000000, mean_q: 166.743500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.672086e+02\n",
      "Step 00704: model improved\n",
      "  from 1.667435e+02\n",
      "    to 1.672086e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.672086e+02_episode00409\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.672086e+02_episode00409 has done.\n",
      "max mean_q value: 1.672086e+02\n",
      "========== /Model Saver output =============\n",
      " 704/861: episode: 410, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 540815425536.000000, mean_q: 167.208633\n",
      " 704/861: episode: 410, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 540815425536.000000, mean_q: 167.208633\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.675709e+02\n",
      "Step 00705: model improved\n",
      "  from 1.672086e+02\n",
      "    to 1.675709e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.675709e+02_episode00410\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.675709e+02_episode00410 has done.\n",
      "max mean_q value: 1.675709e+02\n",
      "========== /Model Saver output =============\n",
      " 705/861: episode: 411, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 556132663296.000000, mean_q: 167.570892\n",
      " 705/861: episode: 411, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 556132663296.000000, mean_q: 167.570892\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.676634e+02\n",
      "Step 00706: model improved\n",
      "  from 1.675709e+02\n",
      "    to 1.676634e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.676634e+02_episode00411\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.676634e+02_episode00411 has done.\n",
      "max mean_q value: 1.676634e+02\n",
      "========== /Model Saver output =============\n",
      " 706/861: episode: 412, duration: 0.029s, episode steps: 1, steps per second: 34, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 524649103360.000000, mean_q: 167.663422\n",
      " 706/861: episode: 412, duration: 0.030s, episode steps: 1, steps per second: 33, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 524649103360.000000, mean_q: 167.663422\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.682553e+02\n",
      "Step 00707: model improved\n",
      "  from 1.676634e+02\n",
      "    to 1.682553e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.682553e+02_episode00412\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.682553e+02_episode00412 has done.\n",
      "max mean_q value: 1.682553e+02\n",
      "========== /Model Saver output =============\n",
      " 707/861: episode: 413, duration: 0.040s, episode steps: 1, steps per second: 25, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 780448366592.000000, mean_q: 168.255280\n",
      " 707/861: episode: 413, duration: 0.041s, episode steps: 1, steps per second: 25, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 780448366592.000000, mean_q: 168.255280\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.682250e+02\n",
      "========== /Model Saver output =============\n",
      " 708/861: episode: 414, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 493761069056.000000, mean_q: 168.224960\n",
      " 708/861: episode: 414, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 493761069056.000000, mean_q: 168.224960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.687358e+02\n",
      "Step 00709: model improved\n",
      "  from 1.682553e+02\n",
      "    to 1.687358e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.687358e+02_episode00414\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.687358e+02_episode00414 has done.\n",
      "max mean_q value: 1.687358e+02\n",
      "========== /Model Saver output =============\n",
      " 709/861: episode: 415, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 354380513280.000000, mean_q: 168.735840\n",
      " 709/861: episode: 415, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 354380513280.000000, mean_q: 168.735840\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.688573e+02\n",
      "Step 00710: model improved\n",
      "  from 1.687358e+02\n",
      "    to 1.688573e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.688573e+02_episode00415\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.688573e+02_episode00415 has done.\n",
      "max mean_q value: 1.688573e+02\n",
      "========== /Model Saver output =============\n",
      " 710/861: episode: 416, duration: 0.051s, episode steps: 1, steps per second: 19, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 385171816448.000000, mean_q: 168.857285\n",
      " 710/861: episode: 416, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 385171816448.000000, mean_q: 168.857285\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.691184e+02\n",
      "Step 00711: model improved\n",
      "  from 1.688573e+02\n",
      "    to 1.691184e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.691184e+02_episode00416\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.691184e+02_episode00416 has done.\n",
      "max mean_q value: 1.691184e+02\n",
      "========== /Model Saver output =============\n",
      " 711/861: episode: 417, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 757075673088.000000, mean_q: 169.118439\n",
      " 711/861: episode: 417, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 757075673088.000000, mean_q: 169.118439\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.695496e+02\n",
      "Step 00712: model improved\n",
      "  from 1.691184e+02\n",
      "    to 1.695496e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.695496e+02_episode00417\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.695496e+02_episode00417 has done.\n",
      "max mean_q value: 1.695496e+02\n",
      "========== /Model Saver output =============\n",
      " 712/861: episode: 418, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 362414866432.000000, mean_q: 169.549622\n",
      " 712/861: episode: 418, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 362414866432.000000, mean_q: 169.549622\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.698331e+02\n",
      "Step 00713: model improved\n",
      "  from 1.695496e+02\n",
      "    to 1.698331e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.698331e+02_episode00418\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.698331e+02_episode00418 has done.\n",
      "max mean_q value: 1.698331e+02\n",
      "========== /Model Saver output =============\n",
      " 713/861: episode: 419, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 602402324480.000000, mean_q: 169.833115\n",
      " 713/861: episode: 419, duration: 0.035s, episode steps: 1, steps per second: 28, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 602402324480.000000, mean_q: 169.833115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.700743e+02\n",
      "Step 00714: model improved\n",
      "  from 1.698331e+02\n",
      "    to 1.700743e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.700743e+02_episode00419\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.700743e+02_episode00419 has done.\n",
      "max mean_q value: 1.700743e+02\n",
      "========== /Model Saver output =============\n",
      " 714/861: episode: 420, duration: 0.049s, episode steps: 1, steps per second: 20, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 122593067008.000000, mean_q: 170.074265\n",
      " 714/861: episode: 420, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 122593067008.000000, mean_q: 170.074265\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.704393e+02\n",
      "Step 00715: model improved\n",
      "  from 1.700743e+02\n",
      "    to 1.704393e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.704393e+02_episode00420\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.704393e+02_episode00420 has done.\n",
      "max mean_q value: 1.704393e+02\n",
      "========== /Model Saver output =============\n",
      " 715/861: episode: 421, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 385930231808.000000, mean_q: 170.439316\n",
      " 715/861: episode: 421, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 385930231808.000000, mean_q: 170.439316\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.708812e+02\n",
      "Step 00716: model improved\n",
      "  from 1.704393e+02\n",
      "    to 1.708812e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.708812e+02_episode00421\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.708812e+02_episode00421 has done.\n",
      "max mean_q value: 1.708812e+02\n",
      "========== /Model Saver output =============\n",
      " 716/861: episode: 422, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 471059726336.000000, mean_q: 170.881165\n",
      " 716/861: episode: 422, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 471059726336.000000, mean_q: 170.881165\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.709303e+02\n",
      "Step 00717: model improved\n",
      "  from 1.708812e+02\n",
      "    to 1.709303e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.709303e+02_episode00422\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.709303e+02_episode00422 has done.\n",
      "max mean_q value: 1.709303e+02\n",
      "========== /Model Saver output =============\n",
      " 717/861: episode: 423, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 493076152320.000000, mean_q: 170.930298\n",
      " 717/861: episode: 423, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 493076152320.000000, mean_q: 170.930298\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.712702e+02\n",
      "Step 00718: model improved\n",
      "  from 1.709303e+02\n",
      "    to 1.712702e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.712702e+02_episode00423\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.712702e+02_episode00423 has done.\n",
      "max mean_q value: 1.712702e+02\n",
      "========== /Model Saver output =============\n",
      " 718/861: episode: 424, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 478345723904.000000, mean_q: 171.270233"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 718/861: episode: 424, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 478345723904.000000, mean_q: 171.270233\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.714949e+02\n",
      "Step 00719: model improved\n",
      "  from 1.712702e+02\n",
      "    to 1.714949e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.714949e+02_episode00424\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.714949e+02_episode00424 has done.\n",
      "max mean_q value: 1.714949e+02\n",
      "========== /Model Saver output =============\n",
      " 719/861: episode: 425, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 369818468352.000000, mean_q: 171.494904\n",
      " 719/861: episode: 425, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 369818468352.000000, mean_q: 171.494904\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.718146e+02\n",
      "Step 00720: model improved\n",
      "  from 1.714949e+02\n",
      "    to 1.718146e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.718146e+02_episode00425\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.718146e+02_episode00425 has done.\n",
      "max mean_q value: 1.718146e+02\n",
      "========== /Model Saver output =============\n",
      " 720/861: episode: 426, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 454938066944.000000, mean_q: 171.814575\n",
      " 720/861: episode: 426, duration: 0.035s, episode steps: 1, steps per second: 29, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 454938066944.000000, mean_q: 171.814575\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.721607e+02\n",
      "Step 00721: model improved\n",
      "  from 1.718146e+02\n",
      "    to 1.721607e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.721607e+02_episode00426\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.721607e+02_episode00426 has done.\n",
      "max mean_q value: 1.721607e+02\n",
      "========== /Model Saver output =============\n",
      " 721/861: episode: 427, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 300105170944.000000, mean_q: 172.160736\n",
      " 721/861: episode: 427, duration: 0.038s, episode steps: 1, steps per second: 27, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 300105170944.000000, mean_q: 172.160736\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.724570e+02\n",
      "Step 00722: model improved\n",
      "  from 1.721607e+02\n",
      "    to 1.724570e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.724570e+02_episode00427\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.724570e+02_episode00427 has done.\n",
      "max mean_q value: 1.724570e+02\n",
      "========== /Model Saver output =============\n",
      " 722/861: episode: 428, duration: 0.040s, episode steps: 1, steps per second: 25, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 401400594432.000000, mean_q: 172.456985\n",
      " 722/861: episode: 428, duration: 0.041s, episode steps: 1, steps per second: 24, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 401400594432.000000, mean_q: 172.456985\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.726589e+02\n",
      "Step 00723: model improved\n",
      "  from 1.724570e+02\n",
      "    to 1.726589e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.726589e+02_episode00428\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.726589e+02_episode00428 has done.\n",
      "max mean_q value: 1.726589e+02\n",
      "========== /Model Saver output =============\n",
      " 723/861: episode: 429, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 547986997248.000000, mean_q: 172.658875\n",
      " 723/861: episode: 429, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 547986997248.000000, mean_q: 172.658875\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.729374e+02\n",
      "Step 00724: model improved\n",
      "  from 1.726589e+02\n",
      "    to 1.729374e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.729374e+02_episode00429\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.729374e+02_episode00429 has done.\n",
      "max mean_q value: 1.729374e+02\n",
      "========== /Model Saver output =============\n",
      " 724/861: episode: 430, duration: 0.036s, episode steps: 1, steps per second: 28, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 230382469120.000000, mean_q: 172.937439\n",
      " 724/861: episode: 430, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 230382469120.000000, mean_q: 172.937439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.732170e+02\n",
      "Step 00725: model improved\n",
      "  from 1.729374e+02\n",
      "    to 1.732170e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.732170e+02_episode00430\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.732170e+02_episode00430 has done.\n",
      "max mean_q value: 1.732170e+02\n",
      "========== /Model Saver output =============\n",
      " 725/861: episode: 431, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 478330421248.000000, mean_q: 173.216965\n",
      " 725/861: episode: 431, duration: 0.054s, episode steps: 1, steps per second: 19, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 478330421248.000000, mean_q: 173.216965\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.736008e+02\n",
      "Step 00726: model improved\n",
      "  from 1.732170e+02\n",
      "    to 1.736008e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.736008e+02_episode00431\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.736008e+02_episode00431 has done.\n",
      "max mean_q value: 1.736008e+02\n",
      "========== /Model Saver output =============\n",
      " 726/861: episode: 432, duration: 0.039s, episode steps: 1, steps per second: 26, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 501906767872.000000, mean_q: 173.600830\n",
      " 726/861: episode: 432, duration: 0.039s, episode steps: 1, steps per second: 26, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 501906767872.000000, mean_q: 173.600830\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.737880e+02\n",
      "Step 00727: model improved\n",
      "  from 1.736008e+02\n",
      "    to 1.737880e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.737880e+02_episode00432\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.737880e+02_episode00432 has done.\n",
      "max mean_q value: 1.737880e+02\n",
      "========== /Model Saver output =============\n",
      " 727/861: episode: 433, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 377798754304.000000, mean_q: 173.787979\n",
      " 727/861: episode: 433, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 377798754304.000000, mean_q: 173.787979\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.742574e+02\n",
      "Step 00728: model improved\n",
      "  from 1.737880e+02\n",
      "    to 1.742574e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.742574e+02_episode00433\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.742574e+02_episode00433 has done.\n",
      "max mean_q value: 1.742574e+02\n",
      "========== /Model Saver output =============\n",
      " 728/861: episode: 434, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 703654264832.000000, mean_q: 174.257355\n",
      " 728/861: episode: 434, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 703654264832.000000, mean_q: 174.257355\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.743596e+02\n",
      "Step 00729: model improved\n",
      "  from 1.742574e+02\n",
      "    to 1.743596e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.743596e+02_episode00434\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.743596e+02_episode00434 has done.\n",
      "max mean_q value: 1.743596e+02\n",
      "========== /Model Saver output =============\n",
      " 729/861: episode: 435, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 617828188160.000000, mean_q: 174.359589\n",
      " 729/861: episode: 435, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 617828188160.000000, mean_q: 174.359589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.747874e+02\n",
      "Step 00730: model improved\n",
      "  from 1.743596e+02\n",
      "    to 1.747874e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.747874e+02_episode00435\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.747874e+02_episode00435 has done.\n",
      "max mean_q value: 1.747874e+02\n",
      "========== /Model Saver output =============\n",
      " 730/861: episode: 436, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 540835446784.000000, mean_q: 174.787415\n",
      " 730/861: episode: 436, duration: 0.048s, episode steps: 1, steps per second: 21, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 540835446784.000000, mean_q: 174.787415\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.748976e+02\n",
      "Step 00731: model improved\n",
      "  from 1.747874e+02\n",
      "    to 1.748976e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.748976e+02_episode00436\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.748976e+02_episode00436 has done.\n",
      "max mean_q value: 1.748976e+02\n",
      "========== /Model Saver output =============\n",
      " 731/861: episode: 437, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 408653103104.000000, mean_q: 174.897629\n",
      " 731/861: episode: 437, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 408653103104.000000, mean_q: 174.897629\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.752522e+02\n",
      "Step 00732: model improved\n",
      "  from 1.748976e+02\n",
      "    to 1.752522e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.752522e+02_episode00437\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.752522e+02_episode00437 has done.\n",
      "max mean_q value: 1.752522e+02\n",
      "========== /Model Saver output =============\n",
      " 732/861: episode: 438, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 656707682304.000000, mean_q: 175.252197\n",
      " 732/861: episode: 438, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 656707682304.000000, mean_q: 175.252197\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.754701e+02\n",
      "Step 00733: model improved\n",
      "  from 1.752522e+02\n",
      "    to 1.754701e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.754701e+02_episode00438\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.754701e+02_episode00438 has done.\n",
      "max mean_q value: 1.754701e+02\n",
      "========== /Model Saver output =============\n",
      " 733/861: episode: 439, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 795953070080.000000, mean_q: 175.470062\n",
      " 733/861: episode: 439, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 795953070080.000000, mean_q: 175.470062\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.756893e+02\n",
      "Step 00734: model improved\n",
      "  from 1.754701e+02\n",
      "    to 1.756893e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.756893e+02_episode00439\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.756893e+02_episode00439 has done.\n",
      "max mean_q value: 1.756893e+02\n",
      "========== /Model Saver output =============\n",
      " 734/861: episode: 440, duration: 0.039s, episode steps: 1, steps per second: 26, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 486554468352.000000, mean_q: 175.689301\n",
      " 734/861: episode: 440, duration: 0.040s, episode steps: 1, steps per second: 25, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 486554468352.000000, mean_q: 175.689301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.759325e+02\n",
      "Step 00735: model improved\n",
      "  from 1.756893e+02\n",
      "    to 1.759325e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.759325e+02_episode00440\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.759325e+02_episode00440 has done.\n",
      "max mean_q value: 1.759325e+02\n",
      "========== /Model Saver output =============\n",
      " 735/861: episode: 441, duration: 0.039s, episode steps: 1, steps per second: 26, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 308199489536.000000, mean_q: 175.932495\n",
      " 735/861: episode: 441, duration: 0.039s, episode steps: 1, steps per second: 26, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 308199489536.000000, mean_q: 175.932495\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.762335e+02\n",
      "Step 00736: model improved\n",
      "  from 1.759325e+02\n",
      "    to 1.762335e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.762335e+02_episode00441\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.762335e+02_episode00441 has done.\n",
      "max mean_q value: 1.762335e+02\n",
      "========== /Model Saver output =============\n",
      " 736/861: episode: 442, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 300039733248.000000, mean_q: 176.233490\n",
      " 736/861: episode: 442, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 300039733248.000000, mean_q: 176.233490\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.764427e+02\n",
      "Step 00737: model improved\n",
      "  from 1.762335e+02\n",
      "    to 1.764427e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.764427e+02_episode00442\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.764427e+02_episode00442 has done.\n",
      "max mean_q value: 1.764427e+02\n",
      "========== /Model Saver output =============\n",
      " 737/861: episode: 443, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 539957133312.000000, mean_q: 176.442749\n",
      " 737/861: episode: 443, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 539957133312.000000, mean_q: 176.442749\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.768473e+02\n",
      "Step 00738: model improved\n",
      "  from 1.764427e+02\n",
      "    to 1.768473e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.768473e+02_episode00443\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.768473e+02_episode00443 has done.\n",
      "max mean_q value: 1.768473e+02\n",
      "========== /Model Saver output =============\n",
      " 738/861: episode: 444, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 448216989696.000000, mean_q: 176.847290\n",
      " 738/861: episode: 444, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 448216989696.000000, mean_q: 176.847290\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.769019e+02\n",
      "Step 00739: model improved\n",
      "  from 1.768473e+02\n",
      "    to 1.769019e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.769019e+02_episode00444\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.769019e+02_episode00444 has done.\n",
      "max mean_q value: 1.769019e+02\n",
      "========== /Model Saver output =============\n",
      " 739/861: episode: 445, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 214975119360.000000, mean_q: 176.901917\n",
      " 739/861: episode: 445, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 214975119360.000000, mean_q: 176.901917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.772669e+02\n",
      "Step 00740: model improved\n",
      "  from 1.769019e+02\n",
      "    to 1.772669e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.772669e+02_episode00445\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.772669e+02_episode00445 has done.\n",
      "max mean_q value: 1.772669e+02\n",
      "========== /Model Saver output =============\n",
      " 740/861: episode: 446, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 415981436928.000000, mean_q: 177.266937\n",
      " 740/861: episode: 446, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 415981436928.000000, mean_q: 177.266937\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.774475e+02\n",
      "Step 00741: model improved\n",
      "  from 1.772669e+02\n",
      "    to 1.774475e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.774475e+02_episode00446\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.774475e+02_episode00446 has done.\n",
      "max mean_q value: 1.774475e+02\n",
      "========== /Model Saver output =============\n",
      " 741/861: episode: 447, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 672106676224.000000, mean_q: 177.447479\n",
      " 741/861: episode: 447, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 672106676224.000000, mean_q: 177.447479\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.778076e+02\n",
      "Step 00742: model improved\n",
      "  from 1.774475e+02\n",
      "    to 1.778076e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.778076e+02_episode00447\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.778076e+02_episode00447 has done.\n",
      "max mean_q value: 1.778076e+02\n",
      "========== /Model Saver output =============\n",
      " 742/861: episode: 448, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 501942386688.000000, mean_q: 177.807571\n",
      " 742/861: episode: 448, duration: 0.039s, episode steps: 1, steps per second: 26, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 501942386688.000000, mean_q: 177.807571\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.780513e+02\n",
      "Step 00743: model improved\n",
      "  from 1.778076e+02\n",
      "    to 1.780513e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.780513e+02_episode00448\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.780513e+02_episode00448 has done.\n",
      "max mean_q value: 1.780513e+02\n",
      "========== /Model Saver output =============\n",
      " 743/861: episode: 449, duration: 0.033s, episode steps: 1, steps per second: 30, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 501817704448.000000, mean_q: 178.051300\n",
      " 743/861: episode: 449, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 501817704448.000000, mean_q: 178.051300\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.783001e+02\n",
      "Step 00744: model improved\n",
      "  from 1.780513e+02\n",
      "    to 1.783001e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.783001e+02_episode00449\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.783001e+02_episode00449 has done.\n",
      "max mean_q value: 1.783001e+02\n",
      "========== /Model Saver output =============\n",
      " 744/861: episode: 450, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 439495327744.000000, mean_q: 178.300064\n",
      " 744/861: episode: 450, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 439495327744.000000, mean_q: 178.300064\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.784957e+02\n",
      "Step 00745: model improved\n",
      "  from 1.783001e+02\n",
      "    to 1.784957e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.784957e+02_episode00450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.784957e+02_episode00450 has done.\n",
      "max mean_q value: 1.784957e+02\n",
      "========== /Model Saver output =============\n",
      " 745/861: episode: 451, duration: 0.049s, episode steps: 1, steps per second: 20, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 361693052928.000000, mean_q: 178.495728\n",
      " 745/861: episode: 451, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 361693052928.000000, mean_q: 178.495728\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.788837e+02\n",
      "Step 00746: model improved\n",
      "  from 1.784957e+02\n",
      "    to 1.788837e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.788837e+02_episode00451\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.788837e+02_episode00451 has done.\n",
      "max mean_q value: 1.788837e+02\n",
      "========== /Model Saver output =============\n",
      " 746/861: episode: 452, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 370610634752.000000, mean_q: 178.883698\n",
      " 746/861: episode: 452, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 370610634752.000000, mean_q: 178.883698\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.791177e+02\n",
      "Step 00747: model improved\n",
      "  from 1.788837e+02\n",
      "    to 1.791177e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.791177e+02_episode00452\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.791177e+02_episode00452 has done.\n",
      "max mean_q value: 1.791177e+02\n",
      "========== /Model Saver output =============\n",
      " 747/861: episode: 453, duration: 0.034s, episode steps: 1, steps per second: 30, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 377908461568.000000, mean_q: 179.117676\n",
      " 747/861: episode: 453, duration: 0.034s, episode steps: 1, steps per second: 29, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 377908461568.000000, mean_q: 179.117676\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.795443e+02\n",
      "Step 00748: model improved\n",
      "  from 1.791177e+02\n",
      "    to 1.795443e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.795443e+02_episode00453\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.795443e+02_episode00453 has done.\n",
      "max mean_q value: 1.795443e+02\n",
      "========== /Model Saver output =============\n",
      " 748/861: episode: 454, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 471097507840.000000, mean_q: 179.544266\n",
      " 748/861: episode: 454, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 471097507840.000000, mean_q: 179.544266\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.795746e+02\n",
      "Step 00749: model improved\n",
      "  from 1.795443e+02\n",
      "    to 1.795746e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.795746e+02_episode00454\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.795746e+02_episode00454 has done.\n",
      "max mean_q value: 1.795746e+02\n",
      "========== /Model Saver output =============\n",
      " 749/861: episode: 455, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 300090163200.000000, mean_q: 179.574615\n",
      " 749/861: episode: 455, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 300090163200.000000, mean_q: 179.574615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.800258e+02\n",
      "Step 00750: model improved\n",
      "  from 1.795746e+02\n",
      "    to 1.800258e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.800258e+02_episode00455\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.800258e+02_episode00455 has done.\n",
      "max mean_q value: 1.800258e+02\n",
      "========== /Model Saver output =============\n",
      " 750/861: episode: 456, duration: 0.039s, episode steps: 1, steps per second: 26, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 509233659904.000000, mean_q: 180.025757\n",
      " 750/861: episode: 456, duration: 0.041s, episode steps: 1, steps per second: 24, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 509233659904.000000, mean_q: 180.025757\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.803894e+02\n",
      "Step 00751: model improved\n",
      "  from 1.800258e+02\n",
      "    to 1.803894e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.803894e+02_episode00456\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.803894e+02_episode00456 has done.\n",
      "max mean_q value: 1.803894e+02\n",
      "========== /Model Saver output =============\n",
      " 751/861: episode: 457, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 533501706240.000000, mean_q: 180.389435\n",
      " 751/861: episode: 457, duration: 0.048s, episode steps: 1, steps per second: 21, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 533501706240.000000, mean_q: 180.389435\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.805734e+02\n",
      "Step 00752: model improved\n",
      "  from 1.803894e+02\n",
      "    to 1.805734e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.805734e+02_episode00457\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.805734e+02_episode00457 has done.\n",
      "max mean_q value: 1.805734e+02\n",
      "========== /Model Saver output =============\n",
      " 752/861: episode: 458, duration: 0.049s, episode steps: 1, steps per second: 21, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 625826856960.000000, mean_q: 180.573395\n",
      " 752/861: episode: 458, duration: 0.049s, episode steps: 1, steps per second: 20, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 625826856960.000000, mean_q: 180.573395\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.807527e+02\n",
      "Step 00753: model improved\n",
      "  from 1.805734e+02\n",
      "    to 1.807527e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.807527e+02_episode00458\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.807527e+02_episode00458 has done.\n",
      "max mean_q value: 1.807527e+02\n",
      "========== /Model Saver output =============\n",
      " 753/861: episode: 459, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 493710704640.000000, mean_q: 180.752747\n",
      " 753/861: episode: 459, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 493710704640.000000, mean_q: 180.752747\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.810425e+02\n",
      "Step 00754: model improved\n",
      "  from 1.807527e+02\n",
      "    to 1.810425e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.810425e+02_episode00459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -116387.545324\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999211.168787\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "reward: 2114418.907938\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2114416.764871\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999199.251307\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_step 000004 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116027.923874\n",
      "now_datetime: 2017-10-02 00:20:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000004 [2017-10-02 00:20:00]\n",
      "   after: 000005 [2017-10-02 00:25:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 998818.050760\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.810425e+02_episode00459 has done.\n",
      "max mean_q value: 1.810425e+02\n",
      "========== /Model Saver output =============\n",
      " 754/861: episode: 460, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 788677984256.000000, mean_q: 181.042542\n",
      " 754/861: episode: 460, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 788677984256.000000, mean_q: 181.042542\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.814818e+02\n",
      "Step 00755: model improved\n",
      "  from 1.810425e+02\n",
      "    to 1.814818e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.814818e+02_episode00460\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.814818e+02_episode00460 has done.\n",
      "max mean_q value: 1.814818e+02\n",
      "========== /Model Saver output =============\n",
      " 755/861: episode: 461, duration: 0.048s, episode steps: 1, steps per second: 21, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 308245364736.000000, mean_q: 181.481842\n",
      " 755/861: episode: 461, duration: 0.049s, episode steps: 1, steps per second: 20, episode reward: -116387.545, mean reward: -116387.545 [-116387.545, -116387.545], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 308245364736.000000, mean_q: 181.481842\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.819391e+02\n",
      "Step 00760: model improved\n",
      "  from 1.814818e+02\n",
      "    to 1.819391e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.819391e+02_episode00461\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.819391e+02_episode00461 has done.\n",
      "max mean_q value: 1.819391e+02\n",
      "========== /Model Saver output =============\n",
      " 760/861: episode: 462, duration: 0.121s, episode steps: 5, steps per second: 41, episode reward: 6111218.169, mean reward: 1222243.634 [-116027.924, 2114418.908], mean action: 1.400 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 526616002560.000000, mean_q: 181.939133\n",
      " 760/861: episode: 462, duration: 0.122s, episode steps: 5, steps per second: 41, episode reward: 6111218.169, mean reward: 1222243.634 [-116027.924, 2114418.908], mean action: 1.400 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 526616002560.000000, mean_q: 181.939133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116394.201711\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 998818.050760\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116394.201711\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 998818.050760\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116394.201711\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 998818.050760\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116394.201711\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.823972e+02\n",
      "Step 00762: model improved\n",
      "  from 1.819391e+02\n",
      "    to 1.823972e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.823972e+02_episode00462\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.823972e+02_episode00462 has done.\n",
      "max mean_q value: 1.823972e+02\n",
      "========== /Model Saver output =============\n",
      " 762/861: episode: 463, duration: 0.063s, episode steps: 2, steps per second: 32, episode reward: 882423.849, mean reward: 441211.925 [-116394.202, 998818.051], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 401009737728.000000, mean_q: 182.397247\n",
      " 762/861: episode: 463, duration: 0.063s, episode steps: 2, steps per second: 32, episode reward: 882423.849, mean reward: 441211.925 [-116394.202, 998818.051], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 401009737728.000000, mean_q: 182.397247\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.828765e+02\n",
      "Step 00764: model improved\n",
      "  from 1.823972e+02\n",
      "    to 1.828765e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.828765e+02_episode00463\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.828765e+02_episode00463 has done.\n",
      "max mean_q value: 1.828765e+02\n",
      "========== /Model Saver output =============\n",
      " 764/861: episode: 464, duration: 0.059s, episode steps: 2, steps per second: 34, episode reward: 882423.849, mean reward: 441211.925 [-116394.202, 998818.051], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 362070671360.000000, mean_q: 182.876526\n",
      " 764/861: episode: 464, duration: 0.060s, episode steps: 2, steps per second: 33, episode reward: 882423.849, mean reward: 441211.925 [-116394.202, 998818.051], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 362070671360.000000, mean_q: 182.876526\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.831225e+02\n",
      "Step 00766: model improved\n",
      "  from 1.828765e+02\n",
      "    to 1.831225e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.831225e+02_episode00464\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.831225e+02_episode00464 has done.\n",
      "max mean_q value: 1.831225e+02\n",
      "========== /Model Saver output =============\n",
      " 766/861: episode: 465, duration: 0.069s, episode steps: 2, steps per second: 29, episode reward: 882423.849, mean reward: 441211.925 [-116394.202, 998818.051], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 358082019328.000000, mean_q: 183.122452\n",
      " 766/861: episode: 465, duration: 0.069s, episode steps: 2, steps per second: 29, episode reward: 882423.849, mean reward: 441211.925 [-116394.202, 998818.051], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 358082019328.000000, mean_q: 183.122452\n",
      "========== Model Saver output =============="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114416.764871\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999209.025720\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116182.283869\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 998818.050760\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116394.201711\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 998818.050760\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116394.201711\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mean_q value: 1.836260e+02\n",
      "Step 00768: model improved\n",
      "  from 1.831225e+02\n",
      "    to 1.836260e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.836260e+02_episode00465\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.836260e+02_episode00465 has done.\n",
      "max mean_q value: 1.836260e+02\n",
      "========== /Model Saver output =============\n",
      " 768/861: episode: 466, duration: 0.063s, episode steps: 2, steps per second: 32, episode reward: 882423.849, mean reward: 441211.925 [-116394.202, 998818.051], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 307816103936.000000, mean_q: 183.625992\n",
      " 768/861: episode: 466, duration: 0.064s, episode steps: 2, steps per second: 31, episode reward: 882423.849, mean reward: 441211.925 [-116394.202, 998818.051], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 307816103936.000000, mean_q: 183.625992\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.840894e+02\n",
      "Step 00771: model improved\n",
      "  from 1.836260e+02\n",
      "    to 1.840894e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.840894e+02_episode00466\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.840894e+02_episode00466 has done.\n",
      "max mean_q value: 1.840894e+02\n",
      "========== /Model Saver output =============\n",
      " 771/861: episode: 467, duration: 0.075s, episode steps: 3, steps per second: 40, episode reward: 2997443.507, mean reward: 999147.836 [-116182.284, 2114416.765], mean action: 1.667 [1.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 519691862016.000000, mean_q: 184.089355\n",
      " 771/861: episode: 467, duration: 0.076s, episode steps: 3, steps per second: 40, episode reward: 2997443.507, mean reward: 999147.836 [-116182.284, 2114416.765], mean action: 1.667 [1.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 519691862016.000000, mean_q: 184.089355\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.846623e+02\n",
      "Step 00773: model improved\n",
      "  from 1.840894e+02\n",
      "    to 1.846623e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.846623e+02_episode00467\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.846623e+02_episode00467 has done.\n",
      "max mean_q value: 1.846623e+02\n",
      "========== /Model Saver output =============\n",
      " 773/861: episode: 468, duration: 0.063s, episode steps: 2, steps per second: 32, episode reward: 882423.849, mean reward: 441211.925 [-116394.202, 998818.051], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 346362904576.000000, mean_q: 184.662323\n",
      " 773/861: episode: 468, duration: 0.064s, episode steps: 2, steps per second: 31, episode reward: 882423.849, mean reward: 441211.925 [-116394.202, 998818.051], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 346362904576.000000, mean_q: 184.662323\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.849566e+02\n",
      "Step 00775: model improved\n",
      "  from 1.846623e+02\n",
      "    to 1.849566e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.849566e+02_episode00468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 3230015.478982\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 3230019.992302\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2114626.539646\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999406.995466\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_step 000004 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115820.066903\n",
      "now_datetime: 2017-10-02 00:20:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000004 [2017-10-02 00:20:00]\n",
      "   after: 000005 [2017-10-02 00:25:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114421.278191\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999209.025720\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116180.140042\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.849566e+02_episode00468 has done.\n",
      "max mean_q value: 1.849566e+02\n",
      "========== /Model Saver output =============\n",
      " 775/861: episode: 469, duration: 0.064s, episode steps: 2, steps per second: 31, episode reward: 882423.849, mean reward: 441211.925 [-116394.202, 998818.051], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 408720834560.000000, mean_q: 184.956635\n",
      " 775/861: episode: 469, duration: 0.065s, episode steps: 2, steps per second: 31, episode reward: 882423.849, mean reward: 441211.925 [-116394.202, 998818.051], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 408720834560.000000, mean_q: 184.956635\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.856053e+02\n",
      "Step 00780: model improved\n",
      "  from 1.849566e+02\n",
      "    to 1.856053e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.856053e+02_episode00469\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.856053e+02_episode00469 has done.\n",
      "max mean_q value: 1.856053e+02\n",
      "========== /Model Saver output =============\n",
      " 780/861: episode: 470, duration: 0.111s, episode steps: 5, steps per second: 45, episode reward: 9458248.939, mean reward: 1891649.788 [-115820.067, 3230019.992], mean action: 1.600 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 370048827392.000000, mean_q: 185.605347\n",
      " 780/861: episode: 470, duration: 0.113s, episode steps: 5, steps per second: 44, episode reward: 9458248.939, mean reward: 1891649.788 [-115820.067, 3230019.992], mean action: 1.600 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 370048827392.000000, mean_q: 185.605347\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.861745e+02\n",
      "Step 00783: model improved\n",
      "  from 1.856053e+02\n",
      "    to 1.861745e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.861745e+02_episode00470\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.861745e+02_episode00470 has done.\n",
      "max mean_q value: 1.861745e+02\n",
      "========== /Model Saver output =============\n",
      " 783/861: episode: 471, duration: 0.078s, episode steps: 3, steps per second: 38, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 416744603648.000000, mean_q: 186.174515\n",
      " 783/861: episode: 471, duration: 0.079s, episode steps: 3, steps per second: 38, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 416744603648.000000, mean_q: 186.174515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114421.278191\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999209.025720\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116180.140042\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114421.278191\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999209.025720\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116180.140042\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114421.278191\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999209.025720\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116180.140042\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114421.278191\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999209.025720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.867179e+02\n",
      "Step 00786: model improved\n",
      "  from 1.861745e+02\n",
      "    to 1.867179e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.867179e+02_episode00471\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.867179e+02_episode00471 has done.\n",
      "max mean_q value: 1.867179e+02\n",
      "========== /Model Saver output =============\n",
      " 786/861: episode: 472, duration: 0.088s, episode steps: 3, steps per second: 34, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 452416667648.000000, mean_q: 186.717911\n",
      " 786/861: episode: 472, duration: 0.088s, episode steps: 3, steps per second: 34, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 452416667648.000000, mean_q: 186.717911\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.872533e+02\n",
      "Step 00789: model improved\n",
      "  from 1.867179e+02\n",
      "    to 1.872533e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.872533e+02_episode00472\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.872533e+02_episode00472 has done.\n",
      "max mean_q value: 1.872533e+02\n",
      "========== /Model Saver output =============\n",
      " 789/861: episode: 473, duration: 0.078s, episode steps: 3, steps per second: 38, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 328709079040.000000, mean_q: 187.253296\n",
      " 789/861: episode: 473, duration: 0.079s, episode steps: 3, steps per second: 38, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 328709079040.000000, mean_q: 187.253296\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.876132e+02\n",
      "Step 00792: model improved\n",
      "  from 1.872533e+02\n",
      "    to 1.876132e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.876132e+02_episode00473\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.876132e+02_episode00473 has done.\n",
      "max mean_q value: 1.876132e+02\n",
      "========== /Model Saver output =============\n",
      " 792/861: episode: 474, duration: 0.081s, episode steps: 3, steps per second: 37, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 336296673280.000000, mean_q: 187.613235\n",
      " 792/861: episode: 474, duration: 0.082s, episode steps: 3, steps per second: 37, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 336296673280.000000, mean_q: 187.613235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116180.140042\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114421.278191\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999209.025720\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116180.140042\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114421.278191\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999209.025720\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116180.140042\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114421.278191\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.880919e+02\n",
      "Step 00795: model improved\n",
      "  from 1.876132e+02\n",
      "    to 1.880919e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.880919e+02_episode00474\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.880919e+02_episode00474 has done.\n",
      "max mean_q value: 1.880919e+02\n",
      "========== /Model Saver output =============\n",
      " 795/861: episode: 475, duration: 0.075s, episode steps: 3, steps per second: 40, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 475943501824.000000, mean_q: 188.091919\n",
      " 795/861: episode: 475, duration: 0.076s, episode steps: 3, steps per second: 40, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 475943501824.000000, mean_q: 188.091919\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.886078e+02\n",
      "Step 00798: model improved\n",
      "  from 1.880919e+02\n",
      "    to 1.886078e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.886078e+02_episode00475\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.886078e+02_episode00475 has done.\n",
      "max mean_q value: 1.886078e+02\n",
      "========== /Model Saver output =============\n",
      " 798/861: episode: 476, duration: 0.076s, episode steps: 3, steps per second: 40, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 361939140608.000000, mean_q: 188.607773\n",
      " 798/861: episode: 476, duration: 0.076s, episode steps: 3, steps per second: 39, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 361939140608.000000, mean_q: 188.607773\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.889816e+02\n",
      "Step 00801: model improved\n",
      "  from 1.886078e+02\n",
      "    to 1.889816e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.889816e+02_episode00476\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.889816e+02_episode00476 has done.\n",
      "max mean_q value: 1.889816e+02\n",
      "========== /Model Saver output =============\n",
      " 801/861: episode: 477, duration: 0.083s, episode steps: 3, steps per second: 36, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 400826138624.000000, mean_q: 188.981567\n",
      " 801/861: episode: 477, duration: 0.084s, episode steps: 3, steps per second: 36, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 400826138624.000000, mean_q: 188.981567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999209.025720\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116180.140042\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114421.278191\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999209.025720\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116180.140042\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2114421.278191\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999209.025720\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116180.140042\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 4345618.706413\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 4345623.219733\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.896265e+02\n",
      "Step 00804: model improved\n",
      "  from 1.889816e+02\n",
      "    to 1.896265e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.896265e+02_episode00477\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.896265e+02_episode00477 has done.\n",
      "max mean_q value: 1.896265e+02\n",
      "========== /Model Saver output =============\n",
      " 804/861: episode: 478, duration: 0.098s, episode steps: 3, steps per second: 31, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 548043456512.000000, mean_q: 189.626541\n",
      " 804/861: episode: 478, duration: 0.098s, episode steps: 3, steps per second: 31, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 548043456512.000000, mean_q: 189.626541\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.901677e+02\n",
      "Step 00807: model improved\n",
      "  from 1.896265e+02\n",
      "    to 1.901677e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.901677e+02_episode00478\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.901677e+02_episode00478 has done.\n",
      "max mean_q value: 1.901677e+02\n",
      "========== /Model Saver output =============\n",
      " 807/861: episode: 479, duration: 0.077s, episode steps: 3, steps per second: 39, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 346830307328.000000, mean_q: 190.167725\n",
      " 807/861: episode: 479, duration: 0.077s, episode steps: 3, steps per second: 39, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 346830307328.000000, mean_q: 190.167725\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.905443e+02\n",
      "Step 00810: model improved\n",
      "  from 1.901677e+02\n",
      "    to 1.905443e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.905443e+02_episode00479\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.905443e+02_episode00479 has done.\n",
      "max mean_q value: 1.905443e+02\n",
      "========== /Model Saver output =============\n",
      " 810/861: episode: 480, duration: 0.076s, episode steps: 3, steps per second: 40, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 509102686208.000000, mean_q: 190.544312\n",
      " 810/861: episode: 480, duration: 0.076s, episode steps: 3, steps per second: 39, episode reward: 2997450.164, mean reward: 999150.055 [-116180.140, 2114421.278], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 509102686208.000000, mean_q: 190.544312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 3230229.767077\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115010.222897\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_step 000004 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999783.160528\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000004 [2017-10-02 00:20:00]\n",
      "   after: 000005 [2017-10-02 00:25:00]\n",
      "_step ENDED\n",
      "_step 000005 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115736.642765\n",
      "now_datetime: 2017-10-02 00:25:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000005 [2017-10-02 00:25:00]\n",
      "   after: 000006 [2017-10-02 00:30:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 3230024.505622\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2114812.253151\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999423.087389\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115800.518059\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 3230024.505622\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2114812.253151\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999423.087389\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115800.518059\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_reset START\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.912934e+02\n",
      "Step 00816: model improved\n",
      "  from 1.905443e+02\n",
      "    to 1.912934e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.912934e+02_episode00480\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.912934e+02_episode00480 has done.\n",
      "max mean_q value: 1.912934e+02\n",
      "========== /Model Saver output =============\n",
      " 816/861: episode: 481, duration: 0.125s, episode steps: 6, steps per second: 48, episode reward: 14920528.434, mean reward: 2486754.739 [-115736.643, 4345623.220], mean action: 1.667 [0.000, 2.000], mean observation: 58.154 [1.000, 112.827], loss: 482103132160.000000, mean_q: 191.293350\n",
      " 816/861: episode: 481, duration: 0.126s, episode steps: 6, steps per second: 48, episode reward: 14920528.434, mean reward: 2486754.739 [-115736.643, 4345623.220], mean action: 1.667 [0.000, 2.000], mean observation: 58.154 [1.000, 112.827], loss: 482103132160.000000, mean_q: 191.293350\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.921031e+02\n",
      "Step 00820: model improved\n",
      "  from 1.912934e+02\n",
      "    to 1.921031e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.921031e+02_episode00481\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.921031e+02_episode00481 has done.\n",
      "max mean_q value: 1.921031e+02\n",
      "========== /Model Saver output =============\n",
      " 820/861: episode: 482, duration: 0.092s, episode steps: 4, steps per second: 43, episode reward: 6228459.328, mean reward: 1557114.832 [-115800.518, 3230024.506], mean action: 2.000 [2.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 567218077696.000000, mean_q: 192.103149\n",
      " 820/861: episode: 482, duration: 0.093s, episode steps: 4, steps per second: 43, episode reward: 6228459.328, mean reward: 1557114.832 [-115800.518, 3230024.506], mean action: 2.000 [2.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 567218077696.000000, mean_q: 192.103149\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.928127e+02\n",
      "Step 00824: model improved\n",
      "  from 1.921031e+02\n",
      "    to 1.928127e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.928127e+02_episode00482\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.928127e+02_episode00482 has done.\n",
      "max mean_q value: 1.928127e+02\n",
      "========== /Model Saver output =============\n",
      " 824/861: episode: 483, duration: 0.097s, episode steps: 4, steps per second: 41, episode reward: 6228459.328, mean reward: 1557114.832 [-115800.518, 3230024.506], mean action: 2.000 [2.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 569494601728.000000, mean_q: 192.812714\n",
      " 824/861: episode: 483, duration: 0.098s, episode steps: 4, steps per second: 41, episode reward: 6228459.328, mean reward: 1557114.832 [-115800.518, 3230024.506], mean action: 2.000 [2.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 569494601728.000000, mean_q: 192.812714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 3230024.505622\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2114812.253151\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999423.087389\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115800.518059\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 3230024.505622\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2114812.253151\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999423.087389\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115800.518059\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 3230024.505622\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2114812.253151\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999423.087389\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115800.518059\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.936282e+02\n",
      "Step 00828: model improved\n",
      "  from 1.928127e+02\n",
      "    to 1.936282e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.936282e+02_episode00483\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.936282e+02_episode00483 has done.\n",
      "max mean_q value: 1.936282e+02\n",
      "========== /Model Saver output =============\n",
      " 828/861: episode: 484, duration: 0.097s, episode steps: 4, steps per second: 41, episode reward: 6228459.328, mean reward: 1557114.832 [-115800.518, 3230024.506], mean action: 2.000 [2.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 511311347712.000000, mean_q: 193.628235\n",
      " 828/861: episode: 484, duration: 0.098s, episode steps: 4, steps per second: 41, episode reward: 6228459.328, mean reward: 1557114.832 [-115800.518, 3230024.506], mean action: 2.000 [2.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 511311347712.000000, mean_q: 193.628235\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.943121e+02\n",
      "Step 00832: model improved\n",
      "  from 1.936282e+02\n",
      "    to 1.943121e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.943121e+02_episode00484\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.943121e+02_episode00484 has done.\n",
      "max mean_q value: 1.943121e+02\n",
      "========== /Model Saver output =============\n",
      " 832/861: episode: 485, duration: 0.106s, episode steps: 4, steps per second: 38, episode reward: 6228459.328, mean reward: 1557114.832 [-115800.518, 3230024.506], mean action: 2.000 [2.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 480327139328.000000, mean_q: 194.312088\n",
      " 832/861: episode: 485, duration: 0.106s, episode steps: 4, steps per second: 38, episode reward: 6228459.328, mean reward: 1557114.832 [-115800.518, 3230024.506], mean action: 2.000 [2.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 480327139328.000000, mean_q: 194.312088\n",
      "========== Model Saver output =============="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 3230024.505622\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2114812.253151\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2114816.540045\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999599.026481\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_step 000004 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2114826.427250\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000004 [2017-10-02 00:20:00]\n",
      "   after: 000005 [2017-10-02 00:25:00]\n",
      "_step ENDED\n",
      "_step 000005 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999296.133495\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000005 [2017-10-02 00:25:00]\n",
      "   after: 000006 [2017-10-02 00:30:00]\n",
      "_step ENDED\n",
      "_step 000006 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -116243.821751\n",
      "now_datetime: 2017-10-02 00:30:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000006 [2017-10-02 00:30:00]\n",
      "   after: 000007 [2017-10-02 00:35:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999217.825934\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mean_q value: 1.949996e+02\n",
      "Step 00836: model improved\n",
      "  from 1.943121e+02\n",
      "    to 1.949996e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.949996e+02_episode00485\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.949996e+02_episode00485 has done.\n",
      "max mean_q value: 1.949996e+02\n",
      "========== /Model Saver output =============\n",
      " 836/861: episode: 486, duration: 0.098s, episode steps: 4, steps per second: 41, episode reward: 6228459.328, mean reward: 1557114.832 [-115800.518, 3230024.506], mean action: 2.000 [2.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 645033099264.000000, mean_q: 194.999603\n",
      " 836/861: episode: 486, duration: 0.099s, episode steps: 4, steps per second: 40, episode reward: 6228459.328, mean reward: 1557114.832 [-115800.518, 3230024.506], mean action: 2.000 [2.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 645033099264.000000, mean_q: 194.999603\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.959494e+02\n",
      "Step 00843: model improved\n",
      "  from 1.949996e+02\n",
      "    to 1.959494e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.959494e+02_episode00486\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.959494e+02_episode00486 has done.\n",
      "max mean_q value: 1.959494e+02\n",
      "========== /Model Saver output =============\n",
      " 843/861: episode: 487, duration: 0.153s, episode steps: 7, steps per second: 46, episode reward: 11457131.064, mean reward: 1636733.009 [-116243.822, 3230024.506], mean action: 1.571 [0.000, 2.000], mean observation: 58.406 [1.000, 112.832], loss: 516111564800.000000, mean_q: 195.949387\n",
      " 843/861: episode: 487, duration: 0.156s, episode steps: 7, steps per second: 45, episode reward: 11457131.064, mean reward: 1636733.009 [-116243.822, 3230024.506], mean action: 1.571 [0.000, 2.000], mean observation: 58.406 [1.000, 112.832], loss: 516111564800.000000, mean_q: 195.949387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "positions_buy_or_sell: 1\n",
      "reward: -115994.426537\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999217.825934\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115994.426537\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999217.825934\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115994.426537\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999217.825934\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115994.426537\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.968198e+02\n",
      "Step 00845: model improved\n",
      "  from 1.959494e+02\n",
      "    to 1.968198e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.968198e+02_episode00487\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.968198e+02_episode00487 has done.\n",
      "max mean_q value: 1.968198e+02\n",
      "========== /Model Saver output =============\n",
      " 845/861: episode: 488, duration: 0.058s, episode steps: 2, steps per second: 34, episode reward: 883223.399, mean reward: 441611.700 [-115994.427, 999217.826], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 567756849152.000000, mean_q: 196.819794\n",
      " 845/861: episode: 488, duration: 0.059s, episode steps: 2, steps per second: 34, episode reward: 883223.399, mean reward: 441611.700 [-115994.427, 999217.826], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 567756849152.000000, mean_q: 196.819794\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.973347e+02\n",
      "Step 00847: model improved\n",
      "  from 1.968198e+02\n",
      "    to 1.973347e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.973347e+02_episode00488\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.973347e+02_episode00488 has done.\n",
      "max mean_q value: 1.973347e+02\n",
      "========== /Model Saver output =============\n",
      " 847/861: episode: 489, duration: 0.069s, episode steps: 2, steps per second: 29, episode reward: 883223.399, mean reward: 441611.700 [-115994.427, 999217.826], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 389144051712.000000, mean_q: 197.334717\n",
      " 847/861: episode: 489, duration: 0.069s, episode steps: 2, steps per second: 29, episode reward: 883223.399, mean reward: 441611.700 [-115994.427, 999217.826], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 389144051712.000000, mean_q: 197.334717\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.974787e+02\n",
      "Step 00849: model improved\n",
      "  from 1.973347e+02\n",
      "    to 1.974787e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.974787e+02_episode00489\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.974787e+02_episode00489 has done.\n",
      "max mean_q value: 1.974787e+02\n",
      "========== /Model Saver output =============\n",
      " 849/861: episode: 490, duration: 0.061s, episode steps: 2, steps per second: 33, episode reward: 883223.399, mean reward: 441611.700 [-115994.427, 999217.826], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 304029433856.000000, mean_q: 197.478699\n",
      " 849/861: episode: 490, duration: 0.062s, episode steps: 2, steps per second: 32, episode reward: 883223.399, mean reward: 441611.700 [-115994.427, 999217.826], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 304029433856.000000, mean_q: 197.478699\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.980047e+02\n",
      "Step 00851: model improved\n",
      "  from 1.974787e+02\n",
      "    to 1.980047e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.980047e+02_episode00490\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.980047e+02_episode00490 has done.\n",
      "max mean_q value: 1.980047e+02\n",
      "========== /Model Saver output =============\n",
      " 851/861: episode: 491, duration: 0.048s, episode steps: 2, steps per second: 42, episode reward: 883223.399, mean reward: 441611.700 [-115994.427, 999217.826], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 563493208064.000000, mean_q: 198.004700\n",
      " 851/861: episode: 491, duration: 0.048s, episode steps: 2, steps per second: 42, episode reward: 883223.399, mean reward: 441611.700 [-115994.427, 999217.826], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 563493208064.000000, mean_q: 198.004700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999217.825934\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115994.426537\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999217.825934\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115994.426537\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999217.825934\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115994.426537\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999217.825934\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115994.426537\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999217.825934\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 1.982917e+02\n",
      "Step 00853: model improved\n",
      "  from 1.980047e+02\n",
      "    to 1.982917e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.982917e+02_episode00491\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.982917e+02_episode00491 has done.\n",
      "max mean_q value: 1.982917e+02\n",
      "========== /Model Saver output =============\n",
      " 853/861: episode: 492, duration: 0.045s, episode steps: 2, steps per second: 45, episode reward: 883223.399, mean reward: 441611.700 [-115994.427, 999217.826], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 559752675328.000000, mean_q: 198.291687\n",
      " 853/861: episode: 492, duration: 0.045s, episode steps: 2, steps per second: 44, episode reward: 883223.399, mean reward: 441611.700 [-115994.427, 999217.826], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 559752675328.000000, mean_q: 198.291687\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.987454e+02\n",
      "Step 00855: model improved\n",
      "  from 1.982917e+02\n",
      "    to 1.987454e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.987454e+02_episode00492\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.987454e+02_episode00492 has done.\n",
      "max mean_q value: 1.987454e+02\n",
      "========== /Model Saver output =============\n",
      " 855/861: episode: 493, duration: 0.046s, episode steps: 2, steps per second: 43, episode reward: 883223.399, mean reward: 441611.700 [-115994.427, 999217.826], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 741979586560.000000, mean_q: 198.745422\n",
      " 855/861: episode: 493, duration: 0.046s, episode steps: 2, steps per second: 43, episode reward: 883223.399, mean reward: 441611.700 [-115994.427, 999217.826], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 741979586560.000000, mean_q: 198.745422\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.992884e+02\n",
      "Step 00857: model improved\n",
      "  from 1.987454e+02\n",
      "    to 1.992884e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.992884e+02_episode00493\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.992884e+02_episode00493 has done.\n",
      "max mean_q value: 1.992884e+02\n",
      "========== /Model Saver output =============\n",
      " 857/861: episode: 494, duration: 0.050s, episode steps: 2, steps per second: 40, episode reward: 883223.399, mean reward: 441611.700 [-115994.427, 999217.826], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 629358198784.000000, mean_q: 199.288422\n",
      " 857/861: episode: 494, duration: 0.051s, episode steps: 2, steps per second: 39, episode reward: 883223.399, mean reward: 441611.700 [-115994.427, 999217.826], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 629358198784.000000, mean_q: 199.288422\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 1.995694e+02\n",
      "Step 00859: model improved\n",
      "  from 1.992884e+02\n",
      "    to 1.995694e+02, saving model to ./models/Keras-RL_DQN_FX_model_meanq1.995694e+02_episode00494\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq1.995694e+02_episode00494 has done.\n",
      "max mean_q value: 1.995694e+02\n",
      "========== /Model Saver output =============\n",
      " 859/861: episode: 495, duration: 0.063s, episode steps: 2, steps per second: 32, episode reward: 883223.399, mean reward: 441611.700 [-115994.427, 999217.826], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 567478124544.000000, mean_q: 199.569412\n",
      " 859/861: episode: 495, duration: 0.064s, episode steps: 2, steps per second: 31, episode reward: 883223.399, mean reward: 441611.700 [-115994.427, 999217.826], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 567478124544.000000, mean_q: 199.569412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2114421.051765\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done, took 33.626 seconds\n",
      "done, took 33.626 seconds\n",
      "elapsed_time:33.65826988220215[sec]\n",
      "17/11/05 20:00:04\n"
     ]
    }
   ],
   "source": [
    "is_to_train = True\n",
    "if is_to_train:\n",
    "    dfx.train(is_for_time_measurement=True)\n",
    "else:\n",
    "    dfx.test(1, [EpisodeLogger()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[<matplotlib.lines.Line2D at 0x7fc575d35f98>],\n",
       " [<matplotlib.lines.Line2D at 0x7fc575cf1a20>],\n",
       " [<matplotlib.lines.Line2D at 0x7fc575c82b38>],\n",
       " [<matplotlib.lines.Line2D at 0x7fc575c82cc0>]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "data = hd.data()['Close']\n",
    "x = data.index\n",
    "y = data.values\n",
    "sd = 1\n",
    "upper, middle, lower = talib.BBANDS(data.values, timeperiod=20, matype=talib.MA_Type.SMA, nbdevup=sd, nbdevdn=sd)\n",
    "[plt.plot(x, val) for val in [y, upper, middle, lower]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 112.833,  112.793,  112.812,  112.794,  112.795,  112.826,\n",
       "        112.827,  112.832,  112.841,  112.826,  112.815,  112.817,\n",
       "        112.837,  112.84 ,  112.844,  112.851,  112.9  ,  112.906,\n",
       "        112.909,  112.887,  112.888,  112.889,  112.869,  112.874,\n",
       "        112.904,  112.883,  112.851,  112.85 ,  112.878,  112.912,\n",
       "        112.901,  112.877,  112.883,  112.875,  112.889,  112.872,\n",
       "        112.862,  112.871,  112.927,  112.932,  112.939,  112.964,\n",
       "        112.995,  113.017,  113.018,  113.008,  112.991,  112.983,\n",
       "        113.009,  112.983,  112.951,  112.943,  112.944,  112.94 ,\n",
       "        112.917,  112.865,  112.832,  112.821,  112.806,  112.794,\n",
       "        112.794,  112.807,  112.829,  112.817,  112.833,  112.859,\n",
       "        112.863,  112.825,  112.852,  112.887,  112.886,  112.882,\n",
       "        112.848,  112.85 ,  112.818,  112.791,  112.794,  112.802,\n",
       "        112.807,  112.817,  112.769,  112.802,  112.804,  112.777,\n",
       "        112.773,  112.767,  112.77 ,  112.784,  112.788,  112.824,\n",
       "        112.826,  112.817,  112.836,  112.867,  112.844,  112.839,\n",
       "        112.806,  112.828,  112.826,  112.789,  112.708,  112.723,\n",
       "        112.711,  112.675,  112.681,  112.633,  112.608,  112.615,\n",
       "        112.59 ,  112.607,  112.594,  112.627,  112.588,  112.601,\n",
       "        112.565,  112.563,  112.562,  112.629,  112.625,  112.672,\n",
       "        112.862,  112.706,  112.675,  112.635,  112.609,  112.579,\n",
       "        112.563,  112.597,  112.626,  112.602,  112.636,  112.711,\n",
       "        112.722,  112.69 ,  112.681,  112.723,  112.701,  112.686,\n",
       "        112.737,  112.707,  112.679,  112.667,  112.658,  112.608,\n",
       "        112.583,  112.575,  112.573,  112.587,  112.586,  112.583,\n",
       "        112.588,  112.579,  112.6  ,  112.633,  112.658,  112.685,\n",
       "        112.69 ,  112.692,  112.687,  112.761,  112.737,  112.753,\n",
       "        112.735,  112.719,  112.713,  112.711,  112.704,  112.687,\n",
       "        112.681,  112.683,  112.65 ,  112.64 ,  112.62 ,  112.591,\n",
       "        112.611,  112.614,  112.634,  112.596,  112.611,  112.66 ,\n",
       "        112.653,  112.649,  112.658,  112.657,  112.676,  112.689,\n",
       "        112.68 ,  112.707,  112.681,  112.717,  112.728,  112.74 ,\n",
       "        112.733,  112.729,  112.742,  112.733,  112.727,  112.716,\n",
       "        112.722,  112.731,  112.729,  112.707,  112.718,  112.75 ,\n",
       "        112.709,  112.719,  112.708,  112.729,  112.736,  112.733,\n",
       "        112.716,  112.718,  112.707,  112.709,  112.711,  112.711,\n",
       "        112.736,  112.728,  112.731,  112.734,  112.728,  112.69 ,\n",
       "        112.719,  112.724,  112.714,  112.699,  112.684,  112.669,\n",
       "        112.707,  112.726,  112.728,  112.719,  112.744,  112.744,\n",
       "        112.741,  112.759,  112.765,  112.791,  112.79 ,  112.773,\n",
       "        112.802,  112.763,  112.764,  112.73 ,  112.716,  112.708,\n",
       "        112.685,  112.737,  112.731,  112.745,  112.932,  112.946,\n",
       "        112.953,  112.912,  112.925,  112.971,  112.957,  112.975,\n",
       "        112.933,  112.97 ,  112.961,  113.059,  113.056,  113.148,\n",
       "        113.142,  113.117,  113.068,  113.08 ,  113.086,  113.099,\n",
       "        113.092,  113.06 ,  113.058,  113.059,  113.066,  113.072,\n",
       "        113.072,  113.064,  113.043,  113.064,  113.071,  113.089,\n",
       "        113.124,  113.148,  113.135,  113.169,  113.137,  113.142])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Deep Q-LearningでFXしてみた](http://recruit.gmo.jp/engineer/jisedai/blog/deep-q-learning/)\n",
    "- [slide](https://www.slideshare.net/JunichiroKatsuta/deep-qlearningfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
