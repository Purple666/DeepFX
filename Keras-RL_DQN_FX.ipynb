{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Python] Keras-RLで簡単に強化学習(DQN)を試す](http://qiita.com/inoory/items/e63ade6f21766c7c2393)を参考に、エージェントを作成する。FXの自動取引を行い、利益を出すのが目標。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use('tkagg')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import talib\n",
    "from logging import getLogger, DEBUG, INFO, WARN\n",
    "import os\n",
    "\n",
    "from hist_data import HistData\n",
    "from fx_trade import FXTrade\n",
    "from deep_fx import DeepFX\n",
    "from debug_tools import DebugTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeepFX Started: 17/11/06 01:15:46\n"
     ]
    }
   ],
   "source": [
    "IS_SEND_LOG_TO_STACKDRIVER = True\n",
    "if IS_SEND_LOG_TO_STACKDRIVER:\n",
    "    import logging\n",
    "    import google.cloud.logging\n",
    "    from google.cloud.logging.handlers import CloudLoggingHandler\n",
    "    jupyter_logger = logging.getLogger()\n",
    "    jupyter_logger.setLevel(logging.WARN)\n",
    "    client = google.cloud.logging.Client \\\n",
    "        .from_service_account_json(os.environ.get('GOOGLE_SERVICE_ACCOUNT_JSON_PATH'))\n",
    "    client.setup_logging(log_level=logging.INFO)\n",
    "    handler = CloudLoggingHandler(client, name='deepfx')\n",
    "    logger = logging.getLogger()\n",
    "else:\n",
    "    from logging import StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    handler = StreamHandler()\n",
    "    logger.setLevel(INFO)\n",
    "logger.addHandler(handler)\n",
    "logger.info('DeepFX Started: %s' % DebugTools.now_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header is included\n"
     ]
    }
   ],
   "source": [
    "#import imp\n",
    "#import sys\n",
    "#del(hist_data)\n",
    "#from hist_data import HistData\n",
    "#del(hist_data)\n",
    "#imp.reload(hist_data)\n",
    "#imp.reload(sys.modules[hist_data.__module__])\n",
    "hd = HistData(csv_path = 'historical_data/DAT_ASCII_USDJPY_M1_201710_m5.csv',\n",
    "                     begin_date='2017-10-02T00:00:00',\n",
    "                     end_date='2017-10-02T23:59:59')\n",
    "                     #end_date='2017-10-09T23:59:59')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:00:00</th>\n",
       "      <td>112.808</td>\n",
       "      <td>112.833</td>\n",
       "      <td>112.805</td>\n",
       "      <td>112.833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:05:00</th>\n",
       "      <td>112.833</td>\n",
       "      <td>112.834</td>\n",
       "      <td>112.784</td>\n",
       "      <td>112.793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:10:00</th>\n",
       "      <td>112.793</td>\n",
       "      <td>112.821</td>\n",
       "      <td>112.788</td>\n",
       "      <td>112.812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:15:00</th>\n",
       "      <td>112.812</td>\n",
       "      <td>112.812</td>\n",
       "      <td>112.790</td>\n",
       "      <td>112.794</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:20:00</th>\n",
       "      <td>112.801</td>\n",
       "      <td>112.805</td>\n",
       "      <td>112.787</td>\n",
       "      <td>112.795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:25:00</th>\n",
       "      <td>112.795</td>\n",
       "      <td>112.832</td>\n",
       "      <td>112.794</td>\n",
       "      <td>112.826</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:30:00</th>\n",
       "      <td>112.826</td>\n",
       "      <td>112.834</td>\n",
       "      <td>112.820</td>\n",
       "      <td>112.827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:35:00</th>\n",
       "      <td>112.825</td>\n",
       "      <td>112.851</td>\n",
       "      <td>112.819</td>\n",
       "      <td>112.832</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:40:00</th>\n",
       "      <td>112.836</td>\n",
       "      <td>112.851</td>\n",
       "      <td>112.827</td>\n",
       "      <td>112.841</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:45:00</th>\n",
       "      <td>112.840</td>\n",
       "      <td>112.851</td>\n",
       "      <td>112.826</td>\n",
       "      <td>112.826</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:50:00</th>\n",
       "      <td>112.825</td>\n",
       "      <td>112.836</td>\n",
       "      <td>112.810</td>\n",
       "      <td>112.815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 00:55:00</th>\n",
       "      <td>112.815</td>\n",
       "      <td>112.821</td>\n",
       "      <td>112.807</td>\n",
       "      <td>112.817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:00:00</th>\n",
       "      <td>112.821</td>\n",
       "      <td>112.841</td>\n",
       "      <td>112.819</td>\n",
       "      <td>112.837</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:05:00</th>\n",
       "      <td>112.838</td>\n",
       "      <td>112.842</td>\n",
       "      <td>112.815</td>\n",
       "      <td>112.840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:10:00</th>\n",
       "      <td>112.841</td>\n",
       "      <td>112.852</td>\n",
       "      <td>112.838</td>\n",
       "      <td>112.844</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:15:00</th>\n",
       "      <td>112.843</td>\n",
       "      <td>112.858</td>\n",
       "      <td>112.841</td>\n",
       "      <td>112.851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:20:00</th>\n",
       "      <td>112.851</td>\n",
       "      <td>112.901</td>\n",
       "      <td>112.850</td>\n",
       "      <td>112.900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:25:00</th>\n",
       "      <td>112.902</td>\n",
       "      <td>112.921</td>\n",
       "      <td>112.884</td>\n",
       "      <td>112.906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:30:00</th>\n",
       "      <td>112.907</td>\n",
       "      <td>112.914</td>\n",
       "      <td>112.897</td>\n",
       "      <td>112.909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:35:00</th>\n",
       "      <td>112.910</td>\n",
       "      <td>112.910</td>\n",
       "      <td>112.887</td>\n",
       "      <td>112.887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:40:00</th>\n",
       "      <td>112.886</td>\n",
       "      <td>112.906</td>\n",
       "      <td>112.886</td>\n",
       "      <td>112.888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:45:00</th>\n",
       "      <td>112.889</td>\n",
       "      <td>112.902</td>\n",
       "      <td>112.872</td>\n",
       "      <td>112.889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:50:00</th>\n",
       "      <td>112.889</td>\n",
       "      <td>112.889</td>\n",
       "      <td>112.862</td>\n",
       "      <td>112.869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 01:55:00</th>\n",
       "      <td>112.870</td>\n",
       "      <td>112.883</td>\n",
       "      <td>112.842</td>\n",
       "      <td>112.874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 02:00:00</th>\n",
       "      <td>112.878</td>\n",
       "      <td>112.924</td>\n",
       "      <td>112.828</td>\n",
       "      <td>112.904</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 02:05:00</th>\n",
       "      <td>112.905</td>\n",
       "      <td>112.907</td>\n",
       "      <td>112.864</td>\n",
       "      <td>112.883</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 02:10:00</th>\n",
       "      <td>112.881</td>\n",
       "      <td>112.888</td>\n",
       "      <td>112.835</td>\n",
       "      <td>112.851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 02:15:00</th>\n",
       "      <td>112.852</td>\n",
       "      <td>112.861</td>\n",
       "      <td>112.827</td>\n",
       "      <td>112.850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 02:20:00</th>\n",
       "      <td>112.854</td>\n",
       "      <td>112.906</td>\n",
       "      <td>112.851</td>\n",
       "      <td>112.878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 02:25:00</th>\n",
       "      <td>112.876</td>\n",
       "      <td>112.924</td>\n",
       "      <td>112.865</td>\n",
       "      <td>112.912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 21:30:00</th>\n",
       "      <td>112.976</td>\n",
       "      <td>112.988</td>\n",
       "      <td>112.928</td>\n",
       "      <td>112.933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 21:35:00</th>\n",
       "      <td>112.934</td>\n",
       "      <td>113.005</td>\n",
       "      <td>112.934</td>\n",
       "      <td>112.970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 21:40:00</th>\n",
       "      <td>112.969</td>\n",
       "      <td>112.978</td>\n",
       "      <td>112.950</td>\n",
       "      <td>112.961</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 21:45:00</th>\n",
       "      <td>112.962</td>\n",
       "      <td>113.076</td>\n",
       "      <td>112.951</td>\n",
       "      <td>113.059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 21:50:00</th>\n",
       "      <td>113.057</td>\n",
       "      <td>113.062</td>\n",
       "      <td>113.021</td>\n",
       "      <td>113.056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 21:55:00</th>\n",
       "      <td>113.055</td>\n",
       "      <td>113.170</td>\n",
       "      <td>113.055</td>\n",
       "      <td>113.148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:00:00</th>\n",
       "      <td>113.147</td>\n",
       "      <td>113.147</td>\n",
       "      <td>113.118</td>\n",
       "      <td>113.142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:05:00</th>\n",
       "      <td>113.143</td>\n",
       "      <td>113.161</td>\n",
       "      <td>113.115</td>\n",
       "      <td>113.117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:10:00</th>\n",
       "      <td>113.119</td>\n",
       "      <td>113.151</td>\n",
       "      <td>113.056</td>\n",
       "      <td>113.068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:15:00</th>\n",
       "      <td>113.070</td>\n",
       "      <td>113.100</td>\n",
       "      <td>113.067</td>\n",
       "      <td>113.080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:20:00</th>\n",
       "      <td>113.082</td>\n",
       "      <td>113.095</td>\n",
       "      <td>113.075</td>\n",
       "      <td>113.086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:25:00</th>\n",
       "      <td>113.086</td>\n",
       "      <td>113.122</td>\n",
       "      <td>113.068</td>\n",
       "      <td>113.099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:30:00</th>\n",
       "      <td>113.099</td>\n",
       "      <td>113.120</td>\n",
       "      <td>113.084</td>\n",
       "      <td>113.092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:35:00</th>\n",
       "      <td>113.091</td>\n",
       "      <td>113.091</td>\n",
       "      <td>113.050</td>\n",
       "      <td>113.060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:40:00</th>\n",
       "      <td>113.061</td>\n",
       "      <td>113.066</td>\n",
       "      <td>113.050</td>\n",
       "      <td>113.058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:45:00</th>\n",
       "      <td>113.059</td>\n",
       "      <td>113.064</td>\n",
       "      <td>113.050</td>\n",
       "      <td>113.059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:50:00</th>\n",
       "      <td>113.060</td>\n",
       "      <td>113.068</td>\n",
       "      <td>113.054</td>\n",
       "      <td>113.066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 22:55:00</th>\n",
       "      <td>113.069</td>\n",
       "      <td>113.077</td>\n",
       "      <td>113.065</td>\n",
       "      <td>113.072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:00:00</th>\n",
       "      <td>113.073</td>\n",
       "      <td>113.082</td>\n",
       "      <td>113.056</td>\n",
       "      <td>113.072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:05:00</th>\n",
       "      <td>113.073</td>\n",
       "      <td>113.073</td>\n",
       "      <td>113.064</td>\n",
       "      <td>113.064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:10:00</th>\n",
       "      <td>113.063</td>\n",
       "      <td>113.063</td>\n",
       "      <td>113.026</td>\n",
       "      <td>113.043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:15:00</th>\n",
       "      <td>113.045</td>\n",
       "      <td>113.068</td>\n",
       "      <td>113.031</td>\n",
       "      <td>113.064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:20:00</th>\n",
       "      <td>113.065</td>\n",
       "      <td>113.084</td>\n",
       "      <td>113.064</td>\n",
       "      <td>113.071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:25:00</th>\n",
       "      <td>113.080</td>\n",
       "      <td>113.105</td>\n",
       "      <td>113.080</td>\n",
       "      <td>113.089</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:30:00</th>\n",
       "      <td>113.088</td>\n",
       "      <td>113.127</td>\n",
       "      <td>113.078</td>\n",
       "      <td>113.124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:35:00</th>\n",
       "      <td>113.124</td>\n",
       "      <td>113.155</td>\n",
       "      <td>113.124</td>\n",
       "      <td>113.148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:40:00</th>\n",
       "      <td>113.147</td>\n",
       "      <td>113.147</td>\n",
       "      <td>113.111</td>\n",
       "      <td>113.135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:45:00</th>\n",
       "      <td>113.135</td>\n",
       "      <td>113.175</td>\n",
       "      <td>113.129</td>\n",
       "      <td>113.169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:50:00</th>\n",
       "      <td>113.167</td>\n",
       "      <td>113.178</td>\n",
       "      <td>113.125</td>\n",
       "      <td>113.137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02 23:55:00</th>\n",
       "      <td>113.139</td>\n",
       "      <td>113.155</td>\n",
       "      <td>113.128</td>\n",
       "      <td>113.142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Open     High      Low    Close  Volume\n",
       "Date                                                           \n",
       "2017-10-02 00:00:00  112.808  112.833  112.805  112.833       0\n",
       "2017-10-02 00:05:00  112.833  112.834  112.784  112.793       0\n",
       "2017-10-02 00:10:00  112.793  112.821  112.788  112.812       0\n",
       "2017-10-02 00:15:00  112.812  112.812  112.790  112.794       0\n",
       "2017-10-02 00:20:00  112.801  112.805  112.787  112.795       0\n",
       "2017-10-02 00:25:00  112.795  112.832  112.794  112.826       0\n",
       "2017-10-02 00:30:00  112.826  112.834  112.820  112.827       0\n",
       "2017-10-02 00:35:00  112.825  112.851  112.819  112.832       0\n",
       "2017-10-02 00:40:00  112.836  112.851  112.827  112.841       0\n",
       "2017-10-02 00:45:00  112.840  112.851  112.826  112.826       0\n",
       "2017-10-02 00:50:00  112.825  112.836  112.810  112.815       0\n",
       "2017-10-02 00:55:00  112.815  112.821  112.807  112.817       0\n",
       "2017-10-02 01:00:00  112.821  112.841  112.819  112.837       0\n",
       "2017-10-02 01:05:00  112.838  112.842  112.815  112.840       0\n",
       "2017-10-02 01:10:00  112.841  112.852  112.838  112.844       0\n",
       "2017-10-02 01:15:00  112.843  112.858  112.841  112.851       0\n",
       "2017-10-02 01:20:00  112.851  112.901  112.850  112.900       0\n",
       "2017-10-02 01:25:00  112.902  112.921  112.884  112.906       0\n",
       "2017-10-02 01:30:00  112.907  112.914  112.897  112.909       0\n",
       "2017-10-02 01:35:00  112.910  112.910  112.887  112.887       0\n",
       "2017-10-02 01:40:00  112.886  112.906  112.886  112.888       0\n",
       "2017-10-02 01:45:00  112.889  112.902  112.872  112.889       0\n",
       "2017-10-02 01:50:00  112.889  112.889  112.862  112.869       0\n",
       "2017-10-02 01:55:00  112.870  112.883  112.842  112.874       0\n",
       "2017-10-02 02:00:00  112.878  112.924  112.828  112.904       0\n",
       "2017-10-02 02:05:00  112.905  112.907  112.864  112.883       0\n",
       "2017-10-02 02:10:00  112.881  112.888  112.835  112.851       0\n",
       "2017-10-02 02:15:00  112.852  112.861  112.827  112.850       0\n",
       "2017-10-02 02:20:00  112.854  112.906  112.851  112.878       0\n",
       "2017-10-02 02:25:00  112.876  112.924  112.865  112.912       0\n",
       "...                      ...      ...      ...      ...     ...\n",
       "2017-10-02 21:30:00  112.976  112.988  112.928  112.933       0\n",
       "2017-10-02 21:35:00  112.934  113.005  112.934  112.970       0\n",
       "2017-10-02 21:40:00  112.969  112.978  112.950  112.961       0\n",
       "2017-10-02 21:45:00  112.962  113.076  112.951  113.059       0\n",
       "2017-10-02 21:50:00  113.057  113.062  113.021  113.056       0\n",
       "2017-10-02 21:55:00  113.055  113.170  113.055  113.148       0\n",
       "2017-10-02 22:00:00  113.147  113.147  113.118  113.142       0\n",
       "2017-10-02 22:05:00  113.143  113.161  113.115  113.117       0\n",
       "2017-10-02 22:10:00  113.119  113.151  113.056  113.068       0\n",
       "2017-10-02 22:15:00  113.070  113.100  113.067  113.080       0\n",
       "2017-10-02 22:20:00  113.082  113.095  113.075  113.086       0\n",
       "2017-10-02 22:25:00  113.086  113.122  113.068  113.099       0\n",
       "2017-10-02 22:30:00  113.099  113.120  113.084  113.092       0\n",
       "2017-10-02 22:35:00  113.091  113.091  113.050  113.060       0\n",
       "2017-10-02 22:40:00  113.061  113.066  113.050  113.058       0\n",
       "2017-10-02 22:45:00  113.059  113.064  113.050  113.059       0\n",
       "2017-10-02 22:50:00  113.060  113.068  113.054  113.066       0\n",
       "2017-10-02 22:55:00  113.069  113.077  113.065  113.072       0\n",
       "2017-10-02 23:00:00  113.073  113.082  113.056  113.072       0\n",
       "2017-10-02 23:05:00  113.073  113.073  113.064  113.064       0\n",
       "2017-10-02 23:10:00  113.063  113.063  113.026  113.043       0\n",
       "2017-10-02 23:15:00  113.045  113.068  113.031  113.064       0\n",
       "2017-10-02 23:20:00  113.065  113.084  113.064  113.071       0\n",
       "2017-10-02 23:25:00  113.080  113.105  113.080  113.089       0\n",
       "2017-10-02 23:30:00  113.088  113.127  113.078  113.124       0\n",
       "2017-10-02 23:35:00  113.124  113.155  113.124  113.148       0\n",
       "2017-10-02 23:40:00  113.147  113.147  113.111  113.135       0\n",
       "2017-10-02 23:45:00  113.135  113.175  113.129  113.169       0\n",
       "2017-10-02 23:50:00  113.167  113.178  113.125  113.137       0\n",
       "2017-10-02 23:55:00  113.139  113.155  113.128  113.142       0\n",
       "\n",
       "[288 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd.data()\n",
    "#len(hist_data.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FXTrade(1000000, 0.08, hd, logger=logger)\n",
    "#env = FXTrade(1000000, 0.08, h, logger=logger)\n",
    "prepared_model_filename = None #'Keras-RL_DQN_FX_model_meanq1.440944e+06_episode00003.h5'\n",
    "dfx = DeepFX(env, prepared_model_filename=prepared_model_filename, steps = 100000, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None\n",
      "17/11/06 01:15:46\n",
      "Training for 100000 steps ...\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training for 100000 steps ...\n",
      "Training for 100000 steps ...\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "Step 00001: model improved\n",
      "  from 0.000000e+00\n",
      "    to 0.000000e+00, saving model to ./models/Keras-RL_DQN_FX_model_meanq0.000000e+00_episode00000\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq0.000000e+00_episode00000 has done."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     1/100000: episode: 1, duration: 0.070s, episode steps: 1, steps per second: 14, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "     2/100000: episode: 2, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "     3/100000: episode: 3, duration: 0.087s, episode steps: 1, steps per second: 11, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "max mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "     1/100000: episode: 1, duration: 0.068s, episode steps: 1, steps per second: 15, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "     1/100000: episode: 1, duration: 0.181s, episode steps: 1, steps per second: 6, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "     2/100000: episode: 2, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "     2/100000: episode: 2, duration: 0.063s, episode steps: 1, steps per second: 16, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "     3/100000: episode: 3, duration: 0.086s, episode steps: 1, steps per second: 12, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "     3/100000: episode: 3, duration: 0.090s, episode steps: 1, steps per second: 11, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "     4/100000: episode: 4, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "     5/100000: episode: 5, duration: 0.064s, episode steps: 1, steps per second: 16, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "     6/100000: episode: 6, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "     4/100000: episode: 4, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "     4/100000: episode: 4, duration: 0.067s, episode steps: 1, steps per second: 15, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "     5/100000: episode: 5, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "     5/100000: episode: 5, duration: 0.069s, episode steps: 1, steps per second: 15, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "     6/100000: episode: 6, duration: 0.054s, episode steps: 1, steps per second: 18, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "     6/100000: episode: 6, duration: 0.066s, episode steps: 1, steps per second: 15, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     7/100000: episode: 7, duration: 0.064s, episode steps: 1, steps per second: 16, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "     8/100000: episode: 8, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "     9/100000: episode: 9, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    10/100000: episode: 10, duration: 0.051s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "     7/100000: episode: 7, duration: 0.063s, episode steps: 1, steps per second: 16, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "     7/100000: episode: 7, duration: 0.069s, episode steps: 1, steps per second: 15, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "     8/100000: episode: 8, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "     8/100000: episode: 8, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "     9/100000: episode: 9, duration: 0.041s, episode steps: 1, steps per second: 25, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "     9/100000: episode: 9, duration: 0.049s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    10/100000: episode: 10, duration: 0.049s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    10/100000: episode: 10, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    11/100000: episode: 11, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    12/100000: episode: 12, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    13/100000: episode: 13, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    14/100000: episode: 14, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    11/100000: episode: 11, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    11/100000: episode: 11, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    12/100000: episode: 12, duration: 0.049s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    12/100000: episode: 12, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    13/100000: episode: 13, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    13/100000: episode: 13, duration: 0.049s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    14/100000: episode: 14, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    14/100000: episode: 14, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    15/100000: episode: 15, duration: 0.068s, episode steps: 1, steps per second: 15, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    16/100000: episode: 16, duration: 0.074s, episode steps: 1, steps per second: 14, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    17/100000: episode: 17, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000000.000000\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    15/100000: episode: 15, duration: 0.068s, episode steps: 1, steps per second: 15, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    15/100000: episode: 15, duration: 0.076s, episode steps: 1, steps per second: 13, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    16/100000: episode: 16, duration: 0.073s, episode steps: 1, steps per second: 14, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    16/100000: episode: 16, duration: 0.077s, episode steps: 1, steps per second: 13, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    17/100000: episode: 17, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    17/100000: episode: 17, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115207.739151\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "    19/100000: episode: 18, duration: 0.090s, episode steps: 2, steps per second: 22, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    20/100000: episode: 19, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    21/100000: episode: 20, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    22/100000: episode: 21, duration: 0.063s, episode steps: 1, steps per second: 16, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    19/100000: episode: 18, duration: 0.089s, episode steps: 2, steps per second: 23, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "    19/100000: episode: 18, duration: 0.093s, episode steps: 2, steps per second: 21, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    20/100000: episode: 19, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    20/100000: episode: 19, duration: 0.049s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    21/100000: episode: 20, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    21/100000: episode: 20, duration: 0.062s, episode steps: 1, steps per second: 16, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    22/100000: episode: 21, duration: 0.063s, episode steps: 1, steps per second: 16, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    22/100000: episode: 21, duration: 0.066s, episode steps: 1, steps per second: 15, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    23/100000: episode: 22, duration: 0.070s, episode steps: 1, steps per second: 14, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000000.000000\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115207.739151\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "    25/100000: episode: 23, duration: 0.069s, episode steps: 2, steps per second: 29, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    26/100000: episode: 24, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    27/100000: episode: 25, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    23/100000: episode: 22, duration: 0.069s, episode steps: 1, steps per second: 14, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    23/100000: episode: 22, duration: 0.073s, episode steps: 1, steps per second: 14, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    25/100000: episode: 23, duration: 0.068s, episode steps: 2, steps per second: 29, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "    25/100000: episode: 23, duration: 0.071s, episode steps: 2, steps per second: 28, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    26/100000: episode: 24, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    26/100000: episode: 24, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    27/100000: episode: 25, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    27/100000: episode: 25, duration: 0.049s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    28/100000: episode: 26, duration: 0.049s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    29/100000: episode: 27, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    30/100000: episode: 28, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000000.000000\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115207.739151\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "    32/100000: episode: 29, duration: 0.065s, episode steps: 2, steps per second: 31, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    28/100000: episode: 26, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    28/100000: episode: 26, duration: 0.051s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    29/100000: episode: 27, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    29/100000: episode: 27, duration: 0.048s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    30/100000: episode: 28, duration: 0.041s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    30/100000: episode: 28, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    32/100000: episode: 29, duration: 0.064s, episode steps: 2, steps per second: 31, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "    32/100000: episode: 29, duration: 0.067s, episode steps: 2, steps per second: 30, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    33/100000: episode: 30, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    34/100000: episode: 31, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    35/100000: episode: 32, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    36/100000: episode: 33, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    33/100000: episode: 30, duration: 0.054s, episode steps: 1, steps per second: 18, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    33/100000: episode: 30, duration: 0.059s, episode steps: 1, steps per second: 17, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    34/100000: episode: 31, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    34/100000: episode: 31, duration: 0.049s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    35/100000: episode: 32, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    35/100000: episode: 32, duration: 0.048s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    36/100000: episode: 33, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    36/100000: episode: 33, duration: 0.049s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    37/100000: episode: 34, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    38/100000: episode: 35, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    39/100000: episode: 36, duration: 0.063s, episode steps: 1, steps per second: 16, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    40/100000: episode: 37, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    37/100000: episode: 34, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    37/100000: episode: 34, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    38/100000: episode: 35, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    38/100000: episode: 35, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    39/100000: episode: 36, duration: 0.062s, episode steps: 1, steps per second: 16, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    39/100000: episode: 36, duration: 0.066s, episode steps: 1, steps per second: 15, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    40/100000: episode: 37, duration: 0.051s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    40/100000: episode: 37, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    41/100000: episode: 38, duration: 0.054s, episode steps: 1, steps per second: 18, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    42/100000: episode: 39, duration: 0.061s, episode steps: 1, steps per second: 16, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    43/100000: episode: 40, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    44/100000: episode: 41, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    41/100000: episode: 38, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    41/100000: episode: 38, duration: 0.056s, episode steps: 1, steps per second: 18, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    42/100000: episode: 39, duration: 0.057s, episode steps: 1, steps per second: 17, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    42/100000: episode: 39, duration: 0.063s, episode steps: 1, steps per second: 16, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    43/100000: episode: 40, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    43/100000: episode: 40, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    44/100000: episode: 41, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    44/100000: episode: 41, duration: 0.048s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    45/100000: episode: 42, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    46/100000: episode: 43, duration: 0.080s, episode steps: 1, steps per second: 12, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    47/100000: episode: 44, duration: 0.092s, episode steps: 1, steps per second: 11, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    45/100000: episode: 42, duration: 0.049s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    45/100000: episode: 42, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    46/100000: episode: 43, duration: 0.079s, episode steps: 1, steps per second: 13, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    46/100000: episode: 43, duration: 0.084s, episode steps: 1, steps per second: 12, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    47/100000: episode: 44, duration: 0.092s, episode steps: 1, steps per second: 11, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    47/100000: episode: 44, duration: 0.099s, episode steps: 1, steps per second: 10, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    48/100000: episode: 45, duration: 0.074s, episode steps: 1, steps per second: 14, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    49/100000: episode: 46, duration: 0.054s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    50/100000: episode: 47, duration: 0.052s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    51/100000: episode: 48, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    48/100000: episode: 45, duration: 0.073s, episode steps: 1, steps per second: 14, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    48/100000: episode: 45, duration: 0.076s, episode steps: 1, steps per second: 13, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    49/100000: episode: 46, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    49/100000: episode: 46, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    50/100000: episode: 47, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    50/100000: episode: 47, duration: 0.055s, episode steps: 1, steps per second: 18, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    51/100000: episode: 48, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    51/100000: episode: 48, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    52/100000: episode: 49, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    53/100000: episode: 50, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    54/100000: episode: 51, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    55/100000: episode: 52, duration: 0.048s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    56/100000: episode: 53, duration: 0.048s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    52/100000: episode: 49, duration: 0.049s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    52/100000: episode: 49, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    53/100000: episode: 50, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    53/100000: episode: 50, duration: 0.048s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    54/100000: episode: 51, duration: 0.038s, episode steps: 1, steps per second: 27, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    54/100000: episode: 51, duration: 0.041s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    55/100000: episode: 52, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    55/100000: episode: 52, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    56/100000: episode: 53, duration: 0.048s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    56/100000: episode: 53, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    57/100000: episode: 54, duration: 0.043s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    58/100000: episode: 55, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    59/100000: episode: 56, duration: 0.054s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    60/100000: episode: 57, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    57/100000: episode: 54, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    57/100000: episode: 54, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    58/100000: episode: 55, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    58/100000: episode: 55, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    59/100000: episode: 56, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    59/100000: episode: 56, duration: 0.057s, episode steps: 1, steps per second: 17, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    60/100000: episode: 57, duration: 0.041s, episode steps: 1, steps per second: 25, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    60/100000: episode: 57, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    61/100000: episode: 58, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    62/100000: episode: 59, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    63/100000: episode: 60, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    64/100000: episode: 61, duration: 0.041s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000000.000000\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    61/100000: episode: 58, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    61/100000: episode: 58, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    62/100000: episode: 59, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    62/100000: episode: 59, duration: 0.050s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    63/100000: episode: 60, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    63/100000: episode: 60, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    64/100000: episode: 61, duration: 0.041s, episode steps: 1, steps per second: 25, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    64/100000: episode: 61, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reward: -115207.739151\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "    66/100000: episode: 62, duration: 0.070s, episode steps: 2, steps per second: 29, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    67/100000: episode: 63, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    68/100000: episode: 64, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    69/100000: episode: 65, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    70/100000: episode: 66, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    66/100000: episode: 62, duration: 0.069s, episode steps: 2, steps per second: 29, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "    66/100000: episode: 62, duration: 0.072s, episode steps: 2, steps per second: 28, episode reward: 884792.261, mean reward: 442396.130 [-115207.739, 1000000.000], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    67/100000: episode: 63, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    67/100000: episode: 63, duration: 0.040s, episode steps: 1, steps per second: 25, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    68/100000: episode: 64, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    68/100000: episode: 64, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    69/100000: episode: 65, duration: 0.041s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    69/100000: episode: 65, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    70/100000: episode: 66, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    70/100000: episode: 66, duration: 0.053s, episode steps: 1, steps per second: 19, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    71/100000: episode: 67, duration: 0.044s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    72/100000: episode: 68, duration: 0.040s, episode steps: 1, steps per second: 25, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    73/100000: episode: 69, duration: 0.038s, episode steps: 1, steps per second: 27, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    74/100000: episode: 70, duration: 0.042s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115598.714111\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115603.227431\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000209.774775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    71/100000: episode: 67, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    71/100000: episode: 67, duration: 0.048s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    72/100000: episode: 68, duration: 0.039s, episode steps: 1, steps per second: 25, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    72/100000: episode: 68, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    73/100000: episode: 69, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    73/100000: episode: 69, duration: 0.040s, episode steps: 1, steps per second: 25, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    74/100000: episode: 70, duration: 0.041s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    74/100000: episode: 70, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115009.769405\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "    78/100000: episode: 71, duration: 0.110s, episode steps: 4, steps per second: 36, episode reward: 5116401.947, mean reward: 1279100.487 [-115009.769, 2115603.227], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000004.513320\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115207.739151\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "    80/100000: episode: 72, duration: 0.074s, episode steps: 2, steps per second: 27, episode reward: 884796.774, mean reward: 442398.387 [-115207.739, 1000004.513], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000004.513320\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000000.000000\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115393.452656\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "    83/100000: episode: 73, duration: 0.092s, episode steps: 3, steps per second: 32, episode reward: 1884611.061, mean reward: 628203.687 [-115393.453, 1000004.513], mean action: 1.333 [0.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    78/100000: episode: 71, duration: 0.108s, episode steps: 4, steps per second: 37, episode reward: 5116401.947, mean reward: 1279100.487 [-115009.769, 2115603.227], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: --, mean_q: --\n",
      "    78/100000: episode: 71, duration: 0.114s, episode steps: 4, steps per second: 35, episode reward: 5116401.947, mean reward: 1279100.487 [-115009.769, 2115603.227], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    80/100000: episode: 72, duration: 0.073s, episode steps: 2, steps per second: 27, episode reward: 884796.774, mean reward: 442398.387 [-115207.739, 1000004.513], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "    80/100000: episode: 72, duration: 0.077s, episode steps: 2, steps per second: 26, episode reward: 884796.774, mean reward: 442398.387 [-115207.739, 1000004.513], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    83/100000: episode: 73, duration: 0.092s, episode steps: 3, steps per second: 33, episode reward: 1884611.061, mean reward: 628203.687 [-115393.453, 1000004.513], mean action: 1.333 [0.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: --, mean_q: --\n",
      "    83/100000: episode: 73, duration: 0.095s, episode steps: 3, steps per second: 32, episode reward: 1884611.061, mean reward: 628203.687 [-115393.453, 1000004.513], mean action: 1.333 [0.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    84/100000: episode: 74, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    85/100000: episode: 75, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    86/100000: episode: 76, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    87/100000: episode: 77, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    88/100000: episode: 78, duration: 0.039s, episode steps: 1, steps per second: 26, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    84/100000: episode: 74, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    84/100000: episode: 74, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    85/100000: episode: 75, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    85/100000: episode: 75, duration: 0.051s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    86/100000: episode: 76, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    86/100000: episode: 76, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    87/100000: episode: 77, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    87/100000: episode: 77, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    88/100000: episode: 78, duration: 0.038s, episode steps: 1, steps per second: 26, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    88/100000: episode: 78, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    89/100000: episode: 79, duration: 0.044s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    90/100000: episode: 80, duration: 0.041s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    91/100000: episode: 81, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    92/100000: episode: 82, duration: 0.039s, episode steps: 1, steps per second: 26, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    93/100000: episode: 83, duration: 0.041s, episode steps: 1, steps per second: 24, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    89/100000: episode: 79, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    89/100000: episode: 79, duration: 0.048s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    90/100000: episode: 80, duration: 0.040s, episode steps: 1, steps per second: 25, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    90/100000: episode: 80, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    91/100000: episode: 81, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    91/100000: episode: 81, duration: 0.049s, episode steps: 1, steps per second: 20, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    92/100000: episode: 82, duration: 0.037s, episode steps: 1, steps per second: 27, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    92/100000: episode: 82, duration: 0.043s, episode steps: 1, steps per second: 23, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    93/100000: episode: 83, duration: 0.041s, episode steps: 1, steps per second: 25, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    93/100000: episode: 83, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    94/100000: episode: 84, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115598.714111\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "    95/100000: episode: 85, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000000.000000\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "reward: 2115207.739151\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115205.596084\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999988.082520\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_step 000004 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115239.092661\n",
      "now_datetime: 2017-10-02 00:20:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000004 [2017-10-02 00:20:00]\n",
      "   after: 000005 [2017-10-02 00:25:00]\n",
      "_step ENDED\n",
      "   100/100000: episode: 86, duration: 0.132s, episode steps: 5, steps per second: 38, episode reward: 6115162.325, mean reward: 1223032.465 [-115239.093, 2115207.739], mean action: 1.400 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: --, mean_q: --\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    94/100000: episode: 84, duration: 0.046s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    94/100000: episode: 84, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "    95/100000: episode: 85, duration: 0.045s, episode steps: 1, steps per second: 22, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "    95/100000: episode: 85, duration: 0.047s, episode steps: 1, steps per second: 21, episode reward: -115598.714, mean reward: -115598.714 [-115598.714, -115598.714], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: --, mean_q: --\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 0.000000e+00\n",
      "========== /Model Saver output =============\n",
      "   100/100000: episode: 86, duration: 0.131s, episode steps: 5, steps per second: 38, episode reward: 6115162.325, mean reward: 1223032.465 [-115239.093, 2115207.739], mean action: 1.400 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: --, mean_q: --\n",
      "   100/100000: episode: 86, duration: 0.138s, episode steps: 5, steps per second: 36, episode reward: 6115162.325, mean reward: 1223032.465 [-115239.093, 2115207.739], mean action: 1.400 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: --, mean_q: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   102/100000: episode: 87, duration: 0.530s, episode steps: 2, steps per second: 4, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 378058375168.000000, mean_q: 56.969555\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   104/100000: episode: 88, duration: 0.099s, episode steps: 2, steps per second: 20, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 118605537280.000000, mean_q: 57.294899\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 5.696955e+01\n",
      "Step 00102: model improved\n",
      "  from 0.000000e+00\n",
      "    to 5.696955e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.696955e+01_episode00086\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.696955e+01_episode00086 has done.\n",
      "max mean_q value: 5.696955e+01\n",
      "========== /Model Saver output =============\n",
      "   102/100000: episode: 87, duration: 0.528s, episode steps: 2, steps per second: 4, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 378058375168.000000, mean_q: 56.969555\n",
      "   102/100000: episode: 87, duration: 0.534s, episode steps: 2, steps per second: 4, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 378058375168.000000, mean_q: 56.969555\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 5.729490e+01\n",
      "Step 00104: model improved\n",
      "  from 5.696955e+01\n",
      "    to 5.729490e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.729490e+01_episode00087\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.729490e+01_episode00087 has done.\n",
      "max mean_q value: 5.729490e+01\n",
      "========== /Model Saver output =============\n",
      "   104/100000: episode: 88, duration: 0.097s, episode steps: 2, steps per second: 21, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 118605537280.000000, mean_q: 57.294899\n",
      "   104/100000: episode: 88, duration: 0.101s, episode steps: 2, steps per second: 20, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 118605537280.000000, mean_q: 57.294899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   106/100000: episode: 89, duration: 0.102s, episode steps: 2, steps per second: 20, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 165227921408.000000, mean_q: 57.396797\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   108/100000: episode: 90, duration: 0.098s, episode steps: 2, steps per second: 20, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 157502373888.000000, mean_q: 57.567028\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 5.739680e+01\n",
      "Step 00106: model improved\n",
      "  from 5.729490e+01\n",
      "    to 5.739680e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.739680e+01_episode00088\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.739680e+01_episode00088 has done.\n",
      "max mean_q value: 5.739680e+01\n",
      "========== /Model Saver output =============\n",
      "   106/100000: episode: 89, duration: 0.100s, episode steps: 2, steps per second: 20, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 165227921408.000000, mean_q: 57.396797\n",
      "   106/100000: episode: 89, duration: 0.105s, episode steps: 2, steps per second: 19, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 165227921408.000000, mean_q: 57.396797\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 5.756703e+01\n",
      "Step 00108: model improved\n",
      "  from 5.739680e+01\n",
      "    to 5.756703e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.756703e+01_episode00089\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.756703e+01_episode00089 has done.\n",
      "max mean_q value: 5.756703e+01\n",
      "========== /Model Saver output =============\n",
      "   108/100000: episode: 90, duration: 0.096s, episode steps: 2, steps per second: 21, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 157502373888.000000, mean_q: 57.567028\n",
      "   108/100000: episode: 90, duration: 0.101s, episode steps: 2, steps per second: 20, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 157502373888.000000, mean_q: 57.567028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   110/100000: episode: 91, duration: 0.122s, episode steps: 2, steps per second: 16, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 153453592576.000000, mean_q: 57.638672\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   112/100000: episode: 92, duration: 0.114s, episode steps: 2, steps per second: 18, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 110906793984.000000, mean_q: 57.752857\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 5.763867e+01\n",
      "Step 00110: model improved\n",
      "  from 5.756703e+01\n",
      "    to 5.763867e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.763867e+01_episode00090\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.763867e+01_episode00090 has done.\n",
      "max mean_q value: 5.763867e+01\n",
      "========== /Model Saver output =============\n",
      "   110/100000: episode: 91, duration: 0.120s, episode steps: 2, steps per second: 17, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 153453592576.000000, mean_q: 57.638672\n",
      "   110/100000: episode: 91, duration: 0.126s, episode steps: 2, steps per second: 16, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 153453592576.000000, mean_q: 57.638672\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 5.775286e+01\n",
      "Step 00112: model improved\n",
      "  from 5.763867e+01\n",
      "    to 5.775286e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.775286e+01_episode00091\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.775286e+01_episode00091 has done.\n",
      "max mean_q value: 5.775286e+01\n",
      "========== /Model Saver output =============\n",
      "   112/100000: episode: 92, duration: 0.113s, episode steps: 2, steps per second: 18, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 110906793984.000000, mean_q: 57.752857\n",
      "   112/100000: episode: 92, duration: 0.116s, episode steps: 2, steps per second: 17, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 110906793984.000000, mean_q: 57.752857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   114/100000: episode: 93, duration: 0.112s, episode steps: 2, steps per second: 18, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 227200679936.000000, mean_q: 57.909691\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   116/100000: episode: 94, duration: 0.128s, episode steps: 2, steps per second: 16, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 207746220032.000000, mean_q: 58.050072\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 5.790969e+01\n",
      "Step 00114: model improved\n",
      "  from 5.775286e+01\n",
      "    to 5.790969e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.790969e+01_episode00092\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.790969e+01_episode00092 has done.\n",
      "max mean_q value: 5.790969e+01\n",
      "========== /Model Saver output =============\n",
      "   114/100000: episode: 93, duration: 0.111s, episode steps: 2, steps per second: 18, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 227200679936.000000, mean_q: 57.909691\n",
      "   114/100000: episode: 93, duration: 0.116s, episode steps: 2, steps per second: 17, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 227200679936.000000, mean_q: 57.909691\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 5.805007e+01\n",
      "Step 00116: model improved\n",
      "  from 5.790969e+01\n",
      "    to 5.805007e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.805007e+01_episode00093\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.805007e+01_episode00093 has done.\n",
      "max mean_q value: 5.805007e+01\n",
      "========== /Model Saver output =============\n",
      "   116/100000: episode: 94, duration: 0.127s, episode steps: 2, steps per second: 16, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 207746220032.000000, mean_q: 58.050072\n",
      "   116/100000: episode: 94, duration: 0.133s, episode steps: 2, steps per second: 15, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 207746220032.000000, mean_q: 58.050072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   118/100000: episode: 95, duration: 0.120s, episode steps: 2, steps per second: 17, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 130337521664.000000, mean_q: 58.178497\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 999606.881973\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115605.370498\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   120/100000: episode: 96, duration: 0.139s, episode steps: 2, steps per second: 14, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 149420490752.000000, mean_q: 58.418823\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 5.817850e+01\n",
      "Step 00118: model improved\n",
      "  from 5.805007e+01\n",
      "    to 5.817850e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.817850e+01_episode00094\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.817850e+01_episode00094 has done.\n",
      "max mean_q value: 5.817850e+01\n",
      "========== /Model Saver output =============\n",
      "   118/100000: episode: 95, duration: 0.117s, episode steps: 2, steps per second: 17, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 130337521664.000000, mean_q: 58.178497\n",
      "   118/100000: episode: 95, duration: 0.123s, episode steps: 2, steps per second: 16, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 130337521664.000000, mean_q: 58.178497\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 5.841882e+01\n",
      "Step 00120: model improved\n",
      "  from 5.817850e+01\n",
      "    to 5.841882e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.841882e+01_episode00095\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.841882e+01_episode00095 has done.\n",
      "max mean_q value: 5.841882e+01\n",
      "========== /Model Saver output =============\n",
      "   120/100000: episode: 96, duration: 0.138s, episode steps: 2, steps per second: 15, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 149420490752.000000, mean_q: 58.418823\n",
      "   120/100000: episode: 96, duration: 0.144s, episode steps: 2, steps per second: 14, episode reward: 884001.511, mean reward: 442000.756 [-115605.370, 999606.882], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 149420490752.000000, mean_q: 58.418823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "positions_buy_or_sell: -1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 3230804.310195\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 3230808.823515\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115415.370859\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000195.826679\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_step 000004 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115031.235690\n",
      "now_datetime: 2017-10-02 00:20:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000004 [2017-10-02 00:20:00]\n",
      "   after: 000005 [2017-10-02 00:25:00]\n",
      "_step ENDED\n",
      "   125/100000: episode: 97, duration: 0.194s, episode steps: 5, steps per second: 26, episode reward: 9462193.096, mean reward: 1892438.619 [-115031.236, 3230808.824], mean action: 1.600 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 269813334016.000000, mean_q: 58.680531\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115210.109404\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999997.856933\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115391.308829\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "   128/100000: episode: 98, duration: 0.145s, episode steps: 3, steps per second: 21, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 187003568128.000000, mean_q: 58.946278\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 5.868053e+01\n",
      "Step 00125: model improved\n",
      "  from 5.841882e+01\n",
      "    to 5.868053e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.868053e+01_episode00096\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.868053e+01_episode00096 has done.\n",
      "max mean_q value: 5.868053e+01\n",
      "========== /Model Saver output =============\n",
      "   125/100000: episode: 97, duration: 0.194s, episode steps: 5, steps per second: 26, episode reward: 9462193.096, mean reward: 1892438.619 [-115031.236, 3230808.824], mean action: 1.600 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 269813334016.000000, mean_q: 58.680531\n",
      "   125/100000: episode: 97, duration: 0.199s, episode steps: 5, steps per second: 25, episode reward: 9462193.096, mean reward: 1892438.619 [-115031.236, 3230808.824], mean action: 1.600 [0.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 269813334016.000000, mean_q: 58.680531\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 5.894628e+01\n",
      "Step 00128: model improved\n",
      "  from 5.868053e+01\n",
      "    to 5.894628e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.894628e+01_episode00097\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.894628e+01_episode00097 has done.\n",
      "max mean_q value: 5.894628e+01\n",
      "========== /Model Saver output =============\n",
      "   128/100000: episode: 98, duration: 0.143s, episode steps: 3, steps per second: 21, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 187003568128.000000, mean_q: 58.946278\n",
      "   128/100000: episode: 98, duration: 0.153s, episode steps: 3, steps per second: 20, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 187003568128.000000, mean_q: 58.946278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reward: 2115210.109404\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999997.856933\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115391.308829\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "   131/100000: episode: 99, duration: 0.148s, episode steps: 3, steps per second: 20, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 225851392000.000000, mean_q: 59.201340\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115210.109404\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999997.856933\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115391.308829\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "   134/100000: episode: 100, duration: 0.154s, episode steps: 3, steps per second: 19, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 440332943360.000000, mean_q: 59.577099\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 5.920134e+01\n",
      "Step 00131: model improved\n",
      "  from 5.894628e+01\n",
      "    to 5.920134e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.920134e+01_episode00098\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.920134e+01_episode00098 has done.\n",
      "max mean_q value: 5.920134e+01\n",
      "========== /Model Saver output =============\n",
      "   131/100000: episode: 99, duration: 0.144s, episode steps: 3, steps per second: 21, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 225851392000.000000, mean_q: 59.201340\n",
      "   131/100000: episode: 99, duration: 0.155s, episode steps: 3, steps per second: 19, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 225851392000.000000, mean_q: 59.201340\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 5.957710e+01\n",
      "Step 00134: model improved\n",
      "  from 5.920134e+01\n",
      "    to 5.957710e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq5.957710e+01_episode00099\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq5.957710e+01_episode00099 has done.\n",
      "max mean_q value: 5.957710e+01\n",
      "========== /Model Saver output =============\n",
      "   134/100000: episode: 100, duration: 0.153s, episode steps: 3, steps per second: 20, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 440332943360.000000, mean_q: 59.577099\n",
      "   134/100000: episode: 100, duration: 0.156s, episode steps: 3, steps per second: 19, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 440332943360.000000, mean_q: 59.577099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115210.109404\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999997.856933\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115391.308829\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "   137/100000: episode: 101, duration: 0.132s, episode steps: 3, steps per second: 23, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 179395051520.000000, mean_q: 60.069248\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115210.109404\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 3230413.335235\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115019.883339\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999800.338439\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_step 000004 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115426.723890\n",
      "now_datetime: 2017-10-02 00:20:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000004 [2017-10-02 00:20:00]\n",
      "   after: 000005 [2017-10-02 00:25:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.006925e+01\n",
      "Step 00137: model improved\n",
      "  from 5.957710e+01\n",
      "    to 6.006925e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.006925e+01_episode00100\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.006925e+01_episode00100 has done.\n",
      "max mean_q value: 6.006925e+01\n",
      "========== /Model Saver output =============\n",
      "   137/100000: episode: 101, duration: 0.130s, episode steps: 3, steps per second: 23, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 179395051520.000000, mean_q: 60.069248\n",
      "   137/100000: episode: 101, duration: 0.134s, episode steps: 3, steps per second: 22, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 179395051520.000000, mean_q: 60.069248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   142/100000: episode: 102, duration: 0.210s, episode steps: 5, steps per second: 24, episode reward: 8345016.943, mean reward: 1669003.389 [-115426.724, 3230413.335], mean action: 1.800 [1.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 417008254976.000000, mean_q: 60.570385\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115210.109404\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999997.856933\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115391.308829\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "   145/100000: episode: 103, duration: 0.150s, episode steps: 3, steps per second: 20, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 463532228608.000000, mean_q: 61.164516\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.057038e+01\n",
      "Step 00142: model improved\n",
      "  from 6.006925e+01\n",
      "    to 6.057038e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.057038e+01_episode00101\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.057038e+01_episode00101 has done.\n",
      "max mean_q value: 6.057038e+01\n",
      "========== /Model Saver output =============\n",
      "   142/100000: episode: 102, duration: 0.208s, episode steps: 5, steps per second: 24, episode reward: 8345016.943, mean reward: 1669003.389 [-115426.724, 3230413.335], mean action: 1.800 [1.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 417008254976.000000, mean_q: 60.570385\n",
      "   142/100000: episode: 102, duration: 0.213s, episode steps: 5, steps per second: 23, episode reward: 8345016.943, mean reward: 1669003.389 [-115426.724, 3230413.335], mean action: 1.800 [1.000, 2.000], mean observation: 57.902 [1.000, 112.826], loss: 417008254976.000000, mean_q: 60.570385\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.116452e+01\n",
      "Step 00145: model improved\n",
      "  from 6.057038e+01\n",
      "    to 6.116452e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.116452e+01_episode00102\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.116452e+01_episode00102 has done.\n",
      "max mean_q value: 6.116452e+01\n",
      "========== /Model Saver output =============\n",
      "   145/100000: episode: 103, duration: 0.149s, episode steps: 3, steps per second: 20, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 463532228608.000000, mean_q: 61.164516\n",
      "   145/100000: episode: 103, duration: 0.151s, episode steps: 3, steps per second: 20, episode reward: 2999816.658, mean reward: 999938.886 [-115391.309, 2115210.109], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 463532228608.000000, mean_q: 61.164516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115210.109404\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999997.856933\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000002.143827\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115215.369737\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "   149/100000: episode: 104, duration: 0.181s, episode steps: 4, steps per second: 22, episode reward: 3999994.740, mean reward: 999998.685 [-115215.370, 2115210.109], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 288993607680.000000, mean_q: 61.836731\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   150/100000: episode: 105, duration: 0.076s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 501969518592.000000, mean_q: 62.380711\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   151/100000: episode: 106, duration: 0.082s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 153424625664.000000, mean_q: 62.763851\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.183673e+01\n",
      "Step 00149: model improved\n",
      "  from 6.116452e+01\n",
      "    to 6.183673e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.183673e+01_episode00103\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.183673e+01_episode00103 has done.\n",
      "max mean_q value: 6.183673e+01\n",
      "========== /Model Saver output =============\n",
      "   149/100000: episode: 104, duration: 0.179s, episode steps: 4, steps per second: 22, episode reward: 3999994.740, mean reward: 999998.685 [-115215.370, 2115210.109], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 288993607680.000000, mean_q: 61.836731\n",
      "   149/100000: episode: 104, duration: 0.182s, episode steps: 4, steps per second: 22, episode reward: 3999994.740, mean reward: 999998.685 [-115215.370, 2115210.109], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 288993607680.000000, mean_q: 61.836731\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.238071e+01\n",
      "Step 00150: model improved\n",
      "  from 6.183673e+01\n",
      "    to 6.238071e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.238071e+01_episode00104\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.238071e+01_episode00104 has done.\n",
      "max mean_q value: 6.238071e+01\n",
      "========== /Model Saver output =============\n",
      "   150/100000: episode: 105, duration: 0.075s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 501969518592.000000, mean_q: 62.380711\n",
      "   150/100000: episode: 105, duration: 0.079s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 501969518592.000000, mean_q: 62.380711\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.276385e+01\n",
      "Step 00151: model improved\n",
      "  from 6.238071e+01\n",
      "    to 6.276385e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.276385e+01_episode00105\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.276385e+01_episode00105 has done.\n",
      "max mean_q value: 6.276385e+01\n",
      "========== /Model Saver output =============\n",
      "   151/100000: episode: 106, duration: 0.081s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 153424625664.000000, mean_q: 62.763851\n",
      "   151/100000: episode: 106, duration: 0.084s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 153424625664.000000, mean_q: 62.763851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   152/100000: episode: 107, duration: 0.072s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 346450788352.000000, mean_q: 62.962414\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   153/100000: episode: 108, duration: 0.082s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 277457698816.000000, mean_q: 63.309628\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   154/100000: episode: 109, duration: 0.063s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238553923584.000000, mean_q: 63.668289\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.296241e+01\n",
      "Step 00152: model improved\n",
      "  from 6.276385e+01\n",
      "    to 6.296241e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.296241e+01_episode00106\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.296241e+01_episode00106 has done.\n",
      "max mean_q value: 6.296241e+01\n",
      "========== /Model Saver output =============\n",
      "   152/100000: episode: 107, duration: 0.071s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 346450788352.000000, mean_q: 62.962414\n",
      "   152/100000: episode: 107, duration: 0.075s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 346450788352.000000, mean_q: 62.962414\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.330963e+01\n",
      "Step 00153: model improved\n",
      "  from 6.296241e+01\n",
      "    to 6.330963e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.330963e+01_episode00107\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.330963e+01_episode00107 has done.\n",
      "max mean_q value: 6.330963e+01\n",
      "========== /Model Saver output =============\n",
      "   153/100000: episode: 108, duration: 0.080s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 277457698816.000000, mean_q: 63.309628\n",
      "   153/100000: episode: 108, duration: 0.084s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 277457698816.000000, mean_q: 63.309628\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.366829e+01\n",
      "Step 00154: model improved\n",
      "  from 6.330963e+01\n",
      "    to 6.366829e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.366829e+01_episode00108\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.366829e+01_episode00108 has done.\n",
      "max mean_q value: 6.366829e+01\n",
      "========== /Model Saver output =============\n",
      "   154/100000: episode: 109, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238553923584.000000, mean_q: 63.668289\n",
      "   154/100000: episode: 109, duration: 0.068s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238553923584.000000, mean_q: 63.668289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   155/100000: episode: 110, duration: 0.071s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 455711358976.000000, mean_q: 64.037766\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   156/100000: episode: 111, duration: 0.080s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207747809280.000000, mean_q: 64.293167\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   157/100000: episode: 112, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 269401194496.000000, mean_q: 64.334564\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.403777e+01\n",
      "Step 00155: model improved\n",
      "  from 6.366829e+01\n",
      "    to 6.403777e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.403777e+01_episode00109\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.403777e+01_episode00109 has done.\n",
      "max mean_q value: 6.403777e+01\n",
      "========== /Model Saver output =============\n",
      "   155/100000: episode: 110, duration: 0.069s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 455711358976.000000, mean_q: 64.037766\n",
      "   155/100000: episode: 110, duration: 0.075s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 455711358976.000000, mean_q: 64.037766\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.429317e+01\n",
      "Step 00156: model improved\n",
      "  from 6.403777e+01\n",
      "    to 6.429317e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.429317e+01_episode00110\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.429317e+01_episode00110 has done.\n",
      "max mean_q value: 6.429317e+01\n",
      "========== /Model Saver output =============\n",
      "   156/100000: episode: 111, duration: 0.075s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207747809280.000000, mean_q: 64.293167\n",
      "   156/100000: episode: 111, duration: 0.084s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207747809280.000000, mean_q: 64.293167\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.433456e+01\n",
      "Step 00157: model improved\n",
      "  from 6.429317e+01\n",
      "    to 6.433456e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.433456e+01_episode00111\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.433456e+01_episode00111 has done.\n",
      "max mean_q value: 6.433456e+01\n",
      "========== /Model Saver output =============\n",
      "   157/100000: episode: 112, duration: 0.058s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 269401194496.000000, mean_q: 64.334564\n",
      "   157/100000: episode: 112, duration: 0.067s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 269401194496.000000, mean_q: 64.334564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   158/100000: episode: 113, duration: 0.076s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 625967628288.000000, mean_q: 64.788353\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   159/100000: episode: 114, duration: 0.078s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 471130636288.000000, mean_q: 64.984512\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   160/100000: episode: 115, duration: 0.079s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 734529060864.000000, mean_q: 65.351364\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.478835e+01\n",
      "Step 00158: model improved\n",
      "  from 6.433456e+01\n",
      "    to 6.478835e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.478835e+01_episode00112\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.478835e+01_episode00112 has done.\n",
      "max mean_q value: 6.478835e+01\n",
      "========== /Model Saver output =============\n",
      "   158/100000: episode: 113, duration: 0.075s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 625967628288.000000, mean_q: 64.788353\n",
      "   158/100000: episode: 113, duration: 0.082s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 625967628288.000000, mean_q: 64.788353\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.498451e+01\n",
      "Step 00159: model improved\n",
      "  from 6.478835e+01\n",
      "    to 6.498451e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.498451e+01_episode00113\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.498451e+01_episode00113 has done.\n",
      "max mean_q value: 6.498451e+01\n",
      "========== /Model Saver output =============\n",
      "   159/100000: episode: 114, duration: 0.074s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 471130636288.000000, mean_q: 64.984512\n",
      "   159/100000: episode: 114, duration: 0.082s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 471130636288.000000, mean_q: 64.984512\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.535136e+01\n",
      "Step 00160: model improved\n",
      "  from 6.498451e+01\n",
      "    to 6.535136e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.535136e+01_episode00114\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.535136e+01_episode00114 has done.\n",
      "max mean_q value: 6.535136e+01\n",
      "========== /Model Saver output =============\n",
      "   160/100000: episode: 115, duration: 0.078s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 734529060864.000000, mean_q: 65.351364\n",
      "   160/100000: episode: 115, duration: 0.080s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 734529060864.000000, mean_q: 65.351364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   161/100000: episode: 116, duration: 0.083s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 308261224448.000000, mean_q: 65.545792\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   162/100000: episode: 117, duration: 0.072s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 354535211008.000000, mean_q: 65.907791\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   163/100000: episode: 118, duration: 0.065s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 192330285056.000000, mean_q: 66.227699\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.554579e+01\n",
      "Step 00161: model improved\n",
      "  from 6.535136e+01\n",
      "    to 6.554579e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.554579e+01_episode00115\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.554579e+01_episode00115 has done.\n",
      "max mean_q value: 6.554579e+01\n",
      "========== /Model Saver output =============\n",
      "   161/100000: episode: 116, duration: 0.080s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 308261224448.000000, mean_q: 65.545792\n",
      "   161/100000: episode: 116, duration: 0.085s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 308261224448.000000, mean_q: 65.545792\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.590779e+01\n",
      "Step 00162: model improved\n",
      "  from 6.554579e+01\n",
      "    to 6.590779e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.590779e+01_episode00116\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.590779e+01_episode00116 has done.\n",
      "max mean_q value: 6.590779e+01\n",
      "========== /Model Saver output =============\n",
      "   162/100000: episode: 117, duration: 0.071s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 354535211008.000000, mean_q: 65.907791\n",
      "   162/100000: episode: 117, duration: 0.078s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 354535211008.000000, mean_q: 65.907791\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.622770e+01\n",
      "Step 00163: model improved\n",
      "  from 6.590779e+01\n",
      "    to 6.622770e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.622770e+01_episode00117\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.622770e+01_episode00117 has done.\n",
      "max mean_q value: 6.622770e+01\n",
      "========== /Model Saver output =============\n",
      "   163/100000: episode: 118, duration: 0.060s, episode steps: 1, steps per second: 17, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 192330285056.000000, mean_q: 66.227699\n",
      "   163/100000: episode: 118, duration: 0.069s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 192330285056.000000, mean_q: 66.227699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   164/100000: episode: 119, duration: 0.093s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 223151325184.000000, mean_q: 66.489990\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   165/100000: episode: 120, duration: 0.074s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 231198490624.000000, mean_q: 66.749695\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   166/100000: episode: 121, duration: 0.070s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 385316093952.000000, mean_q: 66.940292\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.648999e+01\n",
      "Step 00164: model improved\n",
      "  from 6.622770e+01\n",
      "    to 6.648999e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.648999e+01_episode00118\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.648999e+01_episode00118 has done.\n",
      "max mean_q value: 6.648999e+01\n",
      "========== /Model Saver output =============\n",
      "   164/100000: episode: 119, duration: 0.092s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 223151325184.000000, mean_q: 66.489990\n",
      "   164/100000: episode: 119, duration: 0.097s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 223151325184.000000, mean_q: 66.489990\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.674969e+01\n",
      "Step 00165: model improved\n",
      "  from 6.648999e+01\n",
      "    to 6.674969e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.674969e+01_episode00119\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.674969e+01_episode00119 has done.\n",
      "max mean_q value: 6.674969e+01\n",
      "========== /Model Saver output =============\n",
      "   165/100000: episode: 120, duration: 0.073s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 231198490624.000000, mean_q: 66.749695\n",
      "   165/100000: episode: 120, duration: 0.077s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 231198490624.000000, mean_q: 66.749695\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.694029e+01\n",
      "Step 00166: model improved\n",
      "  from 6.674969e+01\n",
      "    to 6.694029e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.694029e+01_episode00120\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.694029e+01_episode00120 has done.\n",
      "max mean_q value: 6.694029e+01\n",
      "========== /Model Saver output =============\n",
      "   166/100000: episode: 121, duration: 0.068s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 385316093952.000000, mean_q: 66.940292\n",
      "   166/100000: episode: 121, duration: 0.074s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 385316093952.000000, mean_q: 66.940292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   167/100000: episode: 122, duration: 0.072s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238542028800.000000, mean_q: 67.163513\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   168/100000: episode: 123, duration: 0.070s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 339069108224.000000, mean_q: 67.383110\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   169/100000: episode: 124, duration: 0.069s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238586806272.000000, mean_q: 67.720848\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.716351e+01\n",
      "Step 00167: model improved\n",
      "  from 6.694029e+01\n",
      "    to 6.716351e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.716351e+01_episode00121\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.716351e+01_episode00121 has done.\n",
      "max mean_q value: 6.716351e+01\n",
      "========== /Model Saver output =============\n",
      "   167/100000: episode: 122, duration: 0.072s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238542028800.000000, mean_q: 67.163513\n",
      "   167/100000: episode: 122, duration: 0.076s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238542028800.000000, mean_q: 67.163513\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.738311e+01\n",
      "Step 00168: model improved\n",
      "  from 6.716351e+01\n",
      "    to 6.738311e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.738311e+01_episode00122\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.738311e+01_episode00122 has done.\n",
      "max mean_q value: 6.738311e+01\n",
      "========== /Model Saver output =============\n",
      "   168/100000: episode: 123, duration: 0.066s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 339069108224.000000, mean_q: 67.383110\n",
      "   168/100000: episode: 123, duration: 0.075s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 339069108224.000000, mean_q: 67.383110\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.772085e+01\n",
      "Step 00169: model improved\n",
      "  from 6.738311e+01\n",
      "    to 6.772085e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.772085e+01_episode00123\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.772085e+01_episode00123 has done.\n",
      "max mean_q value: 6.772085e+01\n",
      "========== /Model Saver output =============\n",
      "   169/100000: episode: 124, duration: 0.066s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238586806272.000000, mean_q: 67.720848\n",
      "   169/100000: episode: 124, duration: 0.072s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238586806272.000000, mean_q: 67.720848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   170/100000: episode: 125, duration: 0.092s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 362564943872.000000, mean_q: 67.923035\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   171/100000: episode: 126, duration: 0.070s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 262019907584.000000, mean_q: 68.130577\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   172/100000: episode: 127, duration: 0.068s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238560935936.000000, mean_q: 68.354225\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.792303e+01\n",
      "Step 00170: model improved\n",
      "  from 6.772085e+01\n",
      "    to 6.792303e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.792303e+01_episode00124\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.792303e+01_episode00124 has done.\n",
      "max mean_q value: 6.792303e+01\n",
      "========== /Model Saver output =============\n",
      "   170/100000: episode: 125, duration: 0.091s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 362564943872.000000, mean_q: 67.923035\n",
      "   170/100000: episode: 125, duration: 0.094s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 362564943872.000000, mean_q: 67.923035\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.813058e+01\n",
      "Step 00171: model improved\n",
      "  from 6.792303e+01\n",
      "    to 6.813058e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.813058e+01_episode00125\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.813058e+01_episode00125 has done.\n",
      "max mean_q value: 6.813058e+01\n",
      "========== /Model Saver output =============\n",
      "   171/100000: episode: 126, duration: 0.069s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 262019907584.000000, mean_q: 68.130577\n",
      "   171/100000: episode: 126, duration: 0.073s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 262019907584.000000, mean_q: 68.130577\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.835423e+01\n",
      "Step 00172: model improved\n",
      "  from 6.813058e+01\n",
      "    to 6.835423e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.835423e+01_episode00126\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.835423e+01_episode00126 has done.\n",
      "max mean_q value: 6.835423e+01\n",
      "========== /Model Saver output =============\n",
      "   172/100000: episode: 127, duration: 0.067s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238560935936.000000, mean_q: 68.354225\n",
      "   172/100000: episode: 127, duration: 0.070s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238560935936.000000, mean_q: 68.354225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   173/100000: episode: 128, duration: 0.098s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 618620715008.000000, mean_q: 68.567764\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   174/100000: episode: 129, duration: 0.064s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 331733172224.000000, mean_q: 68.794128\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   175/100000: episode: 130, duration: 0.080s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 215102619648.000000, mean_q: 68.952515\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.856776e+01\n",
      "Step 00173: model improved\n",
      "  from 6.835423e+01\n",
      "    to 6.856776e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.856776e+01_episode00127\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.856776e+01_episode00127 has done.\n",
      "max mean_q value: 6.856776e+01\n",
      "========== /Model Saver output =============\n",
      "   173/100000: episode: 128, duration: 0.095s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 618620715008.000000, mean_q: 68.567764\n",
      "   173/100000: episode: 128, duration: 0.100s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 618620715008.000000, mean_q: 68.567764\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.879413e+01\n",
      "Step 00174: model improved\n",
      "  from 6.856776e+01\n",
      "    to 6.879413e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.879413e+01_episode00128\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.879413e+01_episode00128 has done.\n",
      "max mean_q value: 6.879413e+01\n",
      "========== /Model Saver output =============\n",
      "   174/100000: episode: 129, duration: 0.063s, episode steps: 1, steps per second: 16, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 331733172224.000000, mean_q: 68.794128\n",
      "   174/100000: episode: 129, duration: 0.067s, episode steps: 1, steps per second: 15, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 331733172224.000000, mean_q: 68.794128\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.895251e+01\n",
      "Step 00175: model improved\n",
      "  from 6.879413e+01\n",
      "    to 6.895251e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.895251e+01_episode00129\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.895251e+01_episode00129 has done.\n",
      "max mean_q value: 6.895251e+01\n",
      "========== /Model Saver output =============\n",
      "   175/100000: episode: 130, duration: 0.078s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 215102619648.000000, mean_q: 68.952515\n",
      "   175/100000: episode: 130, duration: 0.085s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 215102619648.000000, mean_q: 68.952515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   176/100000: episode: 131, duration: 0.100s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 184288837632.000000, mean_q: 69.238586\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   177/100000: episode: 132, duration: 0.105s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 253937090560.000000, mean_q: 69.442245\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.923859e+01\n",
      "Step 00176: model improved\n",
      "  from 6.895251e+01\n",
      "    to 6.923859e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.923859e+01_episode00130\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.923859e+01_episode00130 has done.\n",
      "max mean_q value: 6.923859e+01\n",
      "========== /Model Saver output =============\n",
      "   176/100000: episode: 131, duration: 0.097s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 184288837632.000000, mean_q: 69.238586\n",
      "   176/100000: episode: 131, duration: 0.104s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 184288837632.000000, mean_q: 69.238586\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.944225e+01\n",
      "Step 00177: model improved\n",
      "  from 6.923859e+01\n",
      "    to 6.944225e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.944225e+01_episode00131\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.944225e+01_episode00131 has done.\n",
      "max mean_q value: 6.944225e+01\n",
      "========== /Model Saver output =============\n",
      "   177/100000: episode: 132, duration: 0.103s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 253937090560.000000, mean_q: 69.442245\n",
      "   177/100000: episode: 132, duration: 0.112s, episode steps: 1, steps per second: 9, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 253937090560.000000, mean_q: 69.442245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   178/100000: episode: 133, duration: 0.107s, episode steps: 1, steps per second: 9, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 300939345920.000000, mean_q: 69.648811\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   179/100000: episode: 134, duration: 0.100s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 153474269184.000000, mean_q: 69.815041\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 6.964881e+01\n",
      "Step 00178: model improved\n",
      "  from 6.944225e+01\n",
      "    to 6.964881e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.964881e+01_episode00132\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.964881e+01_episode00132 has done.\n",
      "max mean_q value: 6.964881e+01\n",
      "========== /Model Saver output =============\n",
      "   178/100000: episode: 133, duration: 0.104s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 300939345920.000000, mean_q: 69.648811\n",
      "   178/100000: episode: 133, duration: 0.110s, episode steps: 1, steps per second: 9, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 300939345920.000000, mean_q: 69.648811\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 6.981504e+01\n",
      "Step 00179: model improved\n",
      "  from 6.964881e+01\n",
      "    to 6.981504e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq6.981504e+01_episode00133\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq6.981504e+01_episode00133 has done.\n",
      "max mean_q value: 6.981504e+01\n",
      "========== /Model Saver output =============\n",
      "   179/100000: episode: 134, duration: 0.098s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 153474269184.000000, mean_q: 69.815041\n",
      "   179/100000: episode: 134, duration: 0.103s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 153474269184.000000, mean_q: 69.815041\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.000584e+01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   180/100000: episode: 135, duration: 0.098s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 393351659520.000000, mean_q: 70.005844\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   181/100000: episode: 136, duration: 0.076s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 300196233216.000000, mean_q: 70.186279\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   182/100000: episode: 137, duration: 0.080s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 471153246208.000000, mean_q: 70.449211\n",
      "_reset START\n",
      "self._seed: 100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 00180: model improved\n",
      "  from 6.981504e+01\n",
      "    to 7.000584e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.000584e+01_episode00134\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.000584e+01_episode00134 has done.\n",
      "max mean_q value: 7.000584e+01\n",
      "========== /Model Saver output =============\n",
      "   180/100000: episode: 135, duration: 0.090s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 393351659520.000000, mean_q: 70.005844\n",
      "   180/100000: episode: 135, duration: 0.101s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 393351659520.000000, mean_q: 70.005844\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.018628e+01\n",
      "Step 00181: model improved\n",
      "  from 7.000584e+01\n",
      "    to 7.018628e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.018628e+01_episode00135\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.018628e+01_episode00135 has done.\n",
      "max mean_q value: 7.018628e+01\n",
      "========== /Model Saver output =============\n",
      "   181/100000: episode: 136, duration: 0.075s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 300196233216.000000, mean_q: 70.186279\n",
      "   181/100000: episode: 136, duration: 0.078s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 300196233216.000000, mean_q: 70.186279\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.044921e+01\n",
      "Step 00182: model improved\n",
      "  from 7.018628e+01\n",
      "    to 7.044921e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.044921e+01_episode00136\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.044921e+01_episode00136 has done.\n",
      "max mean_q value: 7.044921e+01\n",
      "========== /Model Saver output =============\n",
      "   182/100000: episode: 137, duration: 0.079s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 471153246208.000000, mean_q: 70.449211\n",
      "   182/100000: episode: 137, duration: 0.082s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 471153246208.000000, mean_q: 70.449211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   183/100000: episode: 138, duration: 0.081s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 153477496832.000000, mean_q: 70.669128\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   184/100000: episode: 139, duration: 0.083s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 153442762752.000000, mean_q: 70.898094\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   185/100000: episode: 140, duration: 0.082s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 393378463744.000000, mean_q: 71.140030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.066913e+01\n",
      "Step 00183: model improved\n",
      "  from 7.044921e+01\n",
      "    to 7.066913e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.066913e+01_episode00137\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.066913e+01_episode00137 has done.\n",
      "max mean_q value: 7.066913e+01\n",
      "========== /Model Saver output =============\n",
      "   183/100000: episode: 138, duration: 0.079s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 153477496832.000000, mean_q: 70.669128\n",
      "   183/100000: episode: 138, duration: 0.091s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 153477496832.000000, mean_q: 70.669128\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.089809e+01\n",
      "Step 00184: model improved\n",
      "  from 7.066913e+01\n",
      "    to 7.089809e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.089809e+01_episode00138\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.089809e+01_episode00138 has done.\n",
      "max mean_q value: 7.089809e+01\n",
      "========== /Model Saver output =============\n",
      "   184/100000: episode: 139, duration: 0.083s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 153442762752.000000, mean_q: 70.898094\n",
      "   184/100000: episode: 139, duration: 0.085s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 153442762752.000000, mean_q: 70.898094\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.114003e+01\n",
      "Step 00185: model improved\n",
      "  from 7.089809e+01\n",
      "    to 7.114003e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.114003e+01_episode00139\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.114003e+01_episode00139 has done.\n",
      "max mean_q value: 7.114003e+01\n",
      "========== /Model Saver output =============\n",
      "   185/100000: episode: 140, duration: 0.082s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 393378463744.000000, mean_q: 71.140030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   186/100000: episode: 141, duration: 0.083s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 355238608896.000000, mean_q: 71.388489\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   187/100000: episode: 142, duration: 0.093s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 386033188864.000000, mean_q: 71.545044\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   185/100000: episode: 140, duration: 0.086s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 393378463744.000000, mean_q: 71.140030\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.138849e+01\n",
      "Step 00186: model improved\n",
      "  from 7.114003e+01\n",
      "    to 7.138849e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.138849e+01_episode00140\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.138849e+01_episode00140 has done.\n",
      "max mean_q value: 7.138849e+01\n",
      "========== /Model Saver output =============\n",
      "   186/100000: episode: 141, duration: 0.081s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 355238608896.000000, mean_q: 71.388489\n",
      "   186/100000: episode: 141, duration: 0.086s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 355238608896.000000, mean_q: 71.388489\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.154504e+01\n",
      "Step 00187: model improved\n",
      "  from 7.138849e+01\n",
      "    to 7.154504e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.154504e+01_episode00141\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.154504e+01_episode00141 has done.\n",
      "max mean_q value: 7.154504e+01\n",
      "========== /Model Saver output =============\n",
      "   187/100000: episode: 142, duration: 0.092s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 386033188864.000000, mean_q: 71.545044\n",
      "   187/100000: episode: 142, duration: 0.097s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 386033188864.000000, mean_q: 71.545044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   188/100000: episode: 143, duration: 0.113s, episode steps: 1, steps per second: 9, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238548074496.000000, mean_q: 71.773499\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   189/100000: episode: 144, duration: 0.098s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238558691328.000000, mean_q: 72.054329\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.177350e+01\n",
      "Step 00188: model improved\n",
      "  from 7.154504e+01\n",
      "    to 7.177350e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.177350e+01_episode00142\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.177350e+01_episode00142 has done.\n",
      "max mean_q value: 7.177350e+01\n",
      "========== /Model Saver output =============\n",
      "   188/100000: episode: 143, duration: 0.111s, episode steps: 1, steps per second: 9, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238548074496.000000, mean_q: 71.773499\n",
      "   188/100000: episode: 143, duration: 0.116s, episode steps: 1, steps per second: 9, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238548074496.000000, mean_q: 71.773499\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.205433e+01\n",
      "Step 00189: model improved\n",
      "  from 7.177350e+01\n",
      "    to 7.205433e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.205433e+01_episode00143\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.205433e+01_episode00143 has done.\n",
      "max mean_q value: 7.205433e+01\n",
      "========== /Model Saver output =============\n",
      "   189/100000: episode: 144, duration: 0.097s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238558691328.000000, mean_q: 72.054329\n",
      "   189/100000: episode: 144, duration: 0.107s, episode steps: 1, steps per second: 9, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238558691328.000000, mean_q: 72.054329\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.224976e+01\n",
      "Step 00190: model improved\n",
      "  from 7.205433e+01\n",
      "    to 7.224976e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.224976e+01_episode00144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   190/100000: episode: 145, duration: 0.076s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 138047078400.000000, mean_q: 72.249756\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   191/100000: episode: 146, duration: 0.080s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 83767836672.000000, mean_q: 72.392853\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   192/100000: episode: 147, duration: 0.084s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 355225108480.000000, mean_q: 72.628571\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.224976e+01_episode00144 has done.\n",
      "max mean_q value: 7.224976e+01\n",
      "========== /Model Saver output =============\n",
      "   190/100000: episode: 145, duration: 0.075s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 138047078400.000000, mean_q: 72.249756\n",
      "   190/100000: episode: 145, duration: 0.081s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 138047078400.000000, mean_q: 72.249756\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.239285e+01\n",
      "Step 00191: model improved\n",
      "  from 7.224976e+01\n",
      "    to 7.239285e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.239285e+01_episode00145\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.239285e+01_episode00145 has done.\n",
      "max mean_q value: 7.239285e+01\n",
      "========== /Model Saver output =============\n",
      "   191/100000: episode: 146, duration: 0.078s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 83767836672.000000, mean_q: 72.392853\n",
      "   191/100000: episode: 146, duration: 0.087s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 83767836672.000000, mean_q: 72.392853\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.262857e+01\n",
      "Step 00192: model improved\n",
      "  from 7.239285e+01\n",
      "    to 7.262857e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.262857e+01_episode00146\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.262857e+01_episode00146 has done.\n",
      "max mean_q value: 7.262857e+01\n",
      "========== /Model Saver output =============\n",
      "   192/100000: episode: 147, duration: 0.082s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 355225108480.000000, mean_q: 72.628571\n",
      "   192/100000: episode: 147, duration: 0.087s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 355225108480.000000, mean_q: 72.628571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   193/100000: episode: 148, duration: 0.085s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 316345024512.000000, mean_q: 72.835403\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   194/100000: episode: 149, duration: 0.101s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207696822272.000000, mean_q: 72.940636\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.283540e+01\n",
      "Step 00193: model improved\n",
      "  from 7.262857e+01\n",
      "    to 7.283540e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.283540e+01_episode00147\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.283540e+01_episode00147 has done.\n",
      "max mean_q value: 7.283540e+01\n",
      "========== /Model Saver output =============\n",
      "   193/100000: episode: 148, duration: 0.083s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 316345024512.000000, mean_q: 72.835403\n",
      "   193/100000: episode: 148, duration: 0.091s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 316345024512.000000, mean_q: 72.835403\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.294064e+01\n",
      "Step 00194: model improved\n",
      "  from 7.283540e+01\n",
      "    to 7.294064e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.294064e+01_episode00148\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.294064e+01_episode00148 has done.\n",
      "max mean_q value: 7.294064e+01\n",
      "========== /Model Saver output =============\n",
      "   194/100000: episode: 149, duration: 0.098s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207696822272.000000, mean_q: 72.940636\n",
      "   194/100000: episode: 149, duration: 0.104s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207696822272.000000, mean_q: 72.940636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   195/100000: episode: 150, duration: 0.101s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 355204628480.000000, mean_q: 73.094360\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   196/100000: episode: 151, duration: 0.076s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207718465536.000000, mean_q: 73.328278\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.309436e+01\n",
      "Step 00195: model improved\n",
      "  from 7.294064e+01\n",
      "    to 7.309436e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.309436e+01_episode00149\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.309436e+01_episode00149 has done.\n",
      "max mean_q value: 7.309436e+01\n",
      "========== /Model Saver output =============\n",
      "   195/100000: episode: 150, duration: 0.099s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 355204628480.000000, mean_q: 73.094360\n",
      "   195/100000: episode: 150, duration: 0.104s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 355204628480.000000, mean_q: 73.094360\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.332828e+01\n",
      "Step 00196: model improved\n",
      "  from 7.309436e+01\n",
      "    to 7.332828e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.332828e+01_episode00150\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.332828e+01_episode00150 has done.\n",
      "max mean_q value: 7.332828e+01\n",
      "========== /Model Saver output =============\n",
      "   196/100000: episode: 151, duration: 0.074s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207718465536.000000, mean_q: 73.328278\n",
      "   196/100000: episode: 151, duration: 0.079s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 207718465536.000000, mean_q: 73.328278\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.336196e+01\n",
      "Step 00197: model improved\n",
      "  from 7.332828e+01\n",
      "    to 7.336196e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.336196e+01_episode00151\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.336196e+01_episode00151 has done.\n",
      "max mean_q value: 7.336196e+01\n",
      "========== /Model Saver output =============\n",
      "   197/100000: episode: 152, duration: 0.092s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 262018957312.000000, mean_q: 73.361961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   197/100000: episode: 152, duration: 0.093s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 262018957312.000000, mean_q: 73.361961\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   198/100000: episode: 153, duration: 0.087s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238573846528.000000, mean_q: 73.540604\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   197/100000: episode: 152, duration: 0.097s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 262018957312.000000, mean_q: 73.361961\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.354060e+01\n",
      "Step 00198: model improved\n",
      "  from 7.336196e+01\n",
      "    to 7.354060e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.354060e+01_episode00152\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.354060e+01_episode00152 has done.\n",
      "max mean_q value: 7.354060e+01\n",
      "========== /Model Saver output =============\n",
      "   198/100000: episode: 153, duration: 0.086s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238573846528.000000, mean_q: 73.540604\n",
      "   198/100000: episode: 153, duration: 0.090s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238573846528.000000, mean_q: 73.540604\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.376295e+01\n",
      "Step 00199: model improved\n",
      "  from 7.354060e+01\n",
      "    to 7.376295e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.376295e+01_episode00153\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.376295e+01_episode00153 has done.\n",
      "max mean_q value: 7.376295e+01\n",
      "========== /Model Saver output =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   199/100000: episode: 154, duration: 0.110s, episode steps: 1, steps per second: 9, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 432297869312.000000, mean_q: 73.762955\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   200/100000: episode: 155, duration: 0.086s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 370548178944.000000, mean_q: 73.918404\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   201/100000: episode: 156, duration: 0.084s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 192320864256.000000, mean_q: 74.122406\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   199/100000: episode: 154, duration: 0.109s, episode steps: 1, steps per second: 9, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 432297869312.000000, mean_q: 73.762955\n",
      "   199/100000: episode: 154, duration: 0.117s, episode steps: 1, steps per second: 9, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 432297869312.000000, mean_q: 73.762955\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.391840e+01\n",
      "Step 00200: model improved\n",
      "  from 7.376295e+01\n",
      "    to 7.391840e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.391840e+01_episode00154\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.391840e+01_episode00154 has done.\n",
      "max mean_q value: 7.391840e+01\n",
      "========== /Model Saver output =============\n",
      "   200/100000: episode: 155, duration: 0.083s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 370548178944.000000, mean_q: 73.918404\n",
      "   200/100000: episode: 155, duration: 0.088s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 370548178944.000000, mean_q: 73.918404\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.412241e+01\n",
      "Step 00201: model improved\n",
      "  from 7.391840e+01\n",
      "    to 7.412241e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.412241e+01_episode00155\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.412241e+01_episode00155 has done.\n",
      "max mean_q value: 7.412241e+01\n",
      "========== /Model Saver output =============\n",
      "   201/100000: episode: 156, duration: 0.083s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 192320864256.000000, mean_q: 74.122406\n",
      "   201/100000: episode: 156, duration: 0.087s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 192320864256.000000, mean_q: 74.122406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   202/100000: episode: 157, duration: 0.078s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 192318783488.000000, mean_q: 74.329987\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   203/100000: episode: 158, duration: 0.102s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 223129174016.000000, mean_q: 74.487732\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.432999e+01\n",
      "Step 00202: model improved\n",
      "  from 7.412241e+01\n",
      "    to 7.432999e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.432999e+01_episode00156\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.432999e+01_episode00156 has done.\n",
      "max mean_q value: 7.432999e+01\n",
      "========== /Model Saver output =============\n",
      "   202/100000: episode: 157, duration: 0.077s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 192318783488.000000, mean_q: 74.329987\n",
      "   202/100000: episode: 157, duration: 0.080s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 192318783488.000000, mean_q: 74.329987\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.448773e+01\n",
      "Step 00203: model improved\n",
      "  from 7.432999e+01\n",
      "    to 7.448773e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.448773e+01_episode00157\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.448773e+01_episode00157 has done.\n",
      "max mean_q value: 7.448773e+01\n",
      "========== /Model Saver output =============\n",
      "   203/100000: episode: 158, duration: 0.099s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 223129174016.000000, mean_q: 74.487732\n",
      "   203/100000: episode: 158, duration: 0.105s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 223129174016.000000, mean_q: 74.487732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   204/100000: episode: 159, duration: 0.092s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 618566713344.000000, mean_q: 74.565247\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000002.143827\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   206/100000: episode: 160, duration: 0.121s, episode steps: 2, steps per second: 16, episode reward: 884796.549, mean reward: 442398.274 [-115205.595, 1000002.144], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 366596390912.000000, mean_q: 74.841080\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000002.143827\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.456525e+01\n",
      "Step 00204: model improved\n",
      "  from 7.448773e+01\n",
      "    to 7.456525e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.456525e+01_episode00158\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.456525e+01_episode00158 has done.\n",
      "max mean_q value: 7.456525e+01\n",
      "========== /Model Saver output =============\n",
      "   204/100000: episode: 159, duration: 0.090s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 618566713344.000000, mean_q: 74.565247\n",
      "   204/100000: episode: 159, duration: 0.098s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 618566713344.000000, mean_q: 74.565247\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.484108e+01\n",
      "Step 00206: model improved\n",
      "  from 7.456525e+01\n",
      "    to 7.484108e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.484108e+01_episode00159\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.484108e+01_episode00159 has done.\n",
      "max mean_q value: 7.484108e+01\n",
      "========== /Model Saver output =============\n",
      "   206/100000: episode: 160, duration: 0.120s, episode steps: 2, steps per second: 17, episode reward: 884796.549, mean reward: 442398.274 [-115205.595, 1000002.144], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 366596390912.000000, mean_q: 74.841080\n",
      "   206/100000: episode: 160, duration: 0.126s, episode steps: 2, steps per second: 16, episode reward: 884796.549, mean reward: 442398.274 [-115205.595, 1000002.144], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 366596390912.000000, mean_q: 74.841080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   208/100000: episode: 161, duration: 0.126s, episode steps: 2, steps per second: 16, episode reward: 884796.549, mean reward: 442398.274 [-115205.595, 1000002.144], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 188295708672.000000, mean_q: 75.064819\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   209/100000: episode: 162, duration: 0.096s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 362610163712.000000, mean_q: 75.315033\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.506482e+01\n",
      "Step 00208: model improved\n",
      "  from 7.484108e+01\n",
      "    to 7.506482e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.506482e+01_episode00160\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.506482e+01_episode00160 has done.\n",
      "max mean_q value: 7.506482e+01\n",
      "========== /Model Saver output =============\n",
      "   208/100000: episode: 161, duration: 0.125s, episode steps: 2, steps per second: 16, episode reward: 884796.549, mean reward: 442398.274 [-115205.595, 1000002.144], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 188295708672.000000, mean_q: 75.064819\n",
      "   208/100000: episode: 161, duration: 0.129s, episode steps: 2, steps per second: 15, episode reward: 884796.549, mean reward: 442398.274 [-115205.595, 1000002.144], mean action: 1.500 [1.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 188295708672.000000, mean_q: 75.064819\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.531503e+01\n",
      "Step 00209: model improved\n",
      "  from 7.506482e+01\n",
      "    to 7.531503e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.531503e+01_episode00161\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.531503e+01_episode00161 has done.\n",
      "max mean_q value: 7.531503e+01\n",
      "========== /Model Saver output =============\n",
      "   209/100000: episode: 162, duration: 0.095s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 362610163712.000000, mean_q: 75.315033\n",
      "   209/100000: episode: 162, duration: 0.098s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 362610163712.000000, mean_q: 75.315033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   210/100000: episode: 163, duration: 0.100s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 479221579776.000000, mean_q: 75.530853\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   211/100000: episode: 164, duration: 0.092s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 564229505024.000000, mean_q: 75.656120\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.553085e+01\n",
      "Step 00210: model improved\n",
      "  from 7.531503e+01\n",
      "    to 7.553085e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.553085e+01_episode00162\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.553085e+01_episode00162 has done.\n",
      "max mean_q value: 7.553085e+01\n",
      "========== /Model Saver output =============\n",
      "   210/100000: episode: 163, duration: 0.099s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 479221579776.000000, mean_q: 75.530853\n",
      "   210/100000: episode: 163, duration: 0.104s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 479221579776.000000, mean_q: 75.530853\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.565612e+01\n",
      "Step 00211: model improved\n",
      "  from 7.553085e+01\n",
      "    to 7.565612e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.565612e+01_episode00163\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.565612e+01_episode00163 has done.\n",
      "max mean_q value: 7.565612e+01\n",
      "========== /Model Saver output =============\n",
      "   211/100000: episode: 164, duration: 0.091s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 564229505024.000000, mean_q: 75.656120\n",
      "   211/100000: episode: 164, duration: 0.097s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 564229505024.000000, mean_q: 75.656120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   212/100000: episode: 165, duration: 0.105s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 192316997632.000000, mean_q: 75.892914\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115600.857938\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115605.371258\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000211.918602\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115007.625578\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.589291e+01\n",
      "Step 00212: model improved\n",
      "  from 7.565612e+01\n",
      "    to 7.589291e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.589291e+01_episode00164\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.589291e+01_episode00164 has done.\n",
      "max mean_q value: 7.589291e+01\n",
      "========== /Model Saver output =============\n",
      "   212/100000: episode: 165, duration: 0.103s, episode steps: 1, steps per second: 10, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 192316997632.000000, mean_q: 75.892914\n",
      "   212/100000: episode: 165, duration: 0.109s, episode steps: 1, steps per second: 9, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 192316997632.000000, mean_q: 75.892914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   216/100000: episode: 166, duration: 0.196s, episode steps: 4, steps per second: 20, episode reward: 5116410.522, mean reward: 1279102.631 [-115007.626, 2115605.371], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 260018864128.000000, mean_q: 76.211342\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   218/100000: episode: 167, duration: 0.134s, episode steps: 2, steps per second: 15, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 149408612352.000000, mean_q: 76.599091\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.621134e+01\n",
      "Step 00216: model improved\n",
      "  from 7.589291e+01\n",
      "    to 7.621134e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.621134e+01_episode00165\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.621134e+01_episode00165 has done.\n",
      "max mean_q value: 7.621134e+01\n",
      "========== /Model Saver output =============\n",
      "   216/100000: episode: 166, duration: 0.195s, episode steps: 4, steps per second: 21, episode reward: 5116410.522, mean reward: 1279102.631 [-115007.626, 2115605.371], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 260018864128.000000, mean_q: 76.211342\n",
      "   216/100000: episode: 166, duration: 0.199s, episode steps: 4, steps per second: 20, episode reward: 5116410.522, mean reward: 1279102.631 [-115007.626, 2115605.371], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 260018864128.000000, mean_q: 76.211342\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.659909e+01\n",
      "Step 00218: model improved\n",
      "  from 7.621134e+01\n",
      "    to 7.659909e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.659909e+01_episode00166\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.659909e+01_episode00166 has done.\n",
      "max mean_q value: 7.659909e+01\n",
      "========== /Model Saver output =============\n",
      "   218/100000: episode: 167, duration: 0.132s, episode steps: 2, steps per second: 15, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 149408612352.000000, mean_q: 76.599091\n",
      "   218/100000: episode: 167, duration: 0.141s, episode steps: 2, steps per second: 14, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 149408612352.000000, mean_q: 76.599091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000002.143827\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115391.308829\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "   221/100000: episode: 168, duration: 0.168s, episode steps: 3, steps per second: 18, episode reward: 1884617.492, mean reward: 628205.831 [-115391.309, 1000006.657], mean action: 1.333 [0.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 210199560192.000000, mean_q: 76.964905\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   222/100000: episode: 169, duration: 0.077s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 432248193024.000000, mean_q: 77.230293\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   223/100000: episode: 170, duration: 0.085s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 393406447616.000000, mean_q: 77.450073\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.696490e+01\n",
      "Step 00221: model improved\n",
      "  from 7.659909e+01\n",
      "    to 7.696490e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.696490e+01_episode00167\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.696490e+01_episode00167 has done.\n",
      "max mean_q value: 7.696490e+01\n",
      "========== /Model Saver output =============\n",
      "   221/100000: episode: 168, duration: 0.166s, episode steps: 3, steps per second: 18, episode reward: 1884617.492, mean reward: 628205.831 [-115391.309, 1000006.657], mean action: 1.333 [0.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 210199560192.000000, mean_q: 76.964905\n",
      "   221/100000: episode: 168, duration: 0.171s, episode steps: 3, steps per second: 18, episode reward: 1884617.492, mean reward: 628205.831 [-115391.309, 1000006.657], mean action: 1.333 [0.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 210199560192.000000, mean_q: 76.964905\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.723029e+01\n",
      "Step 00222: model improved\n",
      "  from 7.696490e+01\n",
      "    to 7.723029e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.723029e+01_episode00168\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.723029e+01_episode00168 has done.\n",
      "max mean_q value: 7.723029e+01\n",
      "========== /Model Saver output =============\n",
      "   222/100000: episode: 169, duration: 0.076s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 432248193024.000000, mean_q: 77.230293\n",
      "   222/100000: episode: 169, duration: 0.081s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 432248193024.000000, mean_q: 77.230293\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.745007e+01\n",
      "Step 00223: model improved\n",
      "  from 7.723029e+01\n",
      "    to 7.745007e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.745007e+01_episode00169\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.745007e+01_episode00169 has done.\n",
      "max mean_q value: 7.745007e+01\n",
      "========== /Model Saver output =============\n",
      "   223/100000: episode: 170, duration: 0.084s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 393406447616.000000, mean_q: 77.450073\n",
      "   223/100000: episode: 170, duration: 0.087s, episode steps: 1, steps per second: 11, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 393406447616.000000, mean_q: 77.450073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   224/100000: episode: 171, duration: 0.076s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 107190550528.000000, mean_q: 77.631805\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   225/100000: episode: 172, duration: 0.074s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 262005342208.000000, mean_q: 77.801407\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   226/100000: episode: 173, duration: 0.080s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238587052032.000000, mean_q: 77.975464\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.763181e+01\n",
      "Step 00224: model improved\n",
      "  from 7.745007e+01\n",
      "    to 7.763181e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.763181e+01_episode00170\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.763181e+01_episode00170 has done.\n",
      "max mean_q value: 7.763181e+01\n",
      "========== /Model Saver output =============\n",
      "   224/100000: episode: 171, duration: 0.075s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 107190550528.000000, mean_q: 77.631805\n",
      "   224/100000: episode: 171, duration: 0.078s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 107190550528.000000, mean_q: 77.631805\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.780141e+01\n",
      "Step 00225: model improved\n",
      "  from 7.763181e+01\n",
      "    to 7.780141e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.780141e+01_episode00171\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.780141e+01_episode00171 has done.\n",
      "max mean_q value: 7.780141e+01\n",
      "========== /Model Saver output =============\n",
      "   225/100000: episode: 172, duration: 0.073s, episode steps: 1, steps per second: 14, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 262005342208.000000, mean_q: 77.801407\n",
      "   225/100000: episode: 172, duration: 0.078s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 262005342208.000000, mean_q: 77.801407\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.797546e+01\n",
      "Step 00226: model improved\n",
      "  from 7.780141e+01\n",
      "    to 7.797546e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.797546e+01_episode00172\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.797546e+01_episode00172 has done.\n",
      "max mean_q value: 7.797546e+01\n",
      "========== /Model Saver output =============\n",
      "   226/100000: episode: 173, duration: 0.078s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238587052032.000000, mean_q: 77.975464\n",
      "   226/100000: episode: 173, duration: 0.086s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 238587052032.000000, mean_q: 77.975464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115596.570284\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "   227/100000: episode: 174, duration: 0.079s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 122618118144.000000, mean_q: 78.168129\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115600.857938\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115605.371258\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000211.918602\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115007.625578\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "   231/100000: episode: 175, duration: 0.172s, episode steps: 4, steps per second: 23, episode reward: 5116410.522, mean reward: 1279102.631 [-115007.626, 2115605.371], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 256172752896.000000, mean_q: 78.400024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.816813e+01\n",
      "Step 00227: model improved\n",
      "  from 7.797546e+01\n",
      "    to 7.816813e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.816813e+01_episode00173\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.816813e+01_episode00173 has done.\n",
      "max mean_q value: 7.816813e+01\n",
      "========== /Model Saver output =============\n",
      "   227/100000: episode: 174, duration: 0.078s, episode steps: 1, steps per second: 13, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 122618118144.000000, mean_q: 78.168129\n",
      "   227/100000: episode: 174, duration: 0.081s, episode steps: 1, steps per second: 12, episode reward: -115596.570, mean reward: -115596.570 [-115596.570, -115596.570], mean action: 2.000 [2.000, 2.000], mean observation: 56.896 [1.000, 112.793], loss: 122618118144.000000, mean_q: 78.168129\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.840002e+01\n",
      "Step 00231: model improved\n",
      "  from 7.816813e+01\n",
      "    to 7.840002e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.840002e+01_episode00174\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.840002e+01_episode00174 has done.\n",
      "max mean_q value: 7.840002e+01\n",
      "========== /Model Saver output =============\n",
      "   231/100000: episode: 175, duration: 0.169s, episode steps: 4, steps per second: 24, episode reward: 5116410.522, mean reward: 1279102.631 [-115007.626, 2115605.371], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 256172752896.000000, mean_q: 78.400024\n",
      "   231/100000: episode: 175, duration: 0.175s, episode steps: 4, steps per second: 23, episode reward: 5116410.522, mean reward: 1279102.631 [-115007.626, 2115605.371], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 256172752896.000000, mean_q: 78.400024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   233/100000: episode: 176, duration: 0.105s, episode steps: 2, steps per second: 19, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 250302267392.000000, mean_q: 78.708641\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   235/100000: episode: 177, duration: 0.128s, episode steps: 2, steps per second: 16, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 238550089728.000000, mean_q: 78.910179\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.870864e+01\n",
      "Step 00233: model improved\n",
      "  from 7.840002e+01\n",
      "    to 7.870864e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.870864e+01_episode00175\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.870864e+01_episode00175 has done.\n",
      "max mean_q value: 7.870864e+01\n",
      "========== /Model Saver output =============\n",
      "   233/100000: episode: 176, duration: 0.103s, episode steps: 2, steps per second: 19, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 250302267392.000000, mean_q: 78.708641\n",
      "   233/100000: episode: 176, duration: 0.107s, episode steps: 2, steps per second: 19, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 250302267392.000000, mean_q: 78.708641\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.891018e+01\n",
      "Step 00235: model improved\n",
      "  from 7.870864e+01\n",
      "    to 7.891018e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.891018e+01_episode00176\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.891018e+01_episode00176 has done.\n",
      "max mean_q value: 7.891018e+01\n",
      "========== /Model Saver output =============\n",
      "   235/100000: episode: 177, duration: 0.122s, episode steps: 2, steps per second: 16, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 238550089728.000000, mean_q: 78.910179\n",
      "   235/100000: episode: 177, duration: 0.133s, episode steps: 2, steps per second: 15, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 238550089728.000000, mean_q: 78.910179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   237/100000: episode: 178, duration: 0.129s, episode steps: 2, steps per second: 16, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 254337826816.000000, mean_q: 79.152084\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   239/100000: episode: 179, duration: 0.146s, episode steps: 2, steps per second: 14, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 196015947776.000000, mean_q: 79.387695\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.915208e+01\n",
      "Step 00237: model improved\n",
      "  from 7.891018e+01\n",
      "    to 7.915208e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.915208e+01_episode00177\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.915208e+01_episode00177 has done.\n",
      "max mean_q value: 7.915208e+01\n",
      "========== /Model Saver output =============\n",
      "   237/100000: episode: 178, duration: 0.127s, episode steps: 2, steps per second: 16, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 254337826816.000000, mean_q: 79.152084\n",
      "   237/100000: episode: 178, duration: 0.136s, episode steps: 2, steps per second: 15, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 254337826816.000000, mean_q: 79.152084\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.938770e+01\n",
      "Step 00239: model improved\n",
      "  from 7.915208e+01\n",
      "    to 7.938770e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.938770e+01_episode00178\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.938770e+01_episode00178 has done.\n",
      "max mean_q value: 7.938770e+01\n",
      "========== /Model Saver output =============\n",
      "   239/100000: episode: 179, duration: 0.144s, episode steps: 2, steps per second: 14, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 196015947776.000000, mean_q: 79.387695\n",
      "   239/100000: episode: 179, duration: 0.151s, episode steps: 2, steps per second: 13, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 196015947776.000000, mean_q: 79.387695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   241/100000: episode: 180, duration: 0.127s, episode steps: 2, steps per second: 16, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 324050747392.000000, mean_q: 79.633774\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   243/100000: episode: 181, duration: 0.129s, episode steps: 2, steps per second: 16, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 234897342464.000000, mean_q: 79.916107\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 7.963377e+01\n",
      "Step 00241: model improved\n",
      "  from 7.938770e+01\n",
      "    to 7.963377e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.963377e+01_episode00179\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.963377e+01_episode00179 has done.\n",
      "max mean_q value: 7.963377e+01\n",
      "========== /Model Saver output =============\n",
      "   241/100000: episode: 180, duration: 0.126s, episode steps: 2, steps per second: 16, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 324050747392.000000, mean_q: 79.633774\n",
      "   241/100000: episode: 180, duration: 0.130s, episode steps: 2, steps per second: 15, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 324050747392.000000, mean_q: 79.633774\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 7.991611e+01\n",
      "Step 00243: model improved\n",
      "  from 7.963377e+01\n",
      "    to 7.991611e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq7.991611e+01_episode00180\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq7.991611e+01_episode00180 has done.\n",
      "max mean_q value: 7.991611e+01\n",
      "========== /Model Saver output =============\n",
      "   243/100000: episode: 181, duration: 0.125s, episode steps: 2, steps per second: 16, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 234897342464.000000, mean_q: 79.916107\n",
      "   243/100000: episode: 181, duration: 0.134s, episode steps: 2, steps per second: 15, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 234897342464.000000, mean_q: 79.916107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   245/100000: episode: 182, duration: 0.135s, episode steps: 2, steps per second: 15, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 439999430656.000000, mean_q: 80.192444\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   247/100000: episode: 183, duration: 0.128s, episode steps: 2, steps per second: 16, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 157158375424.000000, mean_q: 80.510864\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.019244e+01\n",
      "Step 00245: model improved\n",
      "  from 7.991611e+01\n",
      "    to 8.019244e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.019244e+01_episode00181\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.019244e+01_episode00181 has done.\n",
      "max mean_q value: 8.019244e+01\n",
      "========== /Model Saver output =============\n",
      "   245/100000: episode: 182, duration: 0.133s, episode steps: 2, steps per second: 15, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 439999430656.000000, mean_q: 80.192444\n",
      "   245/100000: episode: 182, duration: 0.140s, episode steps: 2, steps per second: 14, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 439999430656.000000, mean_q: 80.192444\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.051086e+01\n",
      "Step 00247: model improved\n",
      "  from 8.019244e+01\n",
      "    to 8.051086e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.051086e+01_episode00182\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.051086e+01_episode00182 has done.\n",
      "max mean_q value: 8.051086e+01\n",
      "========== /Model Saver output =============\n",
      "   247/100000: episode: 183, duration: 0.126s, episode steps: 2, steps per second: 16, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 157158375424.000000, mean_q: 80.510864\n",
      "   247/100000: episode: 183, duration: 0.136s, episode steps: 2, steps per second: 15, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 157158375424.000000, mean_q: 80.510864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   249/100000: episode: 184, duration: 0.139s, episode steps: 2, steps per second: 14, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 339480543232.000000, mean_q: 80.746727\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   251/100000: episode: 185, duration: 0.149s, episode steps: 2, steps per second: 13, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 320002392064.000000, mean_q: 81.108932\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.074673e+01\n",
      "Step 00249: model improved\n",
      "  from 8.051086e+01\n",
      "    to 8.074673e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.074673e+01_episode00183\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.074673e+01_episode00183 has done.\n",
      "max mean_q value: 8.074673e+01\n",
      "========== /Model Saver output =============\n",
      "   249/100000: episode: 184, duration: 0.137s, episode steps: 2, steps per second: 15, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 339480543232.000000, mean_q: 80.746727\n",
      "   249/100000: episode: 184, duration: 0.147s, episode steps: 2, steps per second: 14, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 339480543232.000000, mean_q: 80.746727\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.110893e+01\n",
      "Step 00251: model improved\n",
      "  from 8.074673e+01\n",
      "    to 8.110893e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.110893e+01_episode00184\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.110893e+01_episode00184 has done.\n",
      "max mean_q value: 8.110893e+01\n",
      "========== /Model Saver output =============\n",
      "   251/100000: episode: 185, duration: 0.147s, episode steps: 2, steps per second: 14, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 320002392064.000000, mean_q: 81.108932\n",
      "   251/100000: episode: 185, duration: 0.153s, episode steps: 2, steps per second: 13, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 320002392064.000000, mean_q: 81.108932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   253/100000: episode: 186, duration: 0.148s, episode steps: 2, steps per second: 13, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 397461946368.000000, mean_q: 81.436417\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   255/100000: episode: 187, duration: 0.133s, episode steps: 2, steps per second: 15, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 428585517056.000000, mean_q: 81.766808\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.143642e+01\n",
      "Step 00253: model improved\n",
      "  from 8.110893e+01\n",
      "    to 8.143642e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.143642e+01_episode00185\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.143642e+01_episode00185 has done.\n",
      "max mean_q value: 8.143642e+01\n",
      "========== /Model Saver output =============\n",
      "   253/100000: episode: 186, duration: 0.147s, episode steps: 2, steps per second: 14, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 397461946368.000000, mean_q: 81.436417\n",
      "   253/100000: episode: 186, duration: 0.151s, episode steps: 2, steps per second: 13, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 397461946368.000000, mean_q: 81.436417\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.176681e+01\n",
      "Step 00255: model improved\n",
      "  from 8.143642e+01\n",
      "    to 8.176681e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.176681e+01_episode00186\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.176681e+01_episode00186 has done.\n",
      "max mean_q value: 8.176681e+01\n",
      "========== /Model Saver output =============\n",
      "   255/100000: episode: 187, duration: 0.132s, episode steps: 2, steps per second: 15, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 428585517056.000000, mean_q: 81.766808\n",
      "   255/100000: episode: 187, duration: 0.137s, episode steps: 2, steps per second: 15, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 428585517056.000000, mean_q: 81.766808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   257/100000: episode: 188, duration: 0.170s, episode steps: 2, steps per second: 12, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 211421396992.000000, mean_q: 82.109245\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   259/100000: episode: 189, duration: 0.151s, episode steps: 2, steps per second: 13, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 304598220800.000000, mean_q: 82.399460\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.210925e+01\n",
      "Step 00257: model improved\n",
      "  from 8.176681e+01\n",
      "    to 8.210925e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.210925e+01_episode00187\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.210925e+01_episode00187 has done.\n",
      "max mean_q value: 8.210925e+01\n",
      "========== /Model Saver output =============\n",
      "   257/100000: episode: 188, duration: 0.168s, episode steps: 2, steps per second: 12, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 211421396992.000000, mean_q: 82.109245\n",
      "   257/100000: episode: 188, duration: 0.173s, episode steps: 2, steps per second: 12, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 211421396992.000000, mean_q: 82.109245\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.239946e+01\n",
      "Step 00259: model improved\n",
      "  from 8.210925e+01\n",
      "    to 8.239946e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.239946e+01_episode00188\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.239946e+01_episode00188 has done.\n",
      "max mean_q value: 8.239946e+01\n",
      "========== /Model Saver output =============\n",
      "   259/100000: episode: 189, duration: 0.150s, episode steps: 2, steps per second: 13, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 304598220800.000000, mean_q: 82.399460\n",
      "   259/100000: episode: 189, duration: 0.154s, episode steps: 2, steps per second: 13, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 304598220800.000000, mean_q: 82.399460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   261/100000: episode: 190, duration: 0.154s, episode steps: 2, steps per second: 13, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 385696333824.000000, mean_q: 82.699020\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   263/100000: episode: 191, duration: 0.147s, episode steps: 2, steps per second: 14, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 234878763008.000000, mean_q: 83.014076\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.269902e+01\n",
      "Step 00261: model improved\n",
      "  from 8.239946e+01\n",
      "    to 8.269902e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.269902e+01_episode00189\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.269902e+01_episode00189 has done.\n",
      "max mean_q value: 8.269902e+01\n",
      "========== /Model Saver output =============\n",
      "   261/100000: episode: 190, duration: 0.152s, episode steps: 2, steps per second: 13, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 385696333824.000000, mean_q: 82.699020\n",
      "   261/100000: episode: 190, duration: 0.157s, episode steps: 2, steps per second: 13, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 385696333824.000000, mean_q: 82.699020\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.301408e+01\n",
      "Step 00263: model improved\n",
      "  from 8.269902e+01\n",
      "    to 8.301408e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.301408e+01_episode00190\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.301408e+01_episode00190 has done.\n",
      "max mean_q value: 8.301408e+01\n",
      "========== /Model Saver output =============\n",
      "   263/100000: episode: 191, duration: 0.146s, episode steps: 2, steps per second: 14, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 234878763008.000000, mean_q: 83.014076\n",
      "   263/100000: episode: 191, duration: 0.149s, episode steps: 2, steps per second: 13, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 234878763008.000000, mean_q: 83.014076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   265/100000: episode: 192, duration: 0.144s, episode steps: 2, steps per second: 14, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 288864436224.000000, mean_q: 83.305664\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   267/100000: episode: 193, duration: 0.118s, episode steps: 2, steps per second: 17, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 350865129472.000000, mean_q: 83.593391\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.330566e+01\n",
      "Step 00265: model improved\n",
      "  from 8.301408e+01\n",
      "    to 8.330566e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.330566e+01_episode00191\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.330566e+01_episode00191 has done.\n",
      "max mean_q value: 8.330566e+01\n",
      "========== /Model Saver output =============\n",
      "   265/100000: episode: 192, duration: 0.143s, episode steps: 2, steps per second: 14, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 288864436224.000000, mean_q: 83.305664\n",
      "   265/100000: episode: 192, duration: 0.148s, episode steps: 2, steps per second: 13, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 288864436224.000000, mean_q: 83.305664\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.359339e+01\n",
      "Step 00267: model improved\n",
      "  from 8.330566e+01\n",
      "    to 8.359339e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.359339e+01_episode00192\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.359339e+01_episode00192 has done.\n",
      "max mean_q value: 8.359339e+01\n",
      "========== /Model Saver output =============\n",
      "   267/100000: episode: 193, duration: 0.116s, episode steps: 2, steps per second: 17, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 350865129472.000000, mean_q: 83.593391\n",
      "   267/100000: episode: 193, duration: 0.121s, episode steps: 2, steps per second: 17, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 350865129472.000000, mean_q: 83.593391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   269/100000: episode: 194, duration: 0.113s, episode steps: 2, steps per second: 18, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 300603932672.000000, mean_q: 84.002563\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   271/100000: episode: 195, duration: 0.118s, episode steps: 2, steps per second: 17, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 269438795776.000000, mean_q: 84.325363\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.400256e+01\n",
      "Step 00269: model improved\n",
      "  from 8.359339e+01\n",
      "    to 8.400256e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.400256e+01_episode00193\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.400256e+01_episode00193 has done.\n",
      "max mean_q value: 8.400256e+01\n",
      "========== /Model Saver output =============\n",
      "   269/100000: episode: 194, duration: 0.112s, episode steps: 2, steps per second: 18, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 300603932672.000000, mean_q: 84.002563\n",
      "   269/100000: episode: 194, duration: 0.115s, episode steps: 2, steps per second: 17, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 300603932672.000000, mean_q: 84.002563\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.432536e+01\n",
      "Step 00271: model improved\n",
      "  from 8.400256e+01\n",
      "    to 8.432536e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.432536e+01_episode00194\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.432536e+01_episode00194 has done.\n",
      "max mean_q value: 8.432536e+01\n",
      "========== /Model Saver output =============\n",
      "   271/100000: episode: 195, duration: 0.114s, episode steps: 2, steps per second: 17, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 269438795776.000000, mean_q: 84.325363\n",
      "   271/100000: episode: 195, duration: 0.127s, episode steps: 2, steps per second: 16, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 269438795776.000000, mean_q: 84.325363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   273/100000: episode: 196, duration: 0.132s, episode steps: 2, steps per second: 15, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 308292091904.000000, mean_q: 84.684280\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   275/100000: episode: 197, duration: 0.133s, episode steps: 2, steps per second: 15, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 556349259776.000000, mean_q: 85.053459\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.468428e+01\n",
      "Step 00273: model improved\n",
      "  from 8.432536e+01\n",
      "    to 8.468428e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.468428e+01_episode00195\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.468428e+01_episode00195 has done.\n",
      "max mean_q value: 8.468428e+01\n",
      "========== /Model Saver output =============\n",
      "   273/100000: episode: 196, duration: 0.130s, episode steps: 2, steps per second: 15, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 308292091904.000000, mean_q: 84.684280\n",
      "   273/100000: episode: 196, duration: 0.139s, episode steps: 2, steps per second: 14, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 308292091904.000000, mean_q: 84.684280\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.505346e+01\n",
      "Step 00275: model improved\n",
      "  from 8.468428e+01\n",
      "    to 8.505346e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.505346e+01_episode00196\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.505346e+01_episode00196 has done.\n",
      "max mean_q value: 8.505346e+01\n",
      "========== /Model Saver output =============\n",
      "   275/100000: episode: 197, duration: 0.132s, episode steps: 2, steps per second: 15, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 556349259776.000000, mean_q: 85.053459\n",
      "   275/100000: episode: 197, duration: 0.143s, episode steps: 2, steps per second: 14, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 556349259776.000000, mean_q: 85.053459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   277/100000: episode: 198, duration: 0.130s, episode steps: 2, steps per second: 15, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 412859170816.000000, mean_q: 85.437729\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 1000006.657147\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115205.595324\n",
      "now_datetime: 2017-10-02 00:05:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "   279/100000: episode: 199, duration: 0.122s, episode steps: 2, steps per second: 16, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 610906537984.000000, mean_q: 85.793190\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115605.371258\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.543773e+01\n",
      "Step 00277: model improved\n",
      "  from 8.505346e+01\n",
      "    to 8.543773e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.543773e+01_episode00197\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.543773e+01_episode00197 has done.\n",
      "max mean_q value: 8.543773e+01\n",
      "========== /Model Saver output =============\n",
      "   277/100000: episode: 198, duration: 0.129s, episode steps: 2, steps per second: 16, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 412859170816.000000, mean_q: 85.437729\n",
      "   277/100000: episode: 198, duration: 0.138s, episode steps: 2, steps per second: 14, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 412859170816.000000, mean_q: 85.437729\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.579319e+01\n",
      "Step 00279: model improved\n",
      "  from 8.543773e+01\n",
      "    to 8.579319e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.579319e+01_episode00198\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.579319e+01_episode00198 has done.\n",
      "max mean_q value: 8.579319e+01\n",
      "========== /Model Saver output =============\n",
      "   279/100000: episode: 199, duration: 0.119s, episode steps: 2, steps per second: 17, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 610906537984.000000, mean_q: 85.793190\n",
      "   279/100000: episode: 199, duration: 0.125s, episode steps: 2, steps per second: 16, episode reward: 884801.062, mean reward: 442400.531 [-115205.595, 1000006.657], mean action: 2.000 [2.000, 2.000], mean observation: 57.151 [1.000, 112.812], loss: 610906537984.000000, mean_q: 85.793190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: -1\n",
      "positions_buy_or_sell: -1\n",
      "reward: 3230813.110409\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 3230810.967342\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115593.453778\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "_step 000004 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 3230820.854547\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000004 [2017-10-02 00:20:00]\n",
      "   after: 000005 [2017-10-02 00:25:00]\n",
      "_step ENDED\n",
      "_step 000005 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115290.560792\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000005 [2017-10-02 00:25:00]\n",
      "   after: 000006 [2017-10-02 00:30:00]\n",
      "_step ENDED\n",
      "_step 000006 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 3230830.741688\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000006 [2017-10-02 00:30:00]\n",
      "   after: 000007 [2017-10-02 00:35:00]\n",
      "_step ENDED\n",
      "_step 000007 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 2115241.801902\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000007 [2017-10-02 00:35:00]\n",
      "   after: 000008 [2017-10-02 00:40:00]\n",
      "_step ENDED\n",
      "_step 000008 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 999565.908653\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000008 [2017-10-02 00:40:00]\n",
      "   after: 000009 [2017-10-02 00:45:00]\n",
      "_step ENDED\n",
      "_step 000009 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115967.770136\n",
      "now_datetime: 2017-10-02 00:45:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000009 [2017-10-02 00:45:00]\n",
      "   after: 000010 [2017-10-02 00:50:00]\n",
      "_step ENDED\n",
      "   289/100000: episode: 200, duration: 0.452s, episode steps: 10, steps per second: 22, episode reward: 22268605.000, mean reward: 2226860.500 [-115967.770, 3230830.742], mean action: 1.500 [0.000, 2.000], mean observation: 59.158 [1.000, 112.841], loss: 308365623296.000000, mean_q: 86.699486\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115212.253231\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000000.000760\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115389.165002\n",
      "now_datetime: 2017-10-02 00:10:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "   292/100000: episode: 201, duration: 0.152s, episode steps: 3, steps per second: 20, episode reward: 2999823.089, mean reward: 999941.030 [-115389.165, 2115212.253], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 355006906368.000000, mean_q: 87.638908\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.669949e+01\n",
      "Step 00289: model improved\n",
      "  from 8.579319e+01\n",
      "    to 8.669949e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.669949e+01_episode00199\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.669949e+01_episode00199 has done.\n",
      "max mean_q value: 8.669949e+01\n",
      "========== /Model Saver output =============\n",
      "   289/100000: episode: 200, duration: 0.452s, episode steps: 10, steps per second: 22, episode reward: 22268605.000, mean reward: 2226860.500 [-115967.770, 3230830.742], mean action: 1.500 [0.000, 2.000], mean observation: 59.158 [1.000, 112.841], loss: 308365623296.000000, mean_q: 86.699486\n",
      "   289/100000: episode: 200, duration: 0.465s, episode steps: 10, steps per second: 22, episode reward: 22268605.000, mean reward: 2226860.500 [-115967.770, 3230830.742], mean action: 1.500 [0.000, 2.000], mean observation: 59.158 [1.000, 112.841], loss: 308365623296.000000, mean_q: 86.699486\n",
      "========== Model Saver output ==============\n",
      "mean_q value: 8.763891e+01\n",
      "Step 00292: model improved\n",
      "  from 8.669949e+01\n",
      "    to 8.763891e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.763891e+01_episode00200\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.763891e+01_episode00200 has done.\n",
      "max mean_q value: 8.763891e+01\n",
      "========== /Model Saver output =============\n",
      "   292/100000: episode: 201, duration: 0.151s, episode steps: 3, steps per second: 20, episode reward: 2999823.089, mean reward: 999941.030 [-115389.165, 2115212.253], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 355006906368.000000, mean_q: 87.638908\n",
      "   292/100000: episode: 201, duration: 0.157s, episode steps: 3, steps per second: 19, episode reward: 2999823.089, mean reward: 999941.030 [-115389.165, 2115212.253], mean action: 2.000 [2.000, 2.000], mean observation: 57.400 [1.000, 112.812], loss: 355006906368.000000, mean_q: 87.638908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: 2115212.253231\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "_step 000001 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000000.000760\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000001 [2017-10-02 00:05:00]\n",
      "   after: 000002 [2017-10-02 00:10:00]\n",
      "_step ENDED\n",
      "_step 000002 STARTED\n",
      "positions_buy_or_sell: 1\n",
      "reward: 1000004.287654\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000002 [2017-10-02 00:10:00]\n",
      "   after: 000003 [2017-10-02 00:15:00]\n",
      "_step ENDED\n",
      "_step 000003 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "reward: -115213.225910\n",
      "now_datetime: 2017-10-02 00:15:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000003 [2017-10-02 00:15:00]\n",
      "   after: 000004 [2017-10-02 00:20:00]\n",
      "_step ENDED\n",
      "   296/100000: episode: 202, duration: 0.182s, episode steps: 4, steps per second: 22, episode reward: 4000003.316, mean reward: 1000000.829 [-115213.226, 2115212.253], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 335624110080.000000, mean_q: 88.167633\n",
      "_reset START\n",
      "self._seed: 100000\n",
      "Start datetime: 2017-10-02 00:00:00\n",
      "_reset END\n",
      "_step 000000 STARTED\n",
      "現在の総含み益を再計算\n",
      "buy_or_sell: 1\n",
      "positions_buy_or_sell: 1\n",
      "2017-10-02 00:00:00 112.833000\n",
      "reward: -115594.426457\n",
      "now_datetime: 2017-10-02 00:00:00\n",
      "len(self.hist_data.data()) - 1: 287\n",
      "今注目している日時を更新 (=インデックスのインクリメント)\n",
      "  before: 000000 [2017-10-02 00:00:00]\n",
      "   after: 000001 [2017-10-02 00:05:00]\n",
      "_step ENDED\n",
      "done, took 19.155 seconds\n",
      "elapsed_time:19.207477569580078[sec]\n",
      "17/11/06 01:16:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model Saver output ==============\n",
      "mean_q value: 8.816763e+01\n",
      "Step 00296: model improved\n",
      "  from 8.763891e+01\n",
      "    to 8.816763e+01, saving model to ./models/Keras-RL_DQN_FX_model_meanq8.816763e+01_episode00201\n",
      "Save model to ./models/Keras-RL_DQN_FX_model_meanq8.816763e+01_episode00201 has done.\n",
      "max mean_q value: 8.816763e+01\n",
      "========== /Model Saver output =============\n",
      "   296/100000: episode: 202, duration: 0.179s, episode steps: 4, steps per second: 22, episode reward: 4000003.316, mean reward: 1000000.829 [-115213.226, 2115212.253], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 335624110080.000000, mean_q: 88.167633\n",
      "   296/100000: episode: 202, duration: 0.184s, episode steps: 4, steps per second: 22, episode reward: 4000003.316, mean reward: 1000000.829 [-115213.226, 2115212.253], mean action: 1.500 [0.000, 2.000], mean observation: 57.649 [1.000, 112.812], loss: 335624110080.000000, mean_q: 88.167633\n",
      "done, took 19.155 seconds\n",
      "done, took 19.156 seconds\n"
     ]
    }
   ],
   "source": [
    "is_to_train = True\n",
    "if is_to_train:\n",
    "    dfx.train(is_for_time_measurement=True)\n",
    "else:\n",
    "    dfx.test(1, [EpisodeLogger()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[<matplotlib.lines.Line2D at 0x7fbe4017be10>],\n",
       " [<matplotlib.lines.Line2D at 0x7fbe40134860>],\n",
       " [<matplotlib.lines.Line2D at 0x7fbe40142978>],\n",
       " [<matplotlib.lines.Line2D at 0x7fbe40142b00>]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "data = hd.data()['Close']\n",
    "x = data.index\n",
    "y = data.values\n",
    "sd = 1\n",
    "upper, middle, lower = talib.BBANDS(data.values, timeperiod=20, matype=talib.MA_Type.SMA, nbdevup=sd, nbdevdn=sd)\n",
    "[plt.plot(x, val) for val in [y, upper, middle, lower]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 112.833,  112.793,  112.812,  112.794,  112.795,  112.826,\n",
       "        112.827,  112.832,  112.841,  112.826,  112.815,  112.817,\n",
       "        112.837,  112.84 ,  112.844,  112.851,  112.9  ,  112.906,\n",
       "        112.909,  112.887,  112.888,  112.889,  112.869,  112.874,\n",
       "        112.904,  112.883,  112.851,  112.85 ,  112.878,  112.912,\n",
       "        112.901,  112.877,  112.883,  112.875,  112.889,  112.872,\n",
       "        112.862,  112.871,  112.927,  112.932,  112.939,  112.964,\n",
       "        112.995,  113.017,  113.018,  113.008,  112.991,  112.983,\n",
       "        113.009,  112.983,  112.951,  112.943,  112.944,  112.94 ,\n",
       "        112.917,  112.865,  112.832,  112.821,  112.806,  112.794,\n",
       "        112.794,  112.807,  112.829,  112.817,  112.833,  112.859,\n",
       "        112.863,  112.825,  112.852,  112.887,  112.886,  112.882,\n",
       "        112.848,  112.85 ,  112.818,  112.791,  112.794,  112.802,\n",
       "        112.807,  112.817,  112.769,  112.802,  112.804,  112.777,\n",
       "        112.773,  112.767,  112.77 ,  112.784,  112.788,  112.824,\n",
       "        112.826,  112.817,  112.836,  112.867,  112.844,  112.839,\n",
       "        112.806,  112.828,  112.826,  112.789,  112.708,  112.723,\n",
       "        112.711,  112.675,  112.681,  112.633,  112.608,  112.615,\n",
       "        112.59 ,  112.607,  112.594,  112.627,  112.588,  112.601,\n",
       "        112.565,  112.563,  112.562,  112.629,  112.625,  112.672,\n",
       "        112.862,  112.706,  112.675,  112.635,  112.609,  112.579,\n",
       "        112.563,  112.597,  112.626,  112.602,  112.636,  112.711,\n",
       "        112.722,  112.69 ,  112.681,  112.723,  112.701,  112.686,\n",
       "        112.737,  112.707,  112.679,  112.667,  112.658,  112.608,\n",
       "        112.583,  112.575,  112.573,  112.587,  112.586,  112.583,\n",
       "        112.588,  112.579,  112.6  ,  112.633,  112.658,  112.685,\n",
       "        112.69 ,  112.692,  112.687,  112.761,  112.737,  112.753,\n",
       "        112.735,  112.719,  112.713,  112.711,  112.704,  112.687,\n",
       "        112.681,  112.683,  112.65 ,  112.64 ,  112.62 ,  112.591,\n",
       "        112.611,  112.614,  112.634,  112.596,  112.611,  112.66 ,\n",
       "        112.653,  112.649,  112.658,  112.657,  112.676,  112.689,\n",
       "        112.68 ,  112.707,  112.681,  112.717,  112.728,  112.74 ,\n",
       "        112.733,  112.729,  112.742,  112.733,  112.727,  112.716,\n",
       "        112.722,  112.731,  112.729,  112.707,  112.718,  112.75 ,\n",
       "        112.709,  112.719,  112.708,  112.729,  112.736,  112.733,\n",
       "        112.716,  112.718,  112.707,  112.709,  112.711,  112.711,\n",
       "        112.736,  112.728,  112.731,  112.734,  112.728,  112.69 ,\n",
       "        112.719,  112.724,  112.714,  112.699,  112.684,  112.669,\n",
       "        112.707,  112.726,  112.728,  112.719,  112.744,  112.744,\n",
       "        112.741,  112.759,  112.765,  112.791,  112.79 ,  112.773,\n",
       "        112.802,  112.763,  112.764,  112.73 ,  112.716,  112.708,\n",
       "        112.685,  112.737,  112.731,  112.745,  112.932,  112.946,\n",
       "        112.953,  112.912,  112.925,  112.971,  112.957,  112.975,\n",
       "        112.933,  112.97 ,  112.961,  113.059,  113.056,  113.148,\n",
       "        113.142,  113.117,  113.068,  113.08 ,  113.086,  113.099,\n",
       "        113.092,  113.06 ,  113.058,  113.059,  113.066,  113.072,\n",
       "        113.072,  113.064,  113.043,  113.064,  113.071,  113.089,\n",
       "        113.124,  113.148,  113.135,  113.169,  113.137,  113.142])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeepFX Finished: 17/11/06 01:16:06\n"
     ]
    }
   ],
   "source": [
    "logger.info('DeepFX Finished: %s' % DebugTools.now_str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Deep Q-LearningでFXしてみた](http://recruit.gmo.jp/engineer/jisedai/blog/deep-q-learning/)\n",
    "- [slide](https://www.slideshare.net/JunichiroKatsuta/deep-qlearningfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
