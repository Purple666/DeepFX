{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Python] Keras-RLで簡単に強化学習(DQN)を試す](http://qiita.com/inoory/items/e63ade6f21766c7c2393)を参考に、エージェントを作成する。FXの自動取引を行い、利益を出すのが目標。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym.spaces\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import enum\n",
    "from logging import getLogger, StreamHandler, DEBUG, INFO\n",
    "import time\n",
    "import keras\n",
    "import os\n",
    "import warnings\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger = getLogger(__name__)\n",
    "handler = StreamHandler()\n",
    "handler.setLevel(INFO)\n",
    "logger.setLevel(INFO)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "class DebugTools:\n",
    "    def now():\n",
    "        return dt.datetime.now() + dt.timedelta(hours=9)\n",
    "    def now_str():    \n",
    "        return DebugTools.now().strftime('%y/%m/%d %H:%M:%S')\n",
    "\n",
    "class Action(enum.Enum):\n",
    "    SELL = -1; STAY = 0; BUY = +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HistData:\n",
    "    def __init__(self, date_range=None):\n",
    "        self.csv_path = 'USDJPY.hst_.csv'\n",
    "        self.csv_data = pd.read_csv(self.csv_path, index_col=0, parse_dates=True, header=0)\n",
    "        self.date_range = date_range\n",
    "\n",
    "    def data(self):\n",
    "        if self.date_range is None:\n",
    "            return self.csv_data\n",
    "        else:\n",
    "            return self.csv_data[self.date_range]\n",
    "\n",
    "    def max_value(self):\n",
    "        return self.data()[['High']].max()['High']\n",
    "\n",
    "    def min_value(self):\n",
    "        return self.data()[['Low']].min()['Low']\n",
    "\n",
    "    def dates(self):\n",
    "        return self.data().index.values\n",
    "\n",
    "    ''' 引数の日時がデータフレームに含まれるか '''\n",
    "    def has_datetime(self, datetime64_value):\n",
    "        try:\n",
    "            h.data().loc[datetime64_value]\n",
    "            return True\n",
    "        except KeyError:\n",
    "            return False\n",
    "\n",
    "    def _get_nearist_index(self, before_or_after, datetime):\n",
    "        if before_or_after == 'before':\n",
    "            offset = -1\n",
    "        else:\n",
    "            offset = 0\n",
    "        index = max(h.data().index.searchsorted(datetime) + offset, 0)\n",
    "        return self.data().ix[self.data().index[index]]\n",
    "\n",
    "    ''' 引数の日時を含まない直前に存在する値を取得する '''        \n",
    "    def get_last_exist_datetime(self, datetime64_value):\n",
    "        return self._get_nearist_index('before', datetime64_value)\n",
    "        \n",
    "    ''' 引数の日時を含む直後に存在する値を取得する '''\n",
    "    def get_next_exist_datetime(self, datetime64_value):\n",
    "        return self._get_nearist_index('after', datetime64_value)\n",
    "    \n",
    "    ''' fromとtoの日時の差が閾値内にあるか否か '''\n",
    "    def is_datetime_diff_in_threshould(self, from_datetime, to_datetime, threshold_timedelta):\n",
    "        last_datetime = h.get_last_exist_datetime(from_datetime)\n",
    "        next_exist_datetime = h.get_next_exist_datetime(to_datetime)\n",
    "        delta = next_exist_datetime.name - last_datetime.name\n",
    "        return delta <= threshold_timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' ポジション '''\n",
    "class Position:\n",
    "    def __init__(self, buy_or_sell, price, amount):\n",
    "        self.price = price\n",
    "        self.amount = amount\n",
    "        self.buy_or_sell = buy_or_sell\n",
    "    \n",
    "    ''' 総利益を計算する '''\n",
    "    def calc_profit_by(self, now_price):\n",
    "        return self._calc_unit_profit_by(now_price) * self.amount\n",
    "\n",
    "    ''' 単位あたりの利益を計算する '''\n",
    "    def _calc_unit_profit_by(self, now_price):\n",
    "        if self.buy_or_sell == 'buy' or self.buy_or_sell == Action.BUY.value:\n",
    "            return now_price - self.price\n",
    "        else:\n",
    "            return self.price - now_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FXTrade(gym.core.Env):\n",
    "    AMOUNT_UNIT = 50000\n",
    "    THRESHOULD_TIME_DELTA = dt.timedelta(days=1)\n",
    "    \n",
    "    def __init__(self, initial_cash, spread, hist_data, seed_value=100000, logger=None):\n",
    "        self.hist_data = hist_data\n",
    "        self.initial_cash = initial_cash\n",
    "        self.cash = initial_cash\n",
    "        self.spread = spread\n",
    "        self._positions = []\n",
    "        self._max_date = self._datetime2float(hist_data.dates().max())\n",
    "        self._min_date = self._datetime2float(hist_data.dates().min())\n",
    "        self._seed = seed_value\n",
    "\n",
    "        high = np.array([self._max_date, hist_data.max_value()])\n",
    "        low = np.array([self._min_date, hist_data.min_value()])\n",
    "        self.action_space = gym.spaces.Discrete(3)\n",
    "        self.observation_space = gym.spaces.Box(low = low, high = high) # DateFrame, Close prise\n",
    "        \n",
    "    def get_now_datetime_as(self, datetime_or_float):\n",
    "        if datetime_or_float == 'float':\n",
    "            return self._now_datetime\n",
    "        else:\n",
    "            dt = self._float2datetime(self._now_datetime)\n",
    "            return dt\n",
    "    \n",
    "    def _set_now_datetime(self, value):\n",
    "        if isinstance(value, float):\n",
    "            assert self._min_date <= value, value\n",
    "            assert value <= self._max_date, value\n",
    "            self._now_datetime = value\n",
    "            return value\n",
    "        else:\n",
    "            assert self._min_date <= self._datetime2float(value), '%f <= %f, %s' % (self._min_date, self._datetime2float(value), value)\n",
    "            assert self._datetime2float(value) <= self._max_date, '%f <= %f, %s' % (self._datetime2float(value), self._max_date, value)\n",
    "            float_val = self._datetime2float(value)\n",
    "            self._now_datetime = float_val\n",
    "            return float_val\n",
    "            \n",
    "    def setseed(self, seed_value):\n",
    "        self._seed = seed_value\n",
    "        np.random.seed(self._seed)\n",
    "        print('Set seed value: %d' % self._seed)\n",
    "        return seed_value\n",
    "        \n",
    "    def _seed(self):\n",
    "        return self._seed\n",
    "    \n",
    "    def _datetime2float(self, datetime64_value):\n",
    "        try:\n",
    "            float_val = float(str(datetime64_value.astype('uint64'))[:10])\n",
    "            return float_val\n",
    "        except:\n",
    "            logger.error('_datetime2float except')\n",
    "            import pdb; pdb.set_trace()\n",
    "    \n",
    "    def _float2datetime(self, float_timestamp):\n",
    "        try:\n",
    "            datetime_val = np.datetime64(dt.datetime.utcfromtimestamp(float_timestamp))\n",
    "            return datetime_val\n",
    "        except:\n",
    "            logger.error('_float2datetime except')\n",
    "            import pdb; pdb.set_trace()\n",
    "    \n",
    "    ''' 総含み益を計算する '''\n",
    "    def _calc_total_unrealized_gain_by(self, now_close_value):\n",
    "        if not self._positions: # positions is empty\n",
    "            return 0\n",
    "        total_profit = 0\n",
    "        for position in self._positions:\n",
    "            total_profit += position.calc_profit_by(now_close_value)\n",
    "        return total_profit\n",
    "    \n",
    "    ''' 全ポジションを決済する '''\n",
    "    def _liquidate_all_positions_by(self, now_price):\n",
    "        total_profit = 0\n",
    "        buy_or_sell = self._positions[0].buy_or_sell\n",
    "        \n",
    "        for position in self._positions:\n",
    "            total_profit += position.calc_profit_by(now_price)\n",
    "        self._positions = []\n",
    "        self.cash += total_profit\n",
    "        return total_profit\n",
    "        \n",
    "    ''' 注文を出す '''\n",
    "    def _order(self, buy_or_sell, now_price, amount):\n",
    "        position = Position(buy_or_sell=buy_or_sell, price=now_price, amount=amount)\n",
    "        self._positions.append(position)\n",
    "        return position\n",
    "    \n",
    "    def _get_price_of(self, buy_or_sell, now_buy_price, now_sell_price):\n",
    "        if buy_or_sell == Action.BUY.value or buy_or_sell == Action.STAY.value:\n",
    "            return now_buy_price\n",
    "        elif buy_or_sell == Action.SELL.value:\n",
    "            return now_sell_price\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    ''' 各stepごとに呼ばれる\n",
    "        actionを受け取り、次のstateとreward、episodeが終了したかどうかを返すように実装 '''\n",
    "    def _step(self, action):\n",
    "        logger.debug('_step STARTED')\n",
    "        \n",
    "        # actionを受け取り、次のstateを決定\n",
    "        buy_or_sell_or_stay = action - 1\n",
    "        assert buy_or_sell_or_stay == -1 or \\\n",
    "            buy_or_sell_or_stay == 0 or \\\n",
    "            buy_or_sell_or_stay == 1, 'buy_or_sell_or_stay: %d' % buy_or_sell_or_stay\n",
    "        \n",
    "        dminute = 1 # minuteの増加量\n",
    "        # 今注目している日時を更新\n",
    "        logger.debug('今注目している日時を更新')\n",
    "        #import pdb; pdb.set_trace()\n",
    "        previous_datetime = self.get_now_datetime_as('datetime')\n",
    "        now_datetime = previous_datetime + np.timedelta64(dminute, 'm')\n",
    "                \n",
    "        logger.debug('before')\n",
    "        logger.debug(now_datetime)\n",
    "        logger.debug(self._now_datetime)\n",
    "        #import pdb; pdb.set_trace()\n",
    "        self._set_now_datetime(now_datetime)\n",
    "        logger.debug('after')\n",
    "        logger.debug(now_datetime)\n",
    "        logger.debug(self._now_datetime)\n",
    "        # その時点における値群\n",
    "        if h.has_datetime(now_datetime):\n",
    "            modified_now_datetime = now_datetime\n",
    "        else:\n",
    "            modified_now_datetime = self.hist_data.get_last_exist_datetime(now_datetime).name\n",
    "        now_values = self.hist_data.data().loc[modified_now_datetime]\n",
    "        \n",
    "        now_buy_price = now_values['Close']\n",
    "        self._now_buy_price = now_buy_price\n",
    "        now_sell_price = now_buy_price - self.spread\n",
    "        \n",
    "        logger.debug(modified_now_datetime)\n",
    "        if pd.DatetimeIndex([modified_now_datetime]).hour[0] == 0 and\\\n",
    "            pd.DatetimeIndex([modified_now_datetime]).minute[0] == 0:\n",
    "            # 毎日00:00に表示\n",
    "            if now_datetime == modified_now_datetime:\n",
    "                logger.info('%s %f' % (now_datetime, now_buy_price))\n",
    "            else:\n",
    "                 logger.info('%s (mod: %s) %f' % (now_datetime, modified_now_datetime, now_buy_price))\n",
    "        \n",
    "        now_price = self._get_price_of(buy_or_sell_or_stay, now_buy_price, now_sell_price)\n",
    "        if self._positions: # position is not empty\n",
    "            if buy_or_sell_or_stay == Action.SELL.value:\n",
    "                if self._positions[0].buy_or_sell == Action.BUY.value:\n",
    "                    self._liquidate_all_positions_by(now_price)\n",
    "                else:\n",
    "                    self._order(buy_or_sell_or_stay, self.AMOUNT_UNIT, now_price)\n",
    "            elif buy_or_sell_or_stay == Action.BUY.value:\n",
    "                if self._positions[0].buy_or_sell == Action.SELL.value:\n",
    "                    self._liquidate_all_positions_by(now_price)\n",
    "                else:\n",
    "                    self._order(buy_or_sell_or_stay, self.AMOUNT_UNIT, now_price)\n",
    "        else: #position is empty\n",
    "            if buy_or_sell_or_stay != Action.STAY:\n",
    "                self._order(buy_or_sell_or_stay, self.AMOUNT_UNIT, now_price)\n",
    "            \n",
    "        \n",
    "        # 現在の総含み益を再計算\n",
    "        positions_buy_or_sell = None\n",
    "        if self._positions:\n",
    "            logger.debug('現在の総含み益を再計算')\n",
    "            positions_buy_or_sell = self._positions[0].buy_or_sell\n",
    "            logger.debug('buy_or_sell: %d' % positions_buy_or_sell)\n",
    "        else:\n",
    "            positions_buy_or_sell = Action.BUY.value\n",
    "        logger.debug('positions_buy_or_sell: %d', positions_buy_or_sell)\n",
    "        now_price_for_positions = self._get_price_of(positions_buy_or_sell, now_buy_price, now_sell_price)\n",
    "        self._total_unrealized_gain = self._calc_total_unrealized_gain_by(now_price_for_positions)\n",
    "\n",
    "        # 日付が学習データの最後と一致すれば終了\n",
    "        done = now_datetime == self.hist_data.dates()[-1]\n",
    "        if done:\n",
    "            print('now_datetime: %s' % now_datetime)\n",
    "            print('self.hist_data.dates()[-1]: %s' % self.hist_data.dates()[-1])\n",
    "\n",
    "\n",
    "        # 報酬は現金と総含み益\n",
    "        reward = self._total_unrealized_gain + self.cash\n",
    "        \n",
    "        # 次のstate、reward、終了したかどうか、追加情報の順に返す\n",
    "        # 追加情報は特にないので空dict\n",
    "        logger.debug('_step ENDED')\n",
    "        return np.array([self._now_datetime, self._now_buy_price]), reward, done, {}\n",
    "        \n",
    "    ''' 各episodeの開始時に呼ばれ、初期stateを返すように実装 '''\n",
    "    def _reset(self):\n",
    "        print('_reset START')\n",
    "        print(self.hist_data.dates()[0])\n",
    "\n",
    "        self._set_now_datetime(self.hist_data.dates()[0])\n",
    "        print(self._now_datetime)\n",
    "\n",
    "        self._now_buy_price = self.hist_data.data()['Close'][0]\n",
    "        self._positions = []\n",
    "        print(self._seed)\n",
    "        print('_reset END')\n",
    "        return np.array([self._now_datetime, self._now_buy_price])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rl.callbacks\n",
    "class ModelSaver(rl.callbacks.TrainEpisodeLogger):\n",
    "    def __init__(self, filepath, monitor='loss', verbose=1, save_weights_only=True):\n",
    "        self.min_monitor_value = None\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.verbose = verbose\n",
    "        #self.save_best_only = save_best_only\n",
    "        self.save_weights_only = save_weights_only\n",
    "        super().__init__()\n",
    "\n",
    "    def on_episode_end(self, episode, logs):\n",
    "        print('========== Model Saver output ==============')\n",
    "        loss_value = self._formatted_metrics(episode)[self.monitor]\n",
    "        print('loss_value: %f' % loss_value)\n",
    "        if self.min_monitor_value is None or loss_value < self.min_monitor_value:\n",
    "            previous_value = self.min_monitor_value\n",
    "            self.min_monitor_value = loss_value\n",
    "            self._save_model(previous_monitor=previous_value, loss=loss_value, episode=episode)\n",
    "        print('min monitor loss: %f' % self.min_monitor_value)\n",
    "        print('========== /Model Saver output =============')\n",
    "        super().on_episode_end(episode, logs)\n",
    "\n",
    "    def _save_model(self, previous_monitor, loss, episode):\n",
    "        filepath = self.filepath.format(loss=loss, episode=episode)\n",
    "        if self.verbose > 0:\n",
    "            print('Step %05d: model improved from %0.5f to %0.5f,'\n",
    "                  ' saving model to %s'\n",
    "                  % (self.step, previous_monitor or 0.0,\n",
    "                     self.min_monitor_value or 0.0, filepath))\n",
    "        if self.save_weights_only:\n",
    "            self.model.save_weights(filepath, overwrite=True)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def _formatted_metrics(self, episode):\n",
    "        # Format all metrics.\n",
    "        metrics = np.array(self.metrics[episode])\n",
    "        metrics_variables = []\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('error')\n",
    "            for idx, name in enumerate(self.metrics_names):\n",
    "                try:\n",
    "                    value = np.nanmean(metrics[:, idx])\n",
    "                except Warning:\n",
    "                    value = '--'\n",
    "                metrics_variables += [name, value]\n",
    "        return dict(itertools.zip_longest(*[iter(metrics_variables)] * 2, fillvalue=\"\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = HistData('2010/09/01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_36 (Flatten)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 3)                 51        \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 643.0\n",
      "Trainable params: 643.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17/04/10 23:44:08\n",
      "Training for 2878 steps ...\n",
      "Training for 2878 steps ...\n",
      "_reset START\n",
      "2010-09-01T00:00:00.000000000\n",
      "1283299200.0\n",
      "100000\n",
      "_reset END\n",
      "now_datetime: 2010-09-01T23:59:00.000000\n",
      "self.hist_data.dates()[-1]: 2010-09-01T23:59:00.000000000\n",
      "========== Model Saver output ==============\n",
      "loss_value: 76810932816888624.000000\n",
      "Step 01439: model improved from 0.00000 to 76810932816888624.00000, saving model to Keras-RL_DQN_FX_model_episode00000_loss7.681093e+16.hdf5\n",
      "min monitor loss: 76810932816888624.000000\n",
      "========== /Model Saver output =============\n",
      " 1439/2878: episode: 1, duration: 23.240s, episode steps: 1439, steps per second: 62, episode reward: -1690854265313.871, mean reward: -1175020337.258 [-2225837642.895, -3201913.728], mean action: 1.363 [0.000, 2.000], mean observation: 641671242.131 [83.720, 1283385540.000], loss: 76810932816888624.000000, mean_absolute_error: 2298185224.245142, mean_q: -3219383092.398356\n",
      " 1439/2878: episode: 1, duration: 23.248s, episode steps: 1439, steps per second: 62, episode reward: -1690854265313.871, mean reward: -1175020337.258 [-2225837642.895, -3201913.728], mean action: 1.363 [0.000, 2.000], mean observation: 641671242.131 [83.720, 1283385540.000], loss: 76810932816888624.000000, mean_absolute_error: 2298185224.245142, mean_q: -3219383092.398356\n",
      "_reset START\n",
      "2010-09-01T00:00:00.000000000\n",
      "1283299200.0\n",
      "100000\n",
      "_reset END\n",
      "now_datetime: 2010-09-01T23:59:00.000000\n",
      "self.hist_data.dates()[-1]: 2010-09-01T23:59:00.000000000\n",
      "========== Model Saver output ==============\n",
      "loss_value: 239587964559032320.000000\n",
      "min monitor loss: 76810932816888624.000000\n",
      "========== /Model Saver output =============\n",
      " 2878/2878: episode: 2, duration: 22.664s, episode steps: 1439, steps per second: 63, episode reward: -2960850252636.113, mean reward: -2057574880.220 [-3129862004.457, -756735145.654], mean action: 1.388 [0.000, 2.000], mean observation: 641671242.131 [83.720, 1283385540.000], loss: 239587964559032320.000000, mean_absolute_error: 11046749184.000000, mean_q: -16179841024.000000\n",
      " 2878/2878: episode: 2, duration: 22.668s, episode steps: 1439, steps per second: 63, episode reward: -2960850252636.113, mean reward: -2057574880.220 [-3129862004.457, -756735145.654], mean action: 1.388 [0.000, 2.000], mean observation: 641671242.131 [83.720, 1283385540.000], loss: 239587964559032320.000000, mean_absolute_error: 11046749184.000000, mean_q: -16179841024.000000\n",
      "done, took 45.924 seconds\n",
      "done, took 45.924 seconds\n",
      "elapsed_time:45.927716970443726[sec]\n",
      "17/04/10 23:44:54\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "log_directory = './log'\n",
    "model_directory = './model'\n",
    "#model_filename = 'Keras-RL_DQN_FX_model{epoch:02d}-loss{loss:.2f}-acc{acc:.2f}-vloss{val_loss:.2f}-vacc{val_acc:.2f}.hdf5'\n",
    "model_filename = 'Keras-RL_DQN_FX_model_episode{episode:05d}_loss{loss:e}.hdf5'\n",
    "weights_filename = 'Keras-RL_DQN_FX_weights.h5'\n",
    "\n",
    "env = FXTrade(1000000, 0.08, h)\n",
    "nb_actions = env.action_space.n\n",
    "\n",
    "# DQNのネットワーク定義\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())\n",
    "\n",
    "# experience replay用のmemory\n",
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "# 行動方策はオーソドックスなepsilon-greedy。ほかに、各行動のQ値によって確率を決定するBoltzmannQPolicyが利用可能\n",
    "policy = EpsGreedyQPolicy(eps=0.1) \n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=100,\n",
    "               target_model_update=1e-2, policy=policy)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "\n",
    "tensor_board_callback = keras.callbacks.TensorBoard(log_dir=log_directory, histogram_freq=1)\n",
    "check_point_callback = keras.callbacks.ModelCheckpoint(filepath = os.path.join(model_directory, model_filename),\\\n",
    "                                        monitor='metrics[\"loss\"]', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "model_saver_callback = ModelSaver(model_filename)\n",
    "\n",
    "is_for_time_measurement = True\n",
    "if is_for_time_measurement:\n",
    "    start = time.time()\n",
    "    print(DebugTools.now_str())\n",
    "    #minutes = 2591940/60 # 2591940secs = '2010-09-30 23:59:00' - '2010-09-01 00:00:00'\n",
    "    minutes = (60 * 24 - 1) * 2 # 2days\n",
    "    history = dqn.fit(env, nb_steps=minutes, visualize=False, verbose=2, nb_max_episode_steps=None, \\\n",
    "                     callbacks=[model_saver_callback])\n",
    "    elapsed_time = time.time() - start\n",
    "    print((\"elapsed_time:{0}\".format(elapsed_time)) + \"[sec]\")\n",
    "    print(DebugTools.now_str())\n",
    "else:\n",
    "    history = dqn.fit(env, nb_steps=50000, visualize=False, verbose=2, nb_max_episode_steps=None)\n",
    "#学習の様子を描画したいときは、Envに_render()を実装して、visualize=True にします,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EpisodeLogger(rl.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.observations = {}\n",
    "        self.rewards = {}\n",
    "        self.actions = {}\n",
    "\n",
    "    def on_episode_begin(self, episode, logs):\n",
    "        self.observations[episode] = []\n",
    "        self.rewards[episode] = []\n",
    "        self.actions[episode] = []\n",
    "\n",
    "    def on_step_end(self, step, logs):\n",
    "        episode = logs['episode']\n",
    "        self.observations[episode].append(logs['observation'])\n",
    "        self.rewards[episode].append(logs['reward'])\n",
    "        self.actions[episode].append(logs['action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    cb_ep = EpisodeLogger()\n",
    "    dqn.test(env, nb_episodes=10, visualize=False, callbacks=[cb_ep])\n",
    "\n",
    "\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    for obs in cb_ep.observations.values():\n",
    "        plt.plot([o[0] for o in obs])\n",
    "    plt.xlabel(\"step\")\n",
    "    plt.ylabel(\"pos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
